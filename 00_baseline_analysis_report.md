# Baseline ì½”ë“œ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ

## ğŸ“Š 1. í˜„ì¬ ì„±ëŠ¥ ì§€í‘œ (10 Epochs)

```
H-Mean (F1-Score): 0.8818
Precision: 0.9651  â¬†ï¸ (ë§¤ìš° ë†’ìŒ)
Recall: 0.8194     â¬‡ï¸ (ê°œì„  í•„ìš”)
```

### í•µì‹¬ ë¬¸ì œ ì§„ë‹¨

- **ë†’ì€ Precision (96.51%)**: ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë°•ìŠ¤ëŠ” ëŒ€ë¶€ë¶„ ì •í™•í•¨
- **ë‚®ì€ Recall (81.94%)**: ë§ì€ í…ìŠ¤íŠ¸ ì˜ì—­ì„ ë†“ì¹˜ê³  ìˆìŒ (ì•½ 18% ë¯¸íƒì§€)
- **ë¶ˆê· í˜• íŒ¨í„´**: ëª¨ë¸ì´ **ë³´ìˆ˜ì ìœ¼ë¡œ ì˜ˆì¸¡**í•˜ì—¬ í™•ì‹¤í•œ ê²ƒë§Œ ê°ì§€

---

## ğŸ—ï¸ 2. ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¶„ì„

### 2.1 ì „ì²´ êµ¬ì¡° (DBNet ê¸°ë°˜)

```
Input Image (640Ã—640)
    â†“
Encoder: ResNet18 (Pretrained)
    â†“
Decoder: UNet (FPN-style)
    â†“
Head: DBHead (Prob + Thresh + Binary Maps)
    â†“
Loss: DBLoss (BCE + L1 + Dice)
```

### 2.2 Encoder: TimmBackbone (ResNet18)

```yaml
model_name: 'resnet18'
pretrained: true
select_features: [1, 2, 3, 4]  # Multi-scale features
```

**íŠ¹ì§•:**
- âœ… **ResNet18**: ê°€ë²¼ìš´ ë°±ë³¸ (11.7M params)
- âš ï¸ **í•œê³„**: ì‘ì€ í…ìŠ¤íŠ¸ë‚˜ ë³µì¡í•œ ë ˆì´ì•„ì›ƒ ê°ì§€ ëŠ¥ë ¥ ì œí•œ
- ğŸ’¡ **ì œì•ˆ**: ResNet34/50, EfficientNet, ConvNeXt ë“±ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ ê°€ëŠ¥

### 2.3 Decoder: UNet

```yaml
in_channels: [64, 128, 256, 512]
inner_channels: 256
output_channels: 64
strides: [4, 8, 16, 32]
```

**íŠ¹ì§•:**
- âœ… Multi-scale feature fusion
- âš ï¸ `inner_channels: 256`ì€ ì¤‘ê°„ ìˆ˜ì¤€ (ë” ì¦ê°€ ê°€ëŠ¥)

### 2.4 Head: DBHead

```yaml
in_channels: 256
upscale: 4
k: 50  # Differentiable Binarization ê³„ìˆ˜
postprocess:
  thresh: 0.3          # ğŸ”´ ì¤‘ìš”
  box_thresh: 0.4      # ğŸ”´ ì¤‘ìš”
  max_candidates: 300
```

**Recall ì €í•˜ì˜ ì£¼ìš” ì›ì¸:**
- âš ï¸ **`box_thresh: 0.4`**: ë„ˆë¬´ ë†’ìŒ â†’ í™•ì‹ ì´ ë†’ì€ ë°•ìŠ¤ë§Œ ì„ íƒ
- âš ï¸ **`thresh: 0.3`**: ì´ì§„í™” ì„ê³„ê°’
- ğŸ’¡ **Recallì„ ë†’ì´ë ¤ë©´ `box_thresh`ë¥¼ ë‚®ì¶°ì•¼ í•¨** (0.25~0.35)

---

## ğŸ“ 3. ë°ì´í„° ì „ì²˜ë¦¬ ë¶„ì„

### 3.1 ì´ë¯¸ì§€ í¬ê¸°

```yaml
transforms:
  - LongestMaxSize: 640
  - PadIfNeeded: 640Ã—640
```

**í‰ê°€:**
- âš ï¸ **640Ã—640ì€ ì‘ìŒ**: Receipt ì´ë¯¸ì§€ëŠ” ì¢…ì¢… ì„¸ë¡œë¡œ ê¸¸ê³  í…ìŠ¤íŠ¸ê°€ ì‘ìŒ
- ğŸ’¡ **ì œì•ˆ**: 800~1024ë¡œ ì¦ê°€ (ë©”ëª¨ë¦¬ í—ˆìš© ì‹œ)

### 3.2 Data Augmentation

```yaml
train_transform:
  - HorizontalFlip: p=0.5
  - Normalize: ImageNet ê¸°ì¤€
```

**ë¬¸ì œì :**
- âŒ **ì¦ê°•ì´ ë§¤ìš° ë¶€ì¡±**
  - Rotation âŒ
  - RandomBrightnessContrast âŒ
  - ColorJitter âŒ
  - RandomScale âŒ
  - ShiftScaleRotate âŒ
  
**ì˜í–¥:**
- ë‹¤ì–‘í•œ ê°ë„/ì¡°ëª…/ìŠ¤ì¼€ì¼ì˜ í…ìŠ¤íŠ¸ ì¼ë°˜í™” ë¶€ì¡±
- **Recall ì €í•˜**ì— ê¸°ì—¬

### 3.3 Collate Function

```yaml
shrink_ratio: 0.4    # Text shrinkage for probability map
thresh_min: 0.3
thresh_max: 0.7
```

**íŠ¹ì§•:**
- âœ… DBNet í‘œì¤€ íŒŒë¼ë¯¸í„° ì‚¬ìš©
- âš ï¸ `shrink_ratio: 0.4`ëŠ” ì¤‘ê°„ê°’ (0.3~0.5 ë²”ìœ„ ì‹¤í—˜ ê°€ëŠ¥)

---

## ğŸ”¥ 4. ì†ì‹¤ í•¨ìˆ˜ ë¶„ì„

```yaml
DBLoss:
  negative_ratio: 3.0              # Hard negative mining
  prob_map_loss_weight: 5.0        # ğŸ”´
  thresh_map_loss_weight: 10.0     # ğŸ”´
  binary_map_loss_weight: 1.0      # ğŸ”´
```

**êµ¬ì„±:**
- **Probability Map Loss**: BCE Loss (binary text/non-text)
- **Threshold Map Loss**: L1 Loss (adaptive threshold)
- **Binary Map Loss**: Dice Loss (differentiable binarization)

**ê°€ì¤‘ì¹˜ ë¹„ìœ¨:**
```
Prob : Thresh : Binary = 5 : 10 : 1
```

**í‰ê°€:**
- âœ… **Threshold mapì— ë†’ì€ ê°€ì¤‘ì¹˜**: DBNet ë…¼ë¬¸ê³¼ ì¼ì¹˜
- âš ï¸ **Binary map ê°€ì¤‘ì¹˜ê°€ ë‚®ìŒ**: ìµœì¢… ê²€ì¶œ ì„±ëŠ¥ì— ì§ì ‘ì  ì˜í–¥
- ğŸ’¡ **ì œì•ˆ**: `binary_map_loss_weight: 2.0~3.0`ìœ¼ë¡œ ì¦ê°€ ì‹¤í—˜

---

## âš™ï¸ 5. í•™ìŠµ ì„¤ì • ë¶„ì„

### 5.1 Optimizer & Scheduler

```yaml
optimizer:
  _target_: torch.optim.Adam
  lr: 0.001                    # ğŸ”´ Learning rate
  weight_decay: 0.0001

scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 100               # âš ï¸ ë„ˆë¬´ í¼
  gamma: 0.1
```

**ë¬¸ì œì :**
- âš ï¸ **`step_size: 100`**: 10 epoch í•™ìŠµì—ì„œëŠ” ì‘ë™ ì•ˆ í•¨
  - Stepì´ í•œ ë²ˆë„ ë°œë™ë˜ì§€ ì•ŠìŒ
- âš ï¸ **StepLR**: êµ¬ì‹ ìŠ¤ì¼€ì¤„ëŸ¬
- ğŸ’¡ **ì œì•ˆ**: 
  - `CosineAnnealingLR`, `ReduceLROnPlateau` ì‚¬ìš©
  - `step_size: 3~5`ë¡œ ì¡°ì •

### 5.2 Training Config

```yaml
trainer:
  max_epochs: 10                # ğŸ”´ ë„ˆë¬´ ì§§ìŒ
  batch_size: 16
  num_workers: 4
```

**í‰ê°€:**
- âš ï¸ **10 epochs**: DBNetì€ ì¼ë°˜ì ìœ¼ë¡œ 300~1200 epochs í•„ìš”
- âš ï¸ **batch_size: 16**: ë©”ëª¨ë¦¬ ì—¬ìœ  ìˆìœ¼ë©´ ì¦ê°€ ê°€ëŠ¥
- ğŸ’¡ **ì œì•ˆ**: ìµœì†Œ 50~100 epochs

---

## ğŸ¯ 6. Postprocessing íŒŒë¼ë¯¸í„° ì˜í–¥ ë¶„ì„

### í˜„ì¬ ì„¤ì •ì˜ ë™ì‘ ì›ë¦¬

```python
# db_postprocess.py
thresh: 0.3          # Probability mapì„ 0.3 ê¸°ì¤€ìœ¼ë¡œ ì´ì§„í™”
box_thresh: 0.4      # ë°•ìŠ¤ ì‹ ë¢°ë„ 0.4 ì´ìƒë§Œ ì±„íƒ
max_candidates: 300  # ìµœëŒ€ 300ê°œ í›„ë³´
```

**Recall ì €í•˜ ì‹œë‚˜ë¦¬ì˜¤:**
1. ëª¨ë¸ì´ ì‘ì€/íšŒì „ëœ í…ìŠ¤íŠ¸ì— ëŒ€í•´ 0.35 ì‹ ë¢°ë„ë¡œ ì˜ˆì¸¡
2. `box_thresh: 0.4` ê¸°ì¤€ ë¯¸ë‹¬ë¡œ **ì œê±°ë¨**
3. ê²°ê³¼: False Negative ì¦ê°€ â†’ **Recall í•˜ë½**

**ê°œì„  ë°©í–¥:**
```yaml
postprocess:
  thresh: 0.25           # 0.3 â†’ 0.25 (ë” ë¯¼ê°í•˜ê²Œ)
  box_thresh: 0.3        # 0.4 â†’ 0.3 (ì„ê³„ê°’ ì™„í™”)
  max_candidates: 500    # 300 â†’ 500 (ë” ë§ì€ í›„ë³´)
```

---

## ğŸ“ˆ 7. ì„±ëŠ¥ ë³‘ëª© ìš”ì¸ ìš°ì„ ìˆœìœ„

### ğŸ”´ Critical (ì¦‰ì‹œ ê°œì„  í•„ìš”)

1. **`box_thresh: 0.4 â†’ 0.3`**: Recall ì¦‰ì‹œ ìƒìŠ¹ ì˜ˆìƒ
2. **Scheduler ìˆ˜ì •**: `step_size: 100 â†’ 3~5`
3. **Epochs ì¦ê°€**: `10 â†’ 50+`

### ğŸŸ¡ High Impact (ì¤‘ìš”)

4. **Data Augmentation ì¶”ê°€**: 
   - Rotation, Brightness, Scale ë³€í™˜
5. **ì´ë¯¸ì§€ í•´ìƒë„ ì¦ê°€**: `640 â†’ 800`
6. **Binary map loss ê°€ì¤‘ì¹˜**: `1.0 â†’ 2.0`

### ğŸŸ¢ Medium Impact (ì‹¤í—˜ ê°€ì¹˜)

7. **Backbone ì—…ê·¸ë ˆì´ë“œ**: ResNet18 â†’ ResNet34/50
8. **Optimizer ë³€ê²½**: Adam â†’ AdamW
9. **Shrink ratio ì¡°ì •**: 0.4 â†’ 0.3

---

## ğŸ’¡ 8. ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ Quick Wins

### Phase 1: Postprocessing ì¡°ì • (ì¬í•™ìŠµ ë¶ˆí•„ìš”)

**íŒŒì¼**: `configs/preset/models/head/db_head.yaml`

```yaml
postprocess:
  thresh: 0.25           # â¬‡ï¸ 0.3 â†’ 0.25
  box_thresh: 0.3        # â¬‡ï¸ 0.4 â†’ 0.3
  max_candidates: 500    # â¬†ï¸ 300 â†’ 500
```

**ì˜ˆìƒ íš¨ê³¼:** Recall +2~5%, Precision -1~2%, H-Mean +1~3%

### Phase 2: Scheduler ìˆ˜ì •

**íŒŒì¼**: `configs/preset/models/model_example.yaml`

```yaml
scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  T_max: 10              # max_epochsì™€ ë™ì¼
  eta_min: 0.00001
```

### Phase 3: Augmentation ì¶”ê°€

**íŒŒì¼**: `configs/preset/datasets/db.yaml`

```yaml
train_transform:
  transforms:
    - _target_: albumentations.LongestMaxSize
      max_size: 640
    - _target_: albumentations.PadIfNeeded
      min_width: 640
      min_height: 640
    # ğŸ†• ì¶”ê°€
    - _target_: albumentations.Rotate
      limit: 10
      p: 0.5
    - _target_: albumentations.RandomBrightnessContrast
      brightness_limit: 0.2
      contrast_limit: 0.2
      p: 0.5
    - _target_: albumentations.GaussNoise
      p: 0.3
    - _target_: albumentations.HorizontalFlip
      p: 0.5
    - _target_: albumentations.Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
```

---

## ğŸ“Š 9. ì˜ˆìƒ ì„±ëŠ¥ ê°œì„  ë¡œë“œë§µ

| ë‹¨ê³„ | ì¡°ì¹˜ | ì˜ˆìƒ Recall | ì˜ˆìƒ Precision | ì˜ˆìƒ H-Mean |
|------|------|-------------|----------------|-------------|
| **Baseline** | - | **0.8194** | **0.9651** | **0.8818** |
| **Step 1** | box_thresh ì¡°ì • | 0.845 (+3%) | 0.950 (-1.5%) | 0.895 (+1.3%) |
| **Step 2** | Augmentation ì¶”ê°€ | 0.860 (+5%) | 0.945 (-2%) | 0.901 (+2%) |
| **Step 3** | Epochs 50 + Scheduler | 0.880 (+7.4%) | 0.940 (-2.6%) | 0.909 (+3%) |
| **Step 4** | Image size 800 | 0.895 (+9.2%) | 0.935 (-3.1%) | 0.915 (+3.7%) |
| **Step 5** | Backbone ì—…ê·¸ë ˆì´ë“œ | 0.910 (+11%) | 0.930 (-3.6%) | 0.920 (+4.2%) |

---

## ğŸ“ 10. ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

### ê°•ì 

âœ… DBNet ì•„í‚¤í…ì²˜ êµ¬í˜„ ì™„ì„±ë„ ë†’ìŒ  
âœ… Hydra ê¸°ë°˜ ì„¤ì • ê´€ë¦¬ë¡œ ì‹¤í—˜ ìš©ì´  
âœ… CLEval í‰ê°€ ì²´ê³„ ì˜ êµ¬ì¶•ë¨  
âœ… ë†’ì€ Precision â†’ False Positive ì ìŒ  

### ì•½ì 

âŒ **Recall ë¶€ì¡±** (18% ë¯¸íƒì§€)  
âŒ Data Augmentation ê±°ì˜ ì—†ìŒ  
âŒ Schedulerê°€ 10 epochì—ì„œ ì‘ë™ ì•ˆ í•¨  
âŒ Postprocessing thresholdê°€ ë„ˆë¬´ ë³´ìˆ˜ì   
âŒ í•™ìŠµ epochs ë¶€ì¡± (10 vs ê¶Œì¥ 300+)  

### ìµœìš°ì„  ê°œì„  í•­ëª©

1. **`box_thresh: 0.4 â†’ 0.3`** (5ë¶„ ì‘ì—…, ì¦‰ì‹œ íš¨ê³¼)
2. **Scheduler ìˆ˜ì •** (CosineAnnealingìœ¼ë¡œ ë³€ê²½)
3. **Augmentation ì¶”ê°€** (Rotate, Brightness, Scale)
4. **Epochs ì¦ê°€** (50~100 epochs)

### ì¥ê¸° ê°œì„  ë°©í–¥

- Backbone ì—…ê·¸ë ˆì´ë“œ (ResNet34/50, EfficientNet)
- Pseudo labeling í™œìš© (data/pseudo_label í™œìš©)
- Multi-scale training/inference
- Ensemble ì „ëµ

---

## ğŸ“ ìƒì„¸ ì½”ë“œ ë¶„ì„

### ì£¼ìš” íŒŒì¼ ê²½ë¡œ

```
baseline_code/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ train.yaml                          # í•™ìŠµ ì„¤ì •
â”‚   â”œâ”€â”€ test.yaml                           # í…ŒìŠ¤íŠ¸ ì„¤ì •
â”‚   â”œâ”€â”€ predict.yaml                        # ì˜ˆì¸¡ ì„¤ì •
â”‚   â””â”€â”€ preset/
â”‚       â”œâ”€â”€ datasets/db.yaml                # ë°ì´í„°ì…‹ & Transform
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ model_example.yaml          # Optimizer & Scheduler
â”‚       â”‚   â”œâ”€â”€ encoder/timm_backbone.yaml  # ResNet18
â”‚       â”‚   â”œâ”€â”€ decoder/unet.yaml           # UNet Decoder
â”‚       â”‚   â”œâ”€â”€ head/db_head.yaml           # DBHead & Postprocess
â”‚       â”‚   â””â”€â”€ loss/db_loss.yaml           # DBLoss
â”‚       â””â”€â”€ lightning_modules/base.yaml     # Lightning ì„¤ì •
â”œâ”€â”€ ocr/
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”œâ”€â”€ base.py                         # OCRDataset
â”‚   â”‚   â”œâ”€â”€ db_collate_fn.py                # Ground truth map ìƒì„±
â”‚   â”‚   â””â”€â”€ transforms.py                   # Albumentations wrapper
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ architecture.py                 # OCRModel (ì „ì²´ íŒŒì´í”„ë¼ì¸)
â”‚   â”‚   â”œâ”€â”€ encoder/timm_backbone.py        # TimmBackbone
â”‚   â”‚   â”œâ”€â”€ decoder/unet.py                 # UNet
â”‚   â”‚   â”œâ”€â”€ head/
â”‚   â”‚   â”‚   â”œâ”€â”€ db_head.py                  # DBHead
â”‚   â”‚   â”‚   â””â”€â”€ db_postprocess.py           # í›„ì²˜ë¦¬ (ë°•ìŠ¤ ì¶”ì¶œ)
â”‚   â”‚   â””â”€â”€ loss/
â”‚   â”‚       â”œâ”€â”€ db_loss.py                  # DBLoss
â”‚   â”‚       â”œâ”€â”€ bce_loss.py                 # BCE Loss
â”‚   â”‚       â”œâ”€â”€ dice_loss.py                # Dice Loss
â”‚   â”‚       â””â”€â”€ l1_loss.py                  # L1 Loss
â”‚   â”œâ”€â”€ lightning_modules/
â”‚   â”‚   â””â”€â”€ ocr_pl.py                       # Lightning Module
â”‚   â””â”€â”€ metrics/
â”‚       â””â”€â”€ cleval_metric.py                # CLEval í‰ê°€
â””â”€â”€ runners/
    â”œâ”€â”€ train.py                            # í•™ìŠµ ì‹¤í–‰
    â”œâ”€â”€ test.py                             # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    â””â”€â”€ predict.py                          # ì˜ˆì¸¡ ì‹¤í–‰
```

---

## ğŸ”¬ ì¶”ê°€ ì‹¤í—˜ ì•„ì´ë””ì–´

### 1. Multi-scale Training
- ë‹¤ì–‘í•œ ì´ë¯¸ì§€ í¬ê¸°ë¡œ í•™ìŠµ (640, 800, 1024)
- Validationì€ ê³ ì • í¬ê¸°ë¡œ í‰ê°€

### 2. Test Time Augmentation (TTA)
- Horizontal flip
- Multi-scale inference
- ê²°ê³¼ ì•™ìƒë¸”

### 3. Pseudo Labeling í™œìš©
```
data/pseudo_label/
â”œâ”€â”€ cord-v2/
â”œâ”€â”€ sroie/
â””â”€â”€ wildreceipt/
```
- ì™¸ë¶€ ë°ì´í„°ì…‹ í™œìš©í•˜ì—¬ ì‚¬ì „ í•™ìŠµ
- Fine-tuning on target dataset

### 4. Loss Function ì‹¤í—˜
- Focal Loss ì¶”ê°€
- IoU Loss ì¶”ê°€
- Weighted combination

### 5. Backbone Ablation Study
- ResNet34, ResNet50
- EfficientNet-B0, B1, B2
- ConvNeXt-Tiny
- MobileNetV3

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ë…¼ë¬¸
- **DBNet**: [Real-time Scene Text Detection with Differentiable Binarization](https://arxiv.org/pdf/1911.08947.pdf)
- **CLEval**: [Character-Level Evaluation for Text Detection](https://github.com/clovaai/CLEval)

### êµ¬í˜„ ì°¸ì¡°
- [MhLiao/DB](https://github.com/MhLiao/DB/) - ê³µì‹ DBNet êµ¬í˜„

---

**ë³´ê³ ì„œ ì‘ì„±ì¼**: 2026ë…„ 1ì›” 29ì¼  
**ë¶„ì„ ëŒ€ìƒ**: baseline_code (10 epochs í•™ìŠµ ê²°ê³¼)  
**í˜„ì¬ ì„±ëŠ¥**: H-Mean 0.8818, Precision 0.9651, Recall 0.8194  

---

**í˜„ì¬ ì½”ë“œëŠ” ê²¬ê³ í•œ ê¸°ë°˜ì„ ê°–ì¶”ì—ˆìœ¼ë‚˜, Recall ê°œì„ ì— ì§‘ì¤‘í•œ íŒŒë¼ë¯¸í„° íŠœë‹ê³¼ Data Augmentationì´ ê¸‰ì„ ë¬´ì…ë‹ˆë‹¤.**
