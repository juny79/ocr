# K-Fold 앙상블 심화 분석 보고서 (v3)

**작성일**: 2026. 01. 31  
**작성자**: GitHub Copilot  
**기반 문서**: [4_kfold_analysis_report.md](4_kfold_analysis_report.md)

---

## 1. 실험 개요: "Trade-off의 탐색"

본 보고서는 K-Fold 앙상블의 필터링 강도를 **"다수결 투표(Votes ≥ 2)"**에서 **"과반수 투표(Votes ≥ 3)"**로 강화했을 때의 성능 변화를 집중 분석합니다. 
(5-Fold 기준, 3표는 단순 과반수이자 엄격한 기준에 해당합니다.)

### 1.1 성능 비교 (Leaderboard)

| 지표 (Metric) | v2 (Votes ≥ 2) | **v3 (Votes ≥ 3)** | 증감 (Delta) | 판단 |
| :--- | :---: | :---: | :---: | :---: |
| **H-Mean** | 0.9176 | **0.9247** | **+0.0071 (▲)** | **최고점 갱신** |
| **Precision** | 0.9174 | **0.9510** | **+0.0336 (▲)** | **압도적 성능** |
| **Recall** | 0.9212 | **0.9035** | -0.0177 (▼) | 예상된 하락 |

---

## 2. 결과 심층 분석

### 2.1 정밀도(Precision) 95% 돌파의 의미
*   **"신뢰할 수 있는 모델"**: 모델이 "이건 글자야!"라고 찍으면 **95.1% 확률로 정답**이라는 의미입니다. 이는 실무적으로 매우 가치 있는 결과입니다.
*   **노이즈의 완전한 제거**: K-Fold 학습의 다양성(Diversity) 때문에 발생했던 미세한 동의하지 않는 예측(Disagreement)들이 `Votes ≥ 3` 필터를 거치며 완벽에 가깝게 제거되었습니다.

### 2.2 재현율(Recall) 하락의 원인
*   **"Hard Sample의 탈락"**: 5개의 모델 중 1~2개 모델만 겨우 찾아낸(Votes < 3) **어렵고 희미한 글자들**이 최종 결과에서 제외되었습니다. 이는 엄격한 기준(Strict Majority)이 가져온 자연스러운 반작용(Trade-off)입니다.
*   **방어 전략**: Recall이 90%대로 방어된 것은 다행이나, 0.92(v2) 대비 하락폭이 작지 않습니다. 이를 보완할 방법이 필요합니다.

### 2.3 종합 평가 (H-Mean)
*   일반적인 F1-Score(H-Mean)는 Precision과 Recall의 조화평균이므로, **Precision의 상승폭(+3.3%)이 Recall의 하락폭(-1.7%)을 압도**하여 최종 점수가 상승했습니다.
*   현재 대회/평가 메트릭에서는 **"틀린 것을 뱉지 않는 것(High Precision)"**이 점수 향상에 더 유리하게 작용하고 있습니다.

---

## 3. 최종 제언 및 개선 로드맵

현재까지의 실험으로 우리는 **"High Precision(v3)"**과 **"High Recall(v2)"**이라는 두 가지 강력한 무기를 모두 손에 넣었습니다. 남은 과제는 **떨어진 Recall을 다시 끌어올리는 것**입니다.

### [Step 1: 앙상블 전략 확정]
*   **Winner**: **`Votes ≥ 3` (v3 모델)**
*   이유: H-Mean 점수가 가장 높으며, 고정밀도 모델을 베이스로 Recall을 채워 넣는 것이 반대의 경우보다 쉽습니다.

### [Step 2: Recall 복구 전략]
위 분석에 따라, 다음 단계는 **"정밀도를 유지하며 Recall만 올리는 방법"**에 집중해야 합니다.

1.  **Soft Voting 도입 (추천)**:
    *   현재는 단순히 "박스 개수(Hard Voting)"로만 투표합니다.
    *   개수는 2개(Votes=2)라서 탈락했지만, 모델의 **확신도(Score)**가 매우 높은(예: 0.99) 박스라면 살려주는 **"구제 조건"**을 추가할 수 있습니다.
    *   *예: (Votes ≥ 3) OR (Votes == 2 AND Mean_Score > 0.95)*

2.  **TTA (Test Time Augmentation)**:
    *   이미지를 확대(Scale Up)하여 추론하면 작은 글씨들이 더 잘 보입니다. 이를 앙상블에 포함시키면, 2표를 받아 탈락했던 작은 글씨들이 3표 이상을 받아 부활할 수 있습니다.

3.  **후처리 파라미터 완화**:
    *   Precision이 충분히 높으므로(0.95), `box_thresh`를 `0.5` -> `0.4` 정도로 낮추어 박스 후보를 더 많이 생성하게 합니다.

---

## 4. 결론

> **"엄격함이 승리했다. 하지만 조금 더 유연해질 필요가 있다."**

과반수 투표(Votes ≥ 3) 전략은 **H-Mean 0.9247**이라는 훌륭한 성과를 달성했습니다. 이제 **0.93의 벽**을 넘기 위해서는, 엄격함 속에 숨겨진 "진짜 정답(Hard Positives)"들을 섬세하게 골라내는 고급 앙상블/후처리 기법이 필요합니다.
