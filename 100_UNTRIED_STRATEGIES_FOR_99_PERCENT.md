# ë¯¸ì‹œë„ ì „ëµ ì¢…í•© ë³´ê³ ì„œ: 98.63% â†’ 99%+ ë‹¬ì„± ë¡œë“œë§µ

**ì‘ì„±ì¼**: 2026-02-13 (v2.0 ì—…ë°ì´íŠ¸)  
**í˜„ì¬ ìµœê³  ì ìˆ˜**: H-Mean **98.63%** (HRNet-W44 1024px + External Data + K-Fold Fold3)  
**ìµœì¢… ëª©í‘œ**: H-Mean **99.0%+** ë‹¬ì„±  
**ë¶„ì„ ê¸°ê°„**: 00~56ë²ˆ ë³´ê³ ì„œ ë¶„ì„ + ì¶”ê°€ ì „ëµ 4ê°œ í†µí•©  
**ğŸ†• v2.0 ì‹ ê·œ ì¶”ê°€**: Tiny Box Loss, 13K Pre-training, 2ë‹¨ê³„ í•™ìŠµ, P2 FPN  

---

## ğŸ“Š Executive Summary

### í˜„ì¬ ìƒí™©
- **ë‹¬ì„±í•œ ê°œì„ **: 88.18% â†’ 98.63% (+10.45%p)
- **ì‹¤í–‰ëœ 6ë‹¨ê³„ ëª¨ë©˜í…€**:
  1. í›„ì²˜ë¦¬ ì¡°ì • (+4.30%p)
  2. ResNet18 â†’ ResNet50 (+3.72%p)
  3. Grid Search (+0.33%p)
  4. HRNet-W44 1280px (+1.27%p)
  5. ì™¸ë¶€ ë°ì´í„° SROIE+CORD-v2 (+0.74%p)
  6. K-Fold Fold3 ì„ íƒ (+0.09%p)

### ë¯¸ì‹œë„ ì „ëµ ê°œìš”
**ì´ 25ê°œ ì „ëµ ì‹ë³„** (ê¸°ì¡´ 21ê°œ + ì‹ ê·œ 4ê°œ), 5ê°œ ìš°ì„ ìˆœìœ„ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜:
- ğŸ”¥ **Tier 1 (ì¦‰ì‹œ ì‹¤í–‰)**: 4ê°œ ì „ëµ, ì˜ˆìƒ +0.6~1.2%p â­ **ì‹ ê·œ 1ê°œ ì¶”ê°€**
- â­ **Tier 2 (ê³ íš¨ê³¼ ì¤‘ê¸°)**: 8ê°œ ì „ëµ, ì˜ˆìƒ +0.8~2.0%p â­ **ì‹ ê·œ 3ê°œ ì¶”ê°€**
- ğŸ’¡ **Tier 3 (ì‹¤í—˜ì  ì¥ê¸°)**: 6ê°œ ì „ëµ, ì˜ˆìƒ +0.3~0.7%p
- âš ï¸ **Tier 4 (ê³ ìœ„í—˜)**: 4ê°œ ì „ëµ, íš¨ê³¼ ë¶ˆí™•ì‹¤
- âŒ **Tier 5 (ë¹„ì¶”ì²œ)**: 3ê°œ ì „ëµ, ì‹¤íŒ¨ ê°€ëŠ¥ì„± ë†’ìŒ

### ğŸ†• ì‹ ê·œ ì¶”ê°€ ì „ëµ (BREAKTHROUGH ì ì¬ë ¥)
1. **Tiny Box Loss ê°€ì¤‘ì¹˜ ë¶€ì—¬** (Tier 1) - ì—ëŸ¬ ì¼€ì´ìŠ¤ ì§ì ‘ íƒ€ê²Ÿ, +0.4~0.7%p
2. **ëŒ€ê·œëª¨ ì™¸ë¶€ ë°ì´í„° Pre-training** (Tier 2) - 13,000ì¥ í†µí•©, +0.8~1.2%p
3. **2ë‹¨ê³„ í•™ìŠµ íŒŒì´í”„ë¼ì¸** (Tier 2) - Curriculum Learning, +0.3~0.6%p
4. **P2 Feature Pyramid ë ˆë²¨ ì¶”ê°€** (Tier 2) - ë¯¸ì„¸ í…ìŠ¤íŠ¸ ê°•í™”, +0.2~0.5%p

---

## ğŸ¯ Part 1: Tier 1 ì „ëµ - ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥ (0~2ì¼)

### 1ï¸âƒ£ Unclip Ratio ìµœì í™” â­â­â­â­â­

**í˜„ì¬ ìƒíƒœ**: ê³ ì •ê°’ 2.0 ì‚¬ìš© (ê¸°ë³¸ê°’)  
**ë¬¸ì œì **: ëª¨ë“  í…ìŠ¤íŠ¸ í¬ê¸°ì— ë™ì¼í•œ í™•ì¥ ë¹„ìœ¨ ì ìš©  
**ì˜ˆìƒ ê°œì„ **: +0.2~0.4%p | **ì†Œìš” ì‹œê°„**: 10ë¶„ | **ë‚œì´ë„**: â­

#### ë°°ê²½ ì§€ì‹
```
Unclip Ratio: DBNetì—ì„œ ì¶•ì†Œëœ í…ìŠ¤íŠ¸ ì˜ì—­ì„ ì›ë˜ í¬ê¸°ë¡œ í™•ì¥í•˜ëŠ” ë¹„ìœ¨

ê³¼ì •:
  1. DBNetì´ í…ìŠ¤íŠ¸ ì¤‘ì‹¬ë¶€ë§Œ ê²€ì¶œ (ì¶•ì†Œëœ ì˜ì—­)
  2. Unclipìœ¼ë¡œ í™•ì¥í•˜ì—¬ ì „ì²´ í…ìŠ¤íŠ¸ ì»¤ë²„
  3. ë¹„ìœ¨ì´ ì‘ìœ¼ë©´: í…ìŠ¤íŠ¸ ì¼ë¶€ë§Œ í¬í•¨ (Recall â†“)
  4. ë¹„ìœ¨ì´ í¬ë©´: ë°°ê²½ê¹Œì§€ í¬í•¨ (Precision â†“)
```

#### ì‹¤í–‰ ì „ëµ
```yaml
# íƒìƒ‰ ë²”ìœ„
unclip_ratio_candidates: [1.85, 1.90, 1.95, 2.00, 2.05, 2.10, 2.15]

# Grid Search
for ratio in candidates:
    predictions = predict_with_ratio(val_set, ratio)
    hmean = evaluate(predictions, val_gt)
    if hmean > best_hmean:
        best_ratio = ratio
```

#### ì˜ˆìƒ ê²°ê³¼
```
ìµœì  ë¹„ìœ¨ ë°œê²¬ ì‹œ:
  Before: H=98.63%, unclip_ratio=2.00
  After:  H=98.8~99.0%, unclip_ratio=1.95~2.05
  
ì—ëŸ¬ ë¶„ì„ ê¸°ë°˜ ì˜ˆìƒ:
  - ì‘ì€ ë°•ìŠ¤ (ë©´ì  <40pxÂ²): ratio â†‘ (2.05~2.10)
  - í° ë°•ìŠ¤ (ë©´ì  >5000pxÂ²): ratio â†“ (1.90~1.95)
```

#### ì‹¤í–‰ ëª…ë ¹ì–´
```bash
cd /data/ephemeral/home/baseline_code

# Validation set Grid Search
python scripts/optimize_unclip_ratio.py \
  --checkpoint checkpoints/kfold/fold_3/fold3_best.ckpt \
  --val_json kfold_results/fold_3/val.json \
  --ratio_range 1.85 2.15 \
  --step 0.05
```

---

### 2ï¸âƒ£ ğŸ†• Tiny Box Loss ê°€ì¤‘ì¹˜ ë¶€ì—¬ (Small Object íŠ¹í™”) â­â­â­â­â­

**í˜„ì¬ ìƒíƒœ**: ëª¨ë“  ë°•ìŠ¤ì— ë™ì¼í•œ Loss ê°€ì¤‘ì¹˜ ì ìš©  
**ë¬¸ì œì **: 20pxÂ² ìµœì†Œ ë°•ìŠ¤ ê²€ì¶œ ì‹¤íŒ¨ (56_ERROR_ANALYSIS í™•ì¸)  
**ì˜ˆìƒ ê°œì„ **: +0.4~0.7%p | **ì†Œìš” ì‹œê°„**: 2ì‹œê°„ | **ë‚œì´ë„**: â­â­â­

#### ì—ëŸ¬ ì¼€ì´ìŠ¤ ê¸°ë°˜ í•„ìš”ì„±
```
56_ERROR_ANALYSIS ë°œê²¬:
  ì†Œí˜• ë°•ìŠ¤ ì¹´í…Œê³ ë¦¬ (20ê°œ ì´ë¯¸ì§€):
    - ìµœì†Œ ë°•ìŠ¤ ë©´ì : 20pxÂ² (selectstar_000525.jpg)
    - í‰ê·  ìµœì†Œ ë°•ìŠ¤: 30pxÂ²
    - ê²€ì¶œ ì‹¤íŒ¨ ìœ„í—˜: ë§¤ìš° ë†’ìŒ
  
í˜„ì¬ ëª¨ë¸ íŠ¹ì„±:
  - í° ë°•ìŠ¤ (>1000pxÂ²): Recall 99.5%
  - ì‘ì€ ë°•ìŠ¤ (<100pxÂ²): Recall 95~97% (ì¶”ì •)
  â†’ ì‘ì€ ë°•ìŠ¤ê°€ ì„±ëŠ¥ ë³‘ëª©
```

#### Focal Loss ë³€í˜• ì „ëµ
```python
# ë°•ìŠ¤ í¬ê¸°ë³„ Loss ê°€ì¤‘ì¹˜
def get_loss_weight(box_area):
    if box_area < 50:
        return 10.0   # ì´ˆì†Œí˜• (ê·¹í•œ ê°€ì¤‘ì¹˜)
    elif box_area < 100:
        return 5.0    # ì†Œí˜•
    elif box_area < 200:
        return 2.0    # ì¤‘ì†Œí˜•
    else:
        return 1.0    # í‘œì¤€

# DBNet Loss ìˆ˜ì •
class DBLossWeighted(nn.Module):
    def forward(self, pred, gt, boxes):
        weights = torch.tensor([get_loss_weight(box.area()) for box in boxes])
        
        # Probability Map Loss (ê°€ì¤‘ì¹˜ ì ìš©)
        prob_loss = F.binary_cross_entropy(
            pred['probability_map'], 
            gt['probability_map'],
            weight=weights  # ì‘ì€ ë°•ìŠ¤ ì˜ì—­ì— ë†’ì€ ê°€ì¤‘ì¹˜
        )
        
        # Threshold Map Loss (ë™ì¼ ê°€ì¤‘ì¹˜)
        thresh_loss = ...
        
        return prob_loss + thresh_loss
```

#### ê¸°ëŒ€ íš¨ê³¼
```
ì‘ì€ ë°•ìŠ¤ ê²€ì¶œ ê°œì„ :
  Before: 100pxÂ² ì´í•˜ Recall 95%
  After:  100pxÂ² ì´í•˜ Recall 98~99%
  
ì „ì²´ ì„±ëŠ¥:
  ì†Œí˜• ë°•ìŠ¤ ë¹„ìœ¨: ì „ì²´ì˜ ì•½ 15~20%
  ê°œì„  ê¸°ì—¬: Recall +0.4~0.6%p
  H-Mean: +0.4~0.7%p
```

#### ì‹¤í–‰ ë°©ë²•
```python
# ocr/models/loss/db_loss_weighted.py ìƒì„±
class DBLossWeighted(DBLoss):
    def __init__(self, alpha=5.0, beta=10.0, negative_ratio=3.0):
        super().__init__(alpha, beta, negative_ratio)
        self.tiny_threshold = 50   # ì´ˆì†Œí˜• ê¸°ì¤€
        self.small_threshold = 100 # ì†Œí˜• ê¸°ì¤€
        self.tiny_weight = 10.0
        self.small_weight = 5.0
    
    def compute_area_weights(self, gt_boxes):
        areas = [box['area'] for box in gt_boxes]
        weights = []
        for area in areas:
            if area < self.tiny_threshold:
                weights.append(self.tiny_weight)
            elif area < self.small_threshold:
                weights.append(self.small_weight)
            else:
                weights.append(1.0)
        return torch.tensor(weights)

# configs/preset/models/loss/db_loss_weighted.yaml
loss:
  name: DBLossWeighted
  alpha: 5.0
  beta: 10.0
  tiny_threshold: 50
  small_threshold: 100
  tiny_weight: 10.0
  small_weight: 5.0
```

#### ì‹¤í–‰ ëª…ë ¹ì–´
```bash
cd /data/ephemeral/home/baseline_code

# Loss í´ë˜ìŠ¤ êµ¬í˜„ (1ì‹œê°„)
# ìœ„ ì½”ë“œë¥¼ ocr/models/loss/db_loss_weighted.pyì— ì‘ì„±

# ì¬í›ˆë ¨ (1ì‹œê°„, Fold 3ë§Œ)
python runners/train.py \
    preset=hrnet_w44_1024_external_weighted_loss \
    model.loss.name=DBLossWeighted \
    model.loss.tiny_weight=10.0 \
    model.loss.small_weight=5.0 \
    ++datasets.train_dataset.annotation_path=train_augmented_full.json \
    ++datasets.val_dataset.annotation_path=kfold_results/fold_3/val.json \
    exp_name=hrnet_w44_tiny_box_weighted \
    trainer.max_epochs=10  # Fine-tuning
```

---

### 3ï¸âƒ£ WildReceipt ì™¸ë¶€ ë°ì´í„° ì¶”ê°€ â­â­â­â­

**í˜„ì¬ ìƒíƒœ**: SROIE (626ì¥) + CORD-v2 (800ì¥) ì‚¬ìš©, WildReceipt ë¯¸ì‚¬ìš©  
**ì˜ˆìƒ ê°œì„ **: +0.3~0.5%p | **ì†Œìš” ì‹œê°„**: 3ì‹œê°„ | **ë‚œì´ë„**: â­â­

#### ë°ì´í„° íŠ¹ì„± ë¹„êµ
```
í˜„ì¬ ë°ì´í„°:
  ê¸°ë³¸ ë°ì´í„°: 3,272ì¥ (100%)
  + SROIE:      626ì¥ (+19.1%, ë¹½ë¹½í•œ ì˜ìˆ˜ì¦)
  + CORD-v2:    800ì¥ (+24.4%, í•œê¸€ ë³µì¡ ë ˆì´ì•„ì›ƒ)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ì´ê³„:       4,698ì¥ (+43.6%)

ì¶”ê°€ ê°€ëŠ¥:
  + WildReceipt: 1,300ì¥ (+39.7%, êµ¬ê²¨ì§„/íœ˜ì–´ì§„ ì˜ìˆ˜ì¦)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ìµœì¢…:         5,998ì¥ (+83.3%)
```

#### ê¸°ëŒ€ íš¨ê³¼
```
SROIE+CORD ê¸°ì—¬ë„: +0.71%p (from 97.8% â†’ 98.51%)

WildReceipt ì¶”ê°€ ì‹œ:
  - êµ¬ê²¨ì§„ ì˜ìˆ˜ì¦ ëŒ€ì‘ë ¥ í–¥ìƒ (ì—ëŸ¬ ì¼€ì´ìŠ¤ ëŒ€ì‘)
  - ê·¹ë‹¨ì  ì¢…íš¡ë¹„ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ê°œì„ 
  - ì˜ˆìƒ ê¸°ì—¬: +0.3~0.5%p
```

#### ì‹¤í–‰ ëª…ë ¹ì–´
```bash
# 1. WildReceipt ë‹¤ìš´ë¡œë“œ (5ë¶„)
cd /data/ephemeral/home/data/pseudo_label
git clone https://github.com/clovaai/wildreceipt.git

# 2. í¬ë§· ë³€í™˜ (10ë¶„)
cd /data/ephemeral/home/baseline_code
python scripts/convert_wildreceipt.py \
  --input /data/ephemeral/home/data/pseudo_label/wildreceipt \
  --output /data/ephemeral/home/data/datasets/wildreceipt_converted.json

# 3. ë°ì´í„° ë³‘í•© (5ë¶„)
python scripts/merge_datasets.py \
  --inputs train_augmented_full.json wildreceipt_converted.json \
  --output train_augmented_wildreceipt.json

# 4. ì¬í›ˆë ¨ (2.5ì‹œê°„)
python runners/train.py \
    preset=hrnet_w44_1024_external \
    ++datasets.train_dataset.annotation_path=train_augmented_wildreceipt.json \
    exp_name=hrnet_w44_wildreceipt \
    trainer.max_epochs=18
```

---

### 4ï¸âƒ£ í›„ì²˜ë¦¬ ì´ˆë¯¸ì„¸ ì¡°ì • (0.215 â†’ 0.210~0.220 ë²”ìœ„) â­â­â­â­

**í˜„ì¬ ìƒíƒœ**: thresh=0.215, box_thresh=0.415 (48_comprehensive ìµœì ê°’)  
**ì˜ˆìƒ ê°œì„ **: +0.05~0.15%p | **ì†Œìš” ì‹œê°„**: 5ë¶„ | **ë‚œì´ë„**: â­

#### ì—ëŸ¬ ë¶„ì„ ê¸°ë°˜ ì¡°ì •
```
56_ERROR_ANALYSIS_REPORT.md ë°œê²¬ì‚¬í•­:
  - ê³ ë°€ë„ ì´ë¯¸ì§€ (538 boxes/Mpx): Recall ì†ì‹¤ ìœ„í—˜
  - ì†Œí˜• ë°•ìŠ¤ (20pxÂ² ìµœì†Œ): ê²€ì¶œ ì‹¤íŒ¨ ê°€ëŠ¥ì„±
  
â†’ Threshë¥¼ ì†Œí­ ë‚®ì¶° Recall ê°œì„  ì‹œë„
```

#### íƒìƒ‰ ê³µê°„
```yaml
# ê¸°ì¡´ ìµœì ê°’ ì£¼ë³€ ì„¸ë°€ íƒìƒ‰
thresh:     [0.210, 0.212, 0.215, 0.218, 0.220]
box_thresh: [0.410, 0.412, 0.415, 0.418, 0.420]

ì¡°í•©: 5Ã—5 = 25ê°œ
ì†Œìš” ì‹œê°„: 5ë¶„ (Validation setë§Œ ì˜ˆì¸¡)
```

#### ì˜ˆìƒ ê²°ê³¼
```
99_comprehensiveì—ì„œ ê´€ì°°ëœ íŒ¨í„´:
  thresh vs Recall: éë‹¨ì¡° ê³¡ì„ 
  0.215ê°€ ë¡œì»¬ ìµœëŒ€ê°’ì´ì—ˆìœ¼ë‚˜, ì™¸ë¶€ ë°ì´í„° ì¶”ê°€ í›„ ìµœì ì  ì´ë™ ê°€ëŠ¥

ì˜ˆìƒ ìµœì ì :
  thresh: 0.212~0.218
  box_thresh: 0.415 (ê³ ì • or 0.410~0.420)
  H-Mean: 98.68~98.78%
```

#### ì‹¤í–‰ ëª…ë ¹ì–´
```bash
python scripts/postprocess_grid_search.py \
  --checkpoint checkpoints/kfold/fold_3/fold3_best.ckpt \
  --thresh_range 0.210 0.220 --thresh_step 0.002 \
  --box_thresh_range 0.410 0.420 --box_thresh_step 0.005 \
  --output outputs/postprocess_fine_tuning
```

---

## â­ Part 2: Tier 2 ì „ëµ - ê³ íš¨ê³¼ ì¤‘ê¸° (3~7ì¼)

### 5ï¸âƒ£ ğŸ†• ëŒ€ê·œëª¨ ì™¸ë¶€ ë°ì´í„° í†µí•© Pre-training (13,000ì¥) â­â­â­â­â­

**í˜„ì¬ ìƒíƒœ**: SROIE (626ì¥) + CORD-v2 (800ì¥) = 4,698ì¥  
**ì˜ˆìƒ ê°œì„ **: +0.8~1.2%p | **ì†Œìš” ì‹œê°„**: 8ì‹œê°„ | **ë‚œì´ë„**: â­â­â­

#### í™•ì¥ ë°ì´í„°ì…‹ êµ¬ì„±
```
í˜„ì¬ ë°ì´í„°:
  ëŒ€íšŒ ë°ì´í„°:  3,272ì¥ (100%)
  + SROIE:       626ì¥ (+19.1%, ë¹½ë¹½í•œ ì˜ìˆ˜ì¦)
  + CORD-v2:     800ì¥ (+24.4%, í•œê¸€ ë³µì¡ ë ˆì´ì•„ì›ƒ)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ì†Œê³„:        4,698ì¥ (+43.6%)

ì¶”ê°€ ê°€ëŠ¥ ë°ì´í„°ì…‹:
  + WildReceipt:  1,300ì¥ (+39.7%, êµ¬ê²¨ì§„/íœ˜ì–´ì§„)
  + ICDAR 2019:   1,000ì¥ (+30.6%, ë‹¤êµ­ì–´)
  + RVL-CDIP:     2,500ì¥ (+76.4%, ë¬¸ì„œ ë‹¤ì–‘ì„±)
  + SynthText:    3,500ì¥ (+107%, í•©ì„± ë°ì´í„°)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ì´ê³„:        ~13,000ì¥ (+297% ì¦ê°€!) â­â­â­
```

#### ê° ë°ì´í„°ì…‹ì˜ ì—­í• 
```
SROIE (626ì¥):
  íŠ¹í™”: ì´ˆë°€ì§‘ í…ìŠ¤íŠ¸ (ê°œë¯¸ ì¡ê¸°)
  ê¸°ì—¬: ê³ ë°€ë„ ì´ë¯¸ì§€ ëŒ€ì‘
  
CORD-v2 (800ì¥):
  íŠ¹í™”: í•œêµ­ì–´ ë³µì¡ ë ˆì´ì•„ì›ƒ
  ê¸°ì—¬: ë„ë©”ì¸ ì¼ì¹˜ì„±
  
WildReceipt (1,300ì¥):
  íŠ¹í™”: êµ¬ê²¨ì§„, íœ˜ì–´ì§„ ì˜ìˆ˜ì¦ (ë±€ ì¡ê¸°)
  ê¸°ì—¬: ë³€í˜• ê°•ê±´ì„±
  
ICDAR 2019 (1,000ì¥):
  íŠ¹í™”: ë‹¤êµ­ì–´, ë‹¤ì–‘í•œ í°íŠ¸
  ê¸°ì—¬: ì¼ë°˜í™” ëŠ¥ë ¥
  
RVL-CDIP (2,500ì¥):
  íŠ¹í™”: ë¬¸ì„œ ë ˆì´ì•„ì›ƒ ë‹¤ì–‘ì„±
  ê¸°ì—¬: êµ¬ì¡°ì  ì´í•´ë ¥
  
SynthText (3,500ì¥):
  íŠ¹í™”: í•©ì„± í…ìŠ¤íŠ¸ (ë¬´í•œ ìƒì„± ê°€ëŠ¥)
  ê¸°ì—¬: ë°ì´í„° ì¦ê°• íš¨ê³¼
```

#### 99_comprehensive ë°ì´í„° íš¨ê³¼ ê²€ì¦
```
ì™¸ë¶€ ë°ì´í„° ê¸°ì—¬ë„ ë¶„ì„:
  ê¸°ë³¸ â†’ +626ì¥ SROIE:     +0.35%p (ì¶”ì •)
  ê¸°ë³¸ â†’ +800ì¥ CORD:      +0.36%p (ì¶”ì •)
  ê¸°ë³¸ â†’ +1,426ì¥ ì´ê³„:    +0.71%p
  
ë‹¨ìœ„ë‹¹ íš¨ê³¼: +0.71%p / 1,426ì¥ = 0.50%p per 1,000ì¥

13,000ì¥ ì ìš© ì‹œ:
  ì¶”ê°€ ë°ì´í„°: 13,000 - 4,698 = 8,302ì¥
  ì˜ˆìƒ ê¸°ì—¬: 0.50%p Ã— 8.3 = +0.8~1.2%p â­â­â­
```

#### ì‹¤í–‰ ì „ëµ
```bash
# 1. ëª¨ë“  ì™¸ë¶€ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (2ì‹œê°„)
cd /data/ephemeral/home/data/pseudo_label

# SROIE (ì´ë¯¸ ìˆìŒ)
# CORD-v2 (ì´ë¯¸ ìˆìŒ)

# WildReceipt
git clone https://github.com/clovaai/wildreceipt.git

# ICDAR 2019 RobustReading
wget https://rrc.cvc.uab.es/downloads/icdar2019_task1.zip
unzip icdar2019_task1.zip

# RVL-CDIP (subset)
# Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œ
from huggingface_hub import snapshot_download
snapshot_download("aharley/rvl_cdip", repo_type="dataset", local_dir="./rvl_cdip")

# 2. í†µí•© í¬ë§· ë³€í™˜ (3ì‹œê°„)
cd /data/ephemeral/home/baseline_code
python scripts/convert_all_external_datasets.py \
  --sroie ../data/pseudo_label/sroie \
  --cord ../data/pseudo_label/cord-v2 \
  --wildreceipt ../data/pseudo_label/wildreceipt \
  --icdar ../data/pseudo_label/icdar2019_task1 \
  --rvl_cdip ../data/pseudo_label/rvl_cdip \
  --output ../data/datasets/external_unified_13k.json

# 3. ëŒ€íšŒ ë°ì´í„°ì™€ ë³‘í•© (10ë¶„)
python scripts/merge_datasets.py \
  --base train_augmented_full.json \
  --external external_unified_13k.json \
  --output train_mega_dataset_13k.json \
  --validate  # ì¤‘ë³µ ì œê±°, í’ˆì§ˆ ê²€ì¦

# 4. Pre-training (3ì‹œê°„)
python runners/train.py \
    preset=hrnet_w44_1024_pretrain \
    ++datasets.train_dataset.annotation_path=train_mega_dataset_13k.json \
    exp_name=hrnet_w44_pretrain_13k \
    trainer.max_epochs=15
```

#### ì˜ˆìƒ ê²°ê³¼
```
Pre-training íš¨ê³¼:
  ë°ì´í„° ë‹¤ì–‘ì„±: +297% â†’ ì¼ë°˜í™” ëŠ¥ë ¥ ê·¹ëŒ€í™”
  ë„ë©”ì¸ ì»¤ë²„ë¦¬ì§€:
    - ë°€ì§‘ í…ìŠ¤íŠ¸ (SROIE)
    - í•œêµ­ì–´ (CORD)
    - ë³€í˜• (WildReceipt)
    - ë‹¤êµ­ì–´ (ICDAR)
    - ë‹¤ì–‘í•œ ë ˆì´ì•„ì›ƒ (RVL-CDIP)
  
ì„±ëŠ¥ ì˜ˆìƒ:
  Validation: H-Mean 99.0~99.3%
  Test/Leaderboard: H-Mean 99.2~99.5%
```

---

### 6ï¸âƒ£ ğŸ†• 2ë‹¨ê³„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (Curriculum Learning) â­â­â­â­

**í˜„ì¬ ìƒíƒœ**: ë‹¨ì¼ í•´ìƒë„ (1024px) ë‹¨ì¼ ë°ì´í„°ì…‹ í•™ìŠµ  
**ì˜ˆìƒ ê°œì„ **: +0.3~0.6%p | **ì†Œìš” ì‹œê°„**: 6ì‹œê°„ | **ë‚œì´ë„**: â­â­â­

#### Curriculum Learning ì „ëµ
```
Stage 1: Pre-training (ì™¸ë¶€ ë°ì´í„° í¬í•¨)
  ëª©ì : ë„“ì€ ì¼ë°˜í™” ëŠ¥ë ¥ í™•ë³´
  ë°ì´í„°: 13,000ì¥ í†µí•© ë°ì´í„°ì…‹
  í•´ìƒë„: 1024px (íš¨ìœ¨ì  í•™ìŠµ)
  Epochs: 15
  í•™ìŠµë¥ : 0.001
  
Stage 2: Fine-tuning (ëŒ€íšŒ ë°ì´í„°ë§Œ)
  ëª©ì : ëŒ€íšŒ íŠ¹í™” ì •ë°€ ìµœì í™”
  ë°ì´í„°: 3,272ì¥ ëŒ€íšŒ ë°ì´í„°ë§Œ
  í•´ìƒë„: 1280px (ê³ í•´ìƒë„ ì •ë°€)
  Epochs: 8
  í•™ìŠµë¥ : 0.0001 (1/10ë¡œ ê°ì†Œ)
```

#### 99_comprehensive í•´ìƒë„ ë¶„ì„ ì¬ê²€í† 
```
ê¸°ì¡´ ë°œê²¬:
  1024px â†’ 1280px: +0.0~0.1%p (íš¨ê³¼ ê±°ì˜ ì—†ìŒ)
  
í•˜ì§€ë§Œ:
  "1280px ë‹¨ë… í•™ìŠµ"ê³¼ "1024 Pre-train â†’ 1280 Fine-tune"ì€ ë‹¤ë¦„!
  
ì´ìœ :
  1. Transfer Learning íš¨ê³¼
     - 1024pxì—ì„œ ì¶©ë¶„í•œ feature í•™ìŠµ
     - 1280pxì—ì„œ ë¯¸ì„¸ ì¡°ì •ë§Œ ìˆ˜í–‰
     
  2. ê³ í•´ìƒë„ì˜ ì •í™•í•œ ì—­í• 
     - 1280px ì²˜ìŒë¶€í„°: ìˆ˜ë ´ ëŠë¦¼, ê³¼ì í•© ìœ„í—˜
     - 1280px Fine-tune: ì •ë°€ë„ë§Œ ê°œì„ 
     
  3. ëŒ€íšŒ ë°ì´í„° ì§‘ì¤‘
     - Stage 2ì—ì„œ ì™¸ë¶€ ë°ì´í„° ë°°ì œ
     - ëŒ€íšŒ íŠ¹ì„±ì— ìµœì í™”
```

#### ì‹¤í–‰ ë°©ë²•
```bash
cd /data/ephemeral/home/baseline_code

# Stage 1: Pre-training @ 1024px (3ì‹œê°„)
python runners/train.py \
    preset=hrnet_w44_1024_stage1 \
    ++datasets.train_dataset.annotation_path=train_mega_dataset_13k.json \
    ++datasets.val_dataset.annotation_path=kfold_results/fold_3/val.json \
    datasets.image_size=1024 \
    optimizer.lr=0.001 \
    trainer.max_epochs=15 \
    exp_name=stage1_pretrain_1024px_13k

# Stage 2: Fine-tuning @ 1280px (3ì‹œê°„)
python runners/train.py \
    preset=hrnet_w44_1280_stage2 \
    ++resume_from=outputs/stage1_pretrain_1024px_13k/checkpoints/last.ckpt \
    ++datasets.train_dataset.annotation_path=train.json \
    ++datasets.val_dataset.annotation_path=kfold_results/fold_3/val.json \
    datasets.image_size=1280 \
    optimizer.lr=0.0001 \
    trainer.max_epochs=8 \
    exp_name=stage2_finetune_1280px_competition
```

#### ê¸°ëŒ€ íš¨ê³¼
```
Stage 1 (Pre-training):
  ë„“ì€ ì¼ë°˜í™” ëŠ¥ë ¥ í™•ë³´
  ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ íŒ¨í„´ í•™ìŠµ
  
Stage 2 (Fine-tuning):
  ëŒ€íšŒ ë°ì´í„° íŠ¹í™”:
    - í•œêµ­ì–´ ì˜ìˆ˜ì¦ ë ˆì´ì•„ì›ƒ
    - íŠ¹ì • í°íŠ¸, í˜•ì‹
  ê³ í•´ìƒë„ ì •ë°€ë„:
    - ì‘ì€ ê¸€ì ê²½ê³„ì„  ê°œì„ 
    - ê¸´ í…ìŠ¤íŠ¸ ë¼ì¸ ì •í™•ë„ í–¥ìƒ
  
ìµœì¢… ì˜ˆìƒ:
  Stage 1 ë‹¨ë…: H-Mean 99.0~99.2%
  Stage 2 ì¶”ê°€: H-Mean 99.3~99.6%
  ìˆœìˆ˜ ê°œì„ : +0.3~0.6%p
```

---

### 7ï¸âƒ£ ğŸ†• P2 Feature Pyramid ë ˆë²¨ ì¶”ê°€ (High-Res FPN) â­â­â­â­

**í˜„ì¬ ìƒíƒœ**: FPN P3~P7 ë ˆë²¨ ì‚¬ìš© (1/8 ~ 1/128 í•´ìƒë„)  
**ì˜ˆìƒ ê°œì„ **: +0.2~0.5%p | **ì†Œìš” ì‹œê°„**: 5ì‹œê°„ | **ë‚œì´ë„**: â­â­â­â­

#### Feature Pyramid Network êµ¬ì¡°
```
í˜„ì¬ FPN (DBNet ê¸°ë³¸):
  
  Input Image (1024Ã—1024)
    â†“
  Encoder (HRNet-W44)
    â”œâ”€ 1/4:  256Ã—256  (C2, ë¯¸ì‚¬ìš©)
    â”œâ”€ 1/8:  128Ã—128  (C3) â†’ P3 â­
    â”œâ”€ 1/16:  64Ã—64   (C4) â†’ P4
    â”œâ”€ 1/32:  32Ã—32   (C5) â†’ P5
    â””â”€ 1/64:  16Ã—16   (C6) â†’ P6
  
  FPN Neck:
    P3, P4, P5, P6 â†’ Lateral + Top-down
  
  Head:
    Fused features â†’ Probability Map

ë¬¸ì œì :
  P3 (1/8 í•´ìƒë„)ê°€ ê°€ì¥ ë†’ì€ í•´ìƒë„
  â†’ ì‘ì€ í…ìŠ¤íŠ¸ (20pxÂ²)ëŠ” 1/8ë¡œ ì¤„ë©´ 2.5pxÂ²
  â†’ ì •ë³´ ì†Œì‹¤ ìœ„í—˜
```

#### P2 ë ˆë²¨ ì¶”ê°€ ì„¤ê³„
```
ê°œì„ ëœ FPN:
  
  Input Image (1024Ã—1024)
    â†“
  Encoder (HRNet-W44)
    â”œâ”€ 1/4:  256Ã—256  (C2) â†’ P2 â­â­â­ ì‹ ê·œ ì¶”ê°€
    â”œâ”€ 1/8:  128Ã—128  (C3) â†’ P3
    â”œâ”€ 1/16:  64Ã—64   (C4) â†’ P4
    â”œâ”€ 1/32:  32Ã—32   (C5) â†’ P5
    â””â”€ 1/64:  16Ã—16   (C6) â†’ P6
  
  FPN Neck:
    P2, P3, P4, P5, P6 â†’ Enhanced fusion
  
  Head:
    P2 ì£¼ë„ (ì‘ì€ ê°ì²´) + P3~P6 ë³´ì¡°

ì¥ì :
  ì‘ì€ í…ìŠ¤íŠ¸ (20pxÂ²):
    - 1/8 í•´ìƒë„: 2.5pxÂ² (ì •ë³´ ë¶€ì¡±)
    - 1/4 í•´ìƒë„: 5pxÂ² (ì¶©ë¶„í•œ ì •ë³´)
  
  ê²½ê³„ì„  ì •ë°€ë„:
    - 1/4 í•´ìƒë„ë¡œ ë³µì› â†’ ë” ì •ë°€í•œ polygon
```

#### êµ¬í˜„ ë°©ë²•
```python
# ocr/models/decoder/fpn_with_p2.py
class FPNDecoderWithP2(nn.Module):
    def __init__(self, in_channels=[64, 128, 256, 512], out_channels=256):
        super().__init__()
        
        # Lateral connections (C2ë¶€í„° ì‹œì‘)
        self.lateral_c2 = nn.Conv2d(in_channels[0], out_channels, 1)  # ì‹ ê·œ
        self.lateral_c3 = nn.Conv2d(in_channels[1], out_channels, 1)
        self.lateral_c4 = nn.Conv2d(in_channels[2], out_channels, 1)
        self.lateral_c5 = nn.Conv2d(in_channels[3], out_channels, 1)
        
        # Top-down pathway
        self.smooth_p2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)  # ì‹ ê·œ
        self.smooth_p3 = nn.Conv2d(out_channels, out_channels, 3, padding=1)
        self.smooth_p4 = nn.Conv2d(out_channels, out_channels, 3, padding=1)
        self.smooth_p5 = nn.Conv2d(out_channels, out_channels, 3, padding=1)
        
    def forward(self, features):
        c2, c3, c4, c5 = features  # HRNetì˜ 4ê°œ stage
        
        # Top-down pathway
        p5 = self.lateral_c5(c5)
        p4 = self.lateral_c4(c4) + F.interpolate(p5, scale_factor=2)
        p3 = self.lateral_c3(c3) + F.interpolate(p4, scale_factor=2)
        p2 = self.lateral_c2(c2) + F.interpolate(p3, scale_factor=2)  # ì‹ ê·œ
        
        # Smooth
        p5 = self.smooth_p5(p5)
        p4 = self.smooth_p4(p4)
        p3 = self.smooth_p3(p3)
        p2 = self.smooth_p2(p2)  # ì‹ ê·œ
        
        # Upsample all to P2 resolution for fusion
        p3_up = F.interpolate(p3, scale_factor=2, mode='bilinear')
        p4_up = F.interpolate(p4, scale_factor=4, mode='bilinear')
        p5_up = F.interpolate(p5, scale_factor=8, mode='bilinear')
        
        # Weighted fusion (P2 ì£¼ë„)
        fused = 0.5 * p2 + 0.25 * p3_up + 0.15 * p4_up + 0.10 * p5_up
        
        return fused

# configs/preset/models/decoder/fpn_with_p2.yaml
decoder:
  name: FPNDecoderWithP2
  in_channels: [64, 128, 256, 512]  # HRNet-W44 outputs
  out_channels: 256
  use_p2: true
```

#### ì£¼ì˜ì‚¬í•­
```
ë©”ëª¨ë¦¬ ì¦ê°€:
  P2 (1/4 í•´ìƒë„) = P3ì˜ 4ë°° ë©”ëª¨ë¦¬
  â†’ ë°°ì¹˜ í¬ê¸° 4 â†’ 2ë¡œ ê°ì†Œ í•„ìš”
  
í•™ìŠµ ì‹œê°„:
  FPN ì—°ì‚° ì¦ê°€: +30% ì‹œê°„
  3ì‹œê°„ â†’ 4ì‹œê°„ ì˜ˆìƒ
  
í•˜ì§€ë§Œ:
  ì‘ì€ í…ìŠ¤íŠ¸ ê²€ì¶œ ê°œì„ ì´ ëª©í‘œë¼ë©´ íˆ¬ì ê°€ì¹˜ ìˆìŒ
```

#### ì‹¤í–‰ ëª…ë ¹ì–´
```bash
cd /data/ephemeral/home/baseline_code

# FPN P2 êµ¬í˜„ (1ì‹œê°„)
# ìœ„ ì½”ë“œë¥¼ ocr/models/decoder/fpn_with_p2.pyì— ì‘ì„±

# í•™ìŠµ (4ì‹œê°„)
python runners/train.py \
    preset=hrnet_w44_1024_fpn_p2 \
    model.decoder.name=FPNDecoderWithP2 \
    model.decoder.use_p2=true \
    ++datasets.train_dataset.annotation_path=train_augmented_full.json \
    ++datasets.val_dataset.annotation_path=kfold_results/fold_3/val.json \
    dataloaders.train_dataloader.batch_size=2 \
    trainer.max_epochs=12 \
    exp_name=hrnet_w44_fpn_p2_small_objects
```

#### ì˜ˆìƒ ê²°ê³¼
```
ì†Œí˜• ë°•ìŠ¤ (20~100pxÂ²) ê²€ì¶œ:
  Before P2: Recall 95~97%
  After P2:  Recall 98~99%
  
ê²½ê³„ì„  ì •ë°€ë„:
  Polygon points: ë” ì •í™•í•œ ì¢Œí‘œ
  IoU with GT: +1~2% í–¥ìƒ
  
ì „ì²´ ì„±ëŠ¥:
  Recall: +0.2~0.4%p
  Precision: +0.1~0.2%p (ê²½ê³„ì„  ì •ë°€ë„)
  H-Mean: +0.2~0.5%p
```

---

### 8ï¸âƒ£ EfficientNet-B3/B4 ë°±ë³¸ ì‹¤í—˜ â­â­â­â­â­

**í˜„ì¬ ìƒíƒœ**: HRNet-W44 ì‚¬ìš©  
**ì˜ˆìƒ ê°œì„ **: +0.5~0.8%p (ë‹¨ì¼ ëª¨ë¸) ë˜ëŠ” í˜¼í•© ì•™ìƒë¸”ë¡œ +0.8~1.2%p  
**ì†Œìš” ì‹œê°„**: 3ì‹œê°„ (í•™ìŠµ) | **ë‚œì´ë„**: â­â­

#### EfficientNetì˜ ê°•ì 
```
HRNet-W44 vs EfficientNet-B4:

HRNet-W44:
  ì¥ì : ê³ í•´ìƒë„ ìœ ì§€, í…ìŠ¤íŠ¸ ê²½ê³„ì„  ì •ë°€
  ë‹¨ì : Parameters 67.8M (ë¬´ê±°ì›€)
  íŠ¹í™”: í…ìŠ¤íŠ¸ ê²€ì¶œ

EfficientNet-B4:
  ì¥ì : 
    - Compound Scaling (depth+width+resolution ë™ì‹œ)
    - ImageNet 82.9% Top-1 (HRNetë³´ë‹¤ ë†’ìŒ)
    - 19.3M parameters (ê°€ë²¼ì›€)
  íŠ¹í™”: ì¼ë°˜ ë¬¼ì²´ ê²€ì¶œ, Transfer Learning ìš°ìˆ˜
```

#### ì „ëµ ì˜µì…˜

**ì˜µì…˜ A: ë‹¨ë… ì‹¤í—˜**
```bash
python runners/train.py \
    preset=efficientnet_b4_1024 \
    model.encoder.model_name=tf_efficientnet_b4 \
    datasets.image_size=1024 \
    trainer.max_epochs=18 \
    exp_name=efficientnet_b4_external_data
```

**ì˜µì…˜ B: í˜¼í•© ì•™ìƒë¸” (ì¶”ì²œ)**
```python
# HRNet + EfficientNet ë°±ë³¸ ë‹¤ì–‘ì„± í™œìš©
models = [
    'hrnet_w44_fold3.ckpt',      # H-Mean 98.63%
    'efficientnet_b4_best.ckpt', # ì˜ˆìƒ 98.5~98.7%
]

# Weighted Box Fusion (IoU 0.7)
ensemble_result = wbf(models, weights=[0.55, 0.45], iou_thr=0.7)
```

#### ì˜ˆìƒ ê²°ê³¼
```
ë‹¨ì¼ ëª¨ë¸:
  EfficientNet-B4: H=98.5~98.7% (HRNetë³´ë‹¤ ì•½ê°„ ë‚®ì„ ê°€ëŠ¥ì„±)
  
í˜¼í•© ì•™ìƒë¸”:
  HRNet (í…ìŠ¤íŠ¸ ê²½ê³„ì„  ê°•ì ) + EfficientNet (ì¼ë°˜í™” ê°•ì )
  â†’ ìƒí˜¸ ë³´ì™„ íš¨ê³¼
  ì˜ˆìƒ: H=98.9~99.1% (+0.3~0.5%p)
```

---

### 9ï¸âƒ£ Multi-Scale Test-Time Augmentation â­â­â­â­

**í˜„ì¬ ìƒíƒœ**: ë‹¨ì¼ ìŠ¤ì¼€ì¼ (1024px) ì˜ˆì¸¡, 08_tta_failureë¡œ HFlip TTA ì‹¤íŒ¨  
**ì˜ˆìƒ ê°œì„ **: +0.2~0.4%p | **ì†Œìš” ì‹œê°„**: 30ë¶„ | **ë‚œì´ë„**: â­â­â­

#### 08_tta_failure ì›ì¸ ë¶„ì„
```
ì‹¤íŒ¨ ì›ì¸:
  âœ— HorizontalFlip ì¢Œí‘œ ë³€í™˜ ë¯¸êµ¬í˜„
  âœ— ì˜ëª»ëœ ìœ„ì¹˜ì˜ ë°•ìŠ¤ 215ê°œ ìƒì„±
  âœ— Precision 25.5% í­ë½

êµí›ˆ:
  â†’ Flip TTAëŠ” êµ¬í˜„ ë³µì¡ë„ ë†’ìŒ
  â†’ Multi-Scale TTAê°€ ë” ì•ˆì „í•˜ê³  íš¨ê³¼ì 
```

#### Multi-Scale TTA ì „ëµ
```python
# 3ê°€ì§€ ìŠ¤ì¼€ì¼ë¡œ ì˜ˆì¸¡
scales = [960, 1024, 1088]  # Â±6.25% ë²”ìœ„

predictions = []
for scale in scales:
    resized_image = resize(image, scale)
    pred = model(resized_image)
    pred_original = rescale_boxes(pred, original_size)
    predictions.append(pred_original)

# Weighted Box Fusion
final = wbf(
    predictions,
    weights=[0.25, 0.50, 0.25],  # 1024pxì— ê°€ì¤‘ì¹˜
    iou_thr=0.6
)
```

#### ê¸°ëŒ€ íš¨ê³¼
```
Small Boxes (ì—ëŸ¬ ë¶„ì„ ì¹´í…Œê³ ë¦¬):
  960px:  ì‘ì€ ê¸€ì ì¼ë¶€ ëˆ„ë½ ê°€ëŠ¥
  1024px: í˜„ì¬ ìµœì 
  1088px: ì‘ì€ ê¸€ì ì¶”ê°€ ê²€ì¶œ (+6.25% í•´ìƒë„)
  
  â†’ Fusionìœ¼ë¡œ ëˆ„ë½ ë³´ì™„, Recall +0.2~0.3%p ì˜ˆìƒ
```

#### ì‹¤í–‰ ëª…ë ¹ì–´
```bash
python scripts/predict_multiscale_tta.py \
  --checkpoint checkpoints/kfold/fold_3/fold3_best.ckpt \
  --scales 960 1024 1088 \
  --weights 0.25 0.50 0.25 \
  --iou_threshold 0.6 \
  --output outputs/multiscale_tta
```

---

### ğŸ”Ÿ Anchor Box ì¢…íš¡ë¹„ ì¶”ê°€/ì¡°ì • â­â­â­â­

**í˜„ì¬ ìƒíƒœ**: DBNet ê¸°ë³¸ ì„¤ì • (ë¹„ìœ¨ ë¯¸ì¡°ì •)  
**ì˜ˆìƒ ê°œì„ **: +0.1~0.3%p | **ì†Œìš” ì‹œê°„**: 4ì‹œê°„ (ì¬í•™ìŠµ) | **ë‚œì´ë„**: â­â­â­

#### ì—ëŸ¬ ë¶„ì„ ê¸°ë°˜ í•„ìš”ì„±
```
56_ERROR_ANALYSIS ë°œê²¬:
  ê·¹ë‹¨ì  ì¢…íš¡ë¹„ (AR > 6.0):
    - selectstar_000827.jpg: AR=7.68 (ìµœëŒ€)
    - 20ê°œ ì´ë¯¸ì§€ì—ì„œ AR>6.0
  
  â†’ ê¸°ë³¸ Anchor Boxë¡œ ì»¤ë²„ ë¶€ì¡± ê°€ëŠ¥ì„±
```

#### DBNet Anchor Box ì„¤ì •
```yaml
# í˜„ì¬ (ì¶”ì •, ê¸°ë³¸ê°’)
anchor_ratios:
  - 0.2   # 1:5 (ë§¤ìš° ê°€ë¡œë¡œ ê¸´)
  - 0.5   # 1:2
  - 1.0   # ì •ì‚¬ê°í˜•
  - 2.0   # 2:1
  - 5.0   # 5:1

# ì¶”ê°€ ì œì•ˆ
anchor_ratios:
  - 0.13  # 1:7.5 (AR=7.68 ëŒ€ì‘) â­
  - 0.2
  - 0.5
  - 1.0
  - 2.0
  - 5.0
  - 7.5   # ê·¹ë‹¨ ë¹„ìœ¨ ì¶”ê°€ â­
```

#### ì‹¤í–‰ ë°©ë²•
```yaml
# configs/preset/models/model_hrnet_w44_custom_anchors.yaml
model:
  architecture:
    encoder:
      model_name: hrnet_w44
    decoder:
      name: FPNDecoder
    head:
      name: DBHead
      anchor_ratios: [0.13, 0.2, 0.5, 1.0, 2.0, 5.0, 7.5]  # ìˆ˜ì •
```

#### ì˜ˆìƒ ê²°ê³¼
```
ê·¹ë‹¨ ì¢…íš¡ë¹„ ì´ë¯¸ì§€ (20ê°œ):
  Before: AR>6.0 í…ìŠ¤íŠ¸ ê²€ì¶œë¥  ~95%
  After:  AR>6.0 í…ìŠ¤íŠ¸ ê²€ì¶œë¥  ~98% (+3%p)
  
ì „ì²´ ì„±ëŠ¥:
  Recall: +0.1~0.2%p
  H-Mean: +0.1~0.3%p
```

---

### 1ï¸âƒ£1ï¸âƒ£ Deformable Convolution (DCN) ì ìš© â­â­â­

**í˜„ì¬ ìƒíƒœ**: ì¼ë°˜ Convolution ì‚¬ìš©  
**ì˜ˆìƒ ê°œì„ **: +0.3~0.5%p | **ì†Œìš” ì‹œê°„**: 5ì‹œê°„ (êµ¬í˜„+í•™ìŠµ) | **ë‚œì´ë„**: â­â­â­â­

#### Deformable Convolution ì¥ì 
```
ì¼ë°˜ Convolution:
  3Ã—3 kernel â†’ ê³ ì •ëœ 9ê°œ ìœ„ì¹˜ ìƒ˜í”Œë§
  ë¬¸ì œ: êµ¬ê²¨ì§„, íœ˜ì–´ì§„ í…ìŠ¤íŠ¸ì— ë¶€ì í•©

Deformable Convolution:
  ê° ìƒ˜í”Œë§ ìœ„ì¹˜ê°€ í•™ìŠµ ê°€ëŠ¥í•œ offset
  â†’ í…ìŠ¤íŠ¸ í˜•íƒœì— ë§ì¶° ë™ì  ìƒ˜í”Œë§
  
íš¨ê³¼:
  âœ“ êµ¬ê²¨ì§„ ì˜ìˆ˜ì¦ ëŒ€ì‘ (WildReceipt ì¶”ê°€ ì‹œ ì‹œë„ˆì§€)
  âœ“ ê·¹ë‹¨ ì¢…íš¡ë¹„ í…ìŠ¤íŠ¸ ì²˜ë¦¬
  âœ“ ê²½ê³„ì„  ì •ë°€ë„ í–¥ìƒ
```

#### êµ¬í˜„ ë°©ë²•
```python
# HRNet Backboneì— DCN ì ìš©
from torchvision.ops import DeformConv2d

class HRNetWithDCN(nn.Module):
    def __init__(self):
        # Stage 3, 4ì˜ convolutionì„ DCNìœ¼ë¡œ êµì²´
        self.stage3_dcn = DeformConv2d(256, 256, 3, padding=1)
        self.stage4_dcn = DeformConv2d(512, 512, 3, padding=1)
```

#### ì˜ˆìƒ ê²°ê³¼
```
CVPR 2017 ë…¼ë¬¸ ê²°ê³¼:
  ì¼ë°˜ Conv â†’ DCN: COCO Detection +5~10% mAP
  
OCR ì ìš© ì˜ˆìƒ:
  Recall: +0.3~0.4%p (êµ¬ê²¨ì§„ í…ìŠ¤íŠ¸)
  Precision: ìœ ì§€ or +0.1%p
  H-Mean: +0.3~0.5%p
```

---

### 1ï¸âƒ£2ï¸âƒ£ Vision Transformer (ViT) ë˜ëŠ” Swin Transformer ë°±ë³¸ â­â­â­â­

**í˜„ì¬ ìƒíƒœ**: CNN ê¸°ë°˜ (HRNet-W44)  
**ì˜ˆìƒ ê°œì„ **: +0.5~1.0%p | **ì†Œìš” ì‹œê°„**: 6ì‹œê°„ | **ë‚œì´ë„**: â­â­â­â­

#### Transformer ì¥ì 
```
CNN (HRNet):
  ì¥ì : ì§€ì—­ íŠ¹ì§• ì¶”ì¶œ ê°•ë ¥, ê³ í•´ìƒë„ ìœ ì§€
  ë‹¨ì : ì „ì—­ ë¬¸ë§¥ ë¶€ì¡±, Receptive field ì œí•œ

Vision Transformer:
  ì¥ì :
    - ì „ì—­ Self-Attention (ì´ë¯¸ì§€ ì „ì²´ ë¬¸ë§¥)
    - Long-range dependency ëª¨ë¸ë§
    - í…ìŠ¤íŠ¸ ë¸”ë¡ ê°„ ê´€ê³„ íŒŒì•…
  ë‹¨ì :
    - ë§ì€ ë°ì´í„° í•„ìš” (ì™¸ë¶€ ë°ì´í„° ì¶”ê°€ë¡œ í•´ê²°)
    - í•™ìŠµ ì‹œê°„ ì¦ê°€
```

#### ì¶”ì²œ ëª¨ë¸
```
1. Swin Transformer-B (ì¶”ì²œ â­â­â­â­â­)
   - Hierarchical structure (HRNetê³¼ ìœ ì‚¬)
   - Window-based attention (íš¨ìœ¨ì )
   - ImageNet-22K pretrained ê°€ëŠ¥
   
2. ViT-Base/16
   - í‘œì¤€ Transformer
   - Pretrained ëª¨ë¸ í’ë¶€
```

#### ì‹¤í–‰ ì „ëµ
```yaml
# Swin Transformer ì ìš©
model:
  encoder:
    model_name: swin_base_patch4_window7_224
    pretrained: true
    in_chans: 3
  decoder:
    name: FPNDecoder
  head:
    name: DBHead
```

#### ì˜ˆìƒ ê²°ê³¼
```
ë¬¸í—Œ ì¡°ì‚¬ ê²°ê³¼:
  CNN â†’ Transformer: +1~3% ì¼ë°˜ì 
  
ì™¸ë¶€ ë°ì´í„° 5,998ì¥ ê¸°ë°˜:
  ë°ì´í„° ì¶©ë¶„ì„±: ì¶©ì¡± (TransformerëŠ” >5,000ì¥ ê¶Œì¥)
  ì˜ˆìƒ H-Mean: 98.8~99.3%
```

---

## ğŸ’¡ Part 3: Tier 3 ì „ëµ - ì‹¤í—˜ì  ì¥ê¸° (7~14ì¼)

### 1ï¸âƒ£3ï¸âƒ£ Pseudo-Labeling (Self-Training) â­â­â­

**ì˜ˆìƒ ê°œì„ **: +0.3~0.6%p | **ì†Œìš” ì‹œê°„**: 8ì‹œê°„ | **ë‚œì´ë„**: â­â­â­â­

#### ì „ëµ
```
1. í˜„ì¬ ìµœê³  ëª¨ë¸ (H=98.63%)ë¡œ Test set ì˜ˆì¸¡
2. ê³ ì‹ ë¢°ë„ ì˜ˆì¸¡ë§Œ ì„ ë³„ (confidence > 0.95)
3. Pseudo-GTë¡œ í™œìš©í•˜ì—¬ ì¬í›ˆë ¨
4. ë°˜ë³µ (2~3 iteration)
```

#### ê¸°ëŒ€ íš¨ê³¼
```
Test set íŠ¹ì„± í•™ìŠµ:
  - Train/Test distribution gap ê°ì†Œ
  - ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
  
ì˜ˆìƒ:
  1st iteration: +0.2~0.3%p
  2nd iteration: +0.1~0.2%p
  Total: +0.3~0.5%p
```

---

### 1ï¸âƒ£4ï¸âƒ£ FP16 Mixed Precision + Batch Size ì¦ê°€ â­â­â­

**ì˜ˆìƒ ê°œì„ **: +0.1~0.2%p | **ì†Œìš” ì‹œê°„**: 2ì‹œê°„ | **ë‚œì´ë„**: â­â­

#### ì „ëµ
```yaml
# í˜„ì¬
trainer:
  precision: 32
  batch_size: 4

# ë³€ê²½
trainer:
  precision: 16
  amp_backend: native
  batch_size: 8  # or 12
```

#### ê¸°ëŒ€ íš¨ê³¼
```
Batch Size ì¦ê°€:
  âœ“ ì•ˆì •ì ì¸ Gradient (ë…¸ì´ì¦ˆ ê°ì†Œ)
  âœ“ BatchNorm í†µê³„ ì •í™•ë„ í–¥ìƒ
  
ì˜ˆìƒ:
  H-Mean: +0.1~0.2%p
  í•™ìŠµ ì‹œê°„: 1.3ë°° ë‹¨ì¶•
```

---

### 1ï¸âƒ£5ï¸âƒ£ ConvNeXt ë°±ë³¸ ì‹¤í—˜ â­â­â­

**ì˜ˆìƒ ê°œì„ **: +0.4~0.7%p | **ì†Œìš” ì‹œê°„**: 4ì‹œê°„ | **ë‚œì´ë„**: â­â­â­

#### ConvNeXt íŠ¹ì§•
```
"Transformerë¥¼ ì´ê¸´ CNN" (CVPR 2022)
  - ResNet ë””ìì¸ ê°œì„ 
  - Transformerì˜ ê°•ì  í†µí•©
  - HRNetë³´ë‹¤ íš¨ìœ¨ì 
```

---

### 1ï¸âƒ£6ï¸âƒ£ Focal Loss ë˜ëŠ” DIoU Loss ì ìš© â­â­

**ì˜ˆìƒ ê°œì„ **: +0.1~0.3%p | **ì†Œìš” ì‹œê°„**: 3ì‹œê°„ | **ë‚œì´ë„**: â­â­â­

#### Loss Function ë³€ê²½
```python
# í˜„ì¬: L1 Loss (DBNet ê¸°ë³¸)
# ë³€ê²½: DIoU Loss (ê²½ê³„ì„  ì •ë°€ë„ í–¥ìƒ)

class DIoULoss(nn.Module):
    """Distance-IoU Loss for better bbox regression"""
    pass
```

---

### 1ï¸âƒ£7ï¸âƒ£ CutOut/GridMask Augmentation â­â­

**ì˜ˆìƒ ê°œì„ **: +0.1~0.2%p | **ì†Œìš” ì‹œê°„**: 2ì‹œê°„ | **ë‚œì´ë„**: â­â­

#### Augmentation ê°•í™”
```yaml
augmentation:
  - GridMask:      # ê²©ì ë¬´ëŠ¬ ë§ˆìŠ¤í‚¹
      ratio: 0.6
  - CutOut:        # ëœë¤ ì˜ì—­ ì œê±°
      num_holes: 3
```

---

### 1ï¸âƒ£8ï¸âƒ£ Knowledge Distillation (Teacher-Student) â­â­â­

**ì˜ˆìƒ ê°œì„ **: +0.2~0.4%p | **ì†Œìš” ì‹œê°„**: 8ì‹œê°„ | **ë‚œì´ë„**: â­â­â­â­

#### ì „ëµ
```
Teacher: HRNet-W44 (98.63%)
Student: EfficientNet-B3 (ê°€ë²¼ìš´ ëª¨ë¸)

Distillation:
  Feature-level: Stageë³„ feature map matching
  Response-level: Soft labels í•™ìŠµ
  
ëª©í‘œ:
  Studentê°€ Teacher ì„±ëŠ¥ ê·¼ì ‘ + ì¶”ë¡  ì†ë„ 2ë°°
```

---

## âš ï¸ Part 4: Tier 4 ì „ëµ - ê³ ìœ„í—˜ (íš¨ê³¼ ë¶ˆí™•ì‹¤)

### 1ï¸âƒ£9ï¸âƒ£ 1536px ì´ˆê³ í•´ìƒë„ í•™ìŠµ

**ìœ„í—˜**: 99_comprehensive ë°œê²¬ - 1280px ì´ìƒì€ íš¨ê³¼ ê±°ì˜ ì—†ìŒ  
**ì˜ˆìƒ**: +0.0~0.1%p (ë¹„íš¨ìœ¨)

---

### 2ï¸âƒ£0ï¸âƒ£ Soft Voting with Rescue Mechanism

**ìœ„í—˜**: 53_ensemble_failure - ì´ë¯¸ ìš°ìˆ˜í•œ ëª¨ë¸(98%) ì•™ìƒë¸”ì€ ì—­íš¨ê³¼  
**ì˜ˆìƒ**: -0.2~+0.1%p (ë¶ˆí™•ì‹¤)

---

### 2ï¸âƒ£1ï¸âƒ£ NMS/WBF íŒŒë¼ë¯¸í„° ì¬ì¡°ì • ì•™ìƒë¸”

**ìœ„í—˜**: IoU threshold ì¡°ì •ìœ¼ë¡œ 53ë²ˆ ì‹¤íŒ¨ ê·¹ë³µ ì‹œë„  
**ì˜ˆìƒ**: -0.5~+0.2%p (ìœ„í—˜)

---

### 2ï¸âƒ£2ï¸âƒ£ Learning Rate Warmup + Cosine Annealing ì¬ì¡°ì •

**ìœ„í—˜**: ì´ë¯¸ Grid Searchë¡œ ìµœì í™”ë¨  
**ì˜ˆìƒ**: +0.0~0.05%p (ë¯¸ë¯¸)

---

## âŒ Part 5: Tier 5 ì „ëµ - ë¹„ì¶”ì²œ (ì‹¤íŒ¨ ê°€ëŠ¥ì„± ë†’ìŒ)

### 2ï¸âƒ£3ï¸âƒ£ HorizontalFlip TTA

**ì‹¤íŒ¨ ì‚¬ë¡€**: 08_tta_failure_analysis.md  
**ê²°ê³¼**: H-Mean 18.7% í­ë½  
**ì´ìœ **: ì¢Œí‘œ ë³€í™˜ ë³µì¡ì„±, êµ¬í˜„ ì˜¤ë¥˜ ìœ„í—˜

---

### 2ï¸âƒ£4ï¸âƒ£ K-Fold 5-Fold Voting Ensemble

**ì‹¤íŒ¨ ì‚¬ë¡€**: 53_ensemble_failure_analysis.md  
**ê²°ê³¼**: H-Mean 9.76%p í•˜ë½ (98.63% â†’ 88.87%)  
**ì´ìœ **: ì´ë¯¸ 98% ì´ìƒ ëª¨ë¸ì€ ì•™ìƒë¸” ì—­íš¨ê³¼

---

### 2ï¸âƒ£5ï¸âƒ£ ResNet101/ResNet152 ë°±ë³¸

**ì´ìœ **: 99_comprehensive - HRNetì´ ì´ë¯¸ ResNet ê³„ì—´ ì´ˆì›”  
**ì˜ˆìƒ**: 0%p ë˜ëŠ” ë§ˆì´ë„ˆìŠ¤

---

## ğŸ¯ Part 6: ì‹¤í–‰ ìš°ì„ ìˆœìœ„ ë¡œë“œë§µ

### Phase 1: Quick Wins (1ì£¼ì¼, ì˜ˆìƒ +0.8~1.5%p) ğŸ”¥

```
Day 1:
  âœ… Unclip Ratio ìµœì í™” (10ë¶„)           â†’ +0.2~0.4%p
  âœ… í›„ì²˜ë¦¬ ì´ˆë¯¸ì„¸ ì¡°ì • (5ë¶„)             â†’ +0.05~0.15%p
  â­ Tiny Box Loss ê°€ì¤‘ì¹˜ êµ¬í˜„ (2ì‹œê°„)   â†’ +0.4~0.7%p  ğŸ†•
  
ì˜ˆìƒ ëˆ„ì : 98.63% â†’ 99.25~99.88%

Day 2-3:
  âœ… WildReceipt + ì¶”ê°€ ì™¸ë¶€ ë°ì´í„° (5ì‹œê°„)
     - WildReceipt (1,300ì¥)
     - ICDAR 2019 (1,000ì¥)                 â†’ +0.3~0.5%p
  
ì˜ˆìƒ ëˆ„ì : 99.25% â†’ 99.55~100%

ì‹¤í–‰ ìˆœì„œ:
  1. Unclip ratio grid search â†’ ìµœì ê°’ í™•ì •
  2. Tiny Box Loss êµ¬í˜„ ë° Fine-tuning (1ì‹œê°„)
  3. í›„ì²˜ë¦¬ thresh/box_thresh ë¯¸ì„¸ì¡°ì •
  4. WildReceipt + ì¶”ê°€ ë°ì´í„° ì¤€ë¹„
  5. ì¬í›ˆë ¨ (overnight 3ì‹œê°„)
```

### Phase 2: ê³ íš¨ê³¼ ì‹¤í—˜ (2ì£¼ì¼, ì˜ˆìƒ +1.0~2.0%p ì¶”ê°€) â­

```
Week 2:
  ğŸ†• ëŒ€ê·œëª¨ Pre-training (8ì‹œê°„)          â†’ +0.8~1.2%p
     - 13,000ì¥ í†µí•© ë°ì´í„°ì…‹
     - SROIE + CORD + WildReceipt + ICDAR + RVL-CDIP
  
  ğŸ†• 2ë‹¨ê³„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (6ì‹œê°„)    â†’ +0.3~0.6%p
     - Stage 1: 1024px Pre-training (3ì‹œê°„)
     - Stage 2: 1280px Fine-tuning (3ì‹œê°„)
  
  ğŸ†• P2 Feature Pyramid (5ì‹œê°„)          â†’ +0.2~0.5%p
     - FPNì— ê³ í•´ìƒë„ ë ˆë²¨ ì¶”ê°€
     - ì†Œí˜• ë°•ìŠ¤ íŠ¹í™”
  
  â­ Multi-Scale TTA (30ë¶„)               â†’ +0.3%p
  â­ EfficientNet-B4 í•™ìŠµ (3ì‹œê°„)
  â­ HRNet + EffNet í˜¼í•© ì•™ìƒë¸” (1ì‹œê°„)
  
ì˜ˆìƒ ëˆ„ì : 99.55% â†’ 99.8~100%+
```

### Phase 3: ì¥ê¸° í˜ì‹  (ì¶”ê°€ 2ì£¼, ì˜ˆìƒ +0.5~1.0%p) ğŸ’¡

```
Week 3-4:
  ğŸ’¡ Swin Transformer í•™ìŠµ (6ì‹œê°„)
  ğŸ’¡ Pseudo-Labeling 2 iterations (8ì‹œê°„)
  ğŸ’¡ Deformable Convolution (5ì‹œê°„)
  
ì˜ˆìƒ ìµœì¢…: 99.8% â†’ 99.9~100%+
```

---

## ğŸ“Š Part 7: ì˜ˆìƒ ì„±ëŠ¥ ê¶¤ì 

```
H-Mean ì„±ëŠ¥ ë³€í™” (ì˜ˆìƒ)

100% â”¤                                    â—† 99.9% (Phase 3)
     â”‚                                â”Œâ”€â”€â”€â”˜
 99% â”¤                            â”Œâ”€â”€â”€â”˜ 99.5% (Phase 2)
     â”‚                         â”Œâ”€â”€â”˜
     â”‚                      â”Œâ”€â”€â”˜ 99.15% (Phase 1)
     â”‚                   â”Œâ”€â”€â”˜
 98% â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ 98.63% (í˜„ì¬)
     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º ì‹¤í–‰ ë‹¨ê³„
       í˜„ì¬    Phase 1   Phase 2   Phase 3
              Quick     ê³ íš¨ê³¼    ì¥ê¸°
              Wins      ì‹¤í—˜     í˜ì‹ 
       
ëª©í‘œ: 99.0% ëŒíŒŒ (Phase 1-2ë¡œ ë‹¬ì„± ê°€ëŠ¥)
```

---

## ğŸ’° Part 8: ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼ ë¶„ì„

| ì „ëµ | GPU ì‹œê°„ | êµ¬í˜„ ë‚œì´ë„ | ì˜ˆìƒ íš¨ê³¼ | ROI (íš¨ê³¼/ì‹œê°„) | ì¶”ì²œë„ |
|------|---------|------------|----------|----------------|--------||
| **Unclip Ratio** | 0.2h | â­ | +0.3%p | 1.50 %p/h | â­â­â­â­â­ |
| **í›„ì²˜ë¦¬ ë¯¸ì„¸ì¡°ì •** | 0.1h | â­ | +0.1%p | 1.00 %p/h | â­â­â­â­â­ |
| **ğŸ†• Tiny Box Loss** | 2h | â­â­â­ | +0.6%p | 0.30 %p/h | â­â­â­â­â­ |
| **WildReceipt** | 3h | â­â­ | +0.4%p | 0.13 %p/h | â­â­â­â­ |
| **ğŸ†• 13K Pre-train** | 8h | â­â­â­ | +1.0%p | 0.13 %p/h | â­â­â­â­â­ |
| **ğŸ†• 2ë‹¨ê³„ í•™ìŠµ** | 6h | â­â­â­ | +0.5%p | 0.08 %p/h | â­â­â­â­ |
| **ğŸ†• P2 FPN** | 5h | â­â­â­â­ | +0.4%p | 0.08 %p/h | â­â­â­â­ |
| **Multi-Scale TTA** | 0.5h | â­â­â­ | +0.3%p | 0.60 %p/h | â­â­â­â­â­ |
| **EfficientNet-B4** | 3h | â­â­ | +0.6%p | 0.20 %p/h | â­â­â­â­ |
| **Swin Transformer** | 6h | â­â­â­â­ | +0.7%p | 0.12 %p/h | â­â­â­ |
| **Pseudo-Label** | 8h | â­â­â­â­ | +0.4%p | 0.05 %p/h | â­â­ |

**ìµœê³  ROI Top 5** (ğŸ†• = ì‹ ê·œ ì „ëµ):
1. â­ Unclip Ratio ìµœì í™”: 1.50 %p/h
2. â­ í›„ì²˜ë¦¬ ë¯¸ì„¸ì¡°ì •: 1.00 %p/h
3. â­ Multi-Scale TTA: 0.60 %p/h
4. ğŸ†• **Tiny Box Loss ê°€ì¤‘ì¹˜**: 0.30 %p/h  â† ì‹ ê·œ, ê³ íš¨ê³¼!
5. ğŸ†• **13K Pre-training**: 0.13 %p/h  â† ì ˆëŒ€ íš¨ê³¼ ìµœëŒ€!

**ì£¼ëª©**: Tiny Box LossëŠ” ROIë„ ë†’ê³  ì ˆëŒ€ íš¨ê³¼(+0.6%p)ë„ í¬ë¯€ë¡œ 1ìˆœìœ„ ê¶Œì¥!

---

## ğŸ”¬ Part 9: 56_ERROR_ANALYSIS ì—°ê³„ ìµœì í™”

### ì—ëŸ¬ ì¼€ì´ìŠ¤ë³„ ëŒ€ì‘ ì „ëµ

#### 1. ê³ ë°€ë„ ì´ë¯¸ì§€ (170.7+ boxes/Mpx)
**ë¬¸ì œ**: 538 boxes/Mpx ìµœëŒ€, False Negative ìœ„í—˜  
**ëŒ€ì‘ ì „ëµ**:
- âœ… Unclip Ratio â†‘ (2.0 â†’ 2.05~2.10)
- âœ… Thresh â†“ (0.215 â†’ 0.210)
- âœ… Multi-Scale TTA (1088px ì¶”ê°€)

#### 2. ì†Œí˜• ë°•ìŠ¤ (ë©´ì  < 40pxÂ²)
**ë¬¸ì œ**: 20pxÂ² ìµœì†Œ, ì‘ì€ í…ìŠ¤íŠ¸ ê²€ì¶œ ì‹¤íŒ¨  
**ëŒ€ì‘ ì „ëµ**:
- âœ… Multi-Scale TTA (1088pxë¡œ í•´ìƒë„ ìƒìŠ¹)
- âœ… Deformable Conv (ì‘ì€ ì˜ì—­ adaptive sampling)
- âœ… Box Threshold â†“ (0.415 â†’ 0.410)

#### 3. ê·¹ë‹¨ì  ì¢…íš¡ë¹„ (AR > 6.0)
**ë¬¸ì œ**: AR=7.68 ìµœëŒ€, Anchor box ë§¤ì¹­ ì‹¤íŒ¨  
**ëŒ€ì‘ ì „ëµ**:
- âœ… Anchor Ratio ì¶”ê°€ (0.13, 7.5)
- âœ… Deformable Conv
- âœ… WildReceipt ë°ì´í„° (ê¸´ í…ìŠ¤íŠ¸ ë‹¤ìˆ˜)

#### 4. ë‹¤ìˆ˜ ë°•ìŠ¤ (155+ boxes/image)
**ë¬¸ì œ**: 276ê°œ ìµœëŒ€, NMS ë³µì¡ë„  
**ëŒ€ì‘ ì „ëµ**:
- âœ… Max Candidates â†‘ (500 â†’ 700)
- âœ… NMS IoU threshold ì¡°ì • (0.5 â†’ 0.6)

---

## ğŸ“‹ Part 10: ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1 ì²´í¬ë¦¬ìŠ¤íŠ¸ (1ì£¼ì¼)

```
â–¡ Day 1: Unclip Ratio ìµœì í™”
  â–¡ Grid Search ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (30ë¶„)
  â–¡ Validation set ì‹¤í–‰ (10ë¶„)
  â–¡ ìµœì ê°’ í™•ì • ë° config ì—…ë°ì´íŠ¸ (5ë¶„)
  
â–¡ Day 1: Tiny Box Loss ê°€ì¤‘ì¹˜ êµ¬í˜„ ğŸ†•
  â–¡ DBLossWeighted í´ë˜ìŠ¤ êµ¬í˜„ (1ì‹œê°„)
  â–¡ Config íŒŒì¼ ì„¤ì • (30ë¶„)
  â–¡ Fine-tuning í›ˆë ¨ ì‹¤í–‰ (1ì‹œê°„)
  
â–¡ Day 1: í›„ì²˜ë¦¬ ë¯¸ì„¸ì¡°ì •
  â–¡ Thresh/Box_Thresh Grid Search (5ë¶„)
  â–¡ ìµœì  ì¡°í•© ì„ ì • ë° Test set ì˜ˆì¸¡ (2ë¶„)
  
â–¡ Day 2: ëŒ€ê·œëª¨ ì™¸ë¶€ ë°ì´í„° ì¤€ë¹„ ğŸ†•
  â–¡ WildReceipt + ICDAR ë‹¤ìš´ë¡œë“œ (1ì‹œê°„)
  â–¡ í¬ë§· ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (1ì‹œê°„)
  â–¡ ë³€í™˜ ì‹¤í–‰ ë° ê²€ì¦ (1ì‹œê°„)
  â–¡ ë°ì´í„° ë³‘í•© (30ë¶„)
  
â–¡ Day 2-3: ì¬í›ˆë ¨
  â–¡ í•™ìŠµ ì‹œì‘ (overnight, 3ì‹œê°„)
  â–¡ Validation ì„±ëŠ¥ í™•ì¸
  â–¡ Test set ì˜ˆì¸¡ ë° ì œì¶œ
```

### Phase 2 ì²´í¬ë¦¬ìŠ¤íŠ¸ (2ì£¼ì°¨)

```
â–¡ 13K Pre-training ğŸ†•
  â–¡ ëª¨ë“  ì™¸ë¶€ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (2ì‹œê°„)
  â–¡ í†µí•© í¬ë§· ë³€í™˜ (3ì‹œê°„)
  â–¡ Pre-training í•™ìŠµ (3ì‹œê°„)
  
â–¡ 2ë‹¨ê³„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ğŸ†•
  â–¡ Stage 1: 1024px Pre-training (3ì‹œê°„)
  â–¡ Stage 2: 1280px Fine-tuning (3ì‹œê°„)
  â–¡ ì„±ëŠ¥ ë¹„êµ ë¶„ì„
  
â–¡ P2 Feature Pyramid êµ¬í˜„ ğŸ†•
  â–¡ FPNDecoderWithP2 í´ë˜ìŠ¤ êµ¬í˜„ (1ì‹œê°„)
  â–¡ Config ì„¤ì • ë° í…ŒìŠ¤íŠ¸
  â–¡ í›ˆë ¨ ì‹¤í–‰ (4ì‹œê°„)
  
â–¡ Multi-Scale TTA
  â–¡ TTA ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (1ì‹œê°„)
  â–¡ 3-Scale ì˜ˆì¸¡ ì‹¤í–‰ (30ë¶„)
  â–¡ WBF ë³‘í•© ë° ì œì¶œ (5ë¶„)
  
â–¡ EfficientNet-B4 í•™ìŠµ
  â–¡ Config íŒŒì¼ ìƒì„±
  â–¡ í•™ìŠµ ì‹¤í–‰ (3ì‹œê°„)
  â–¡ Validation í‰ê°€
  
â–¡ í˜¼í•© ì•™ìƒë¸”
  â–¡ HRNet + EffNet WBF êµ¬í˜„
  â–¡ IoU threshold ì‹¤í—˜ (0.6, 0.7, 0.8)
  â–¡ ìµœê³  ì„±ëŠ¥ ì¡°í•© ì œì¶œ
```

---

## ğŸ“ Part 11: í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ë° ì£¼ì˜ì‚¬í•­

### âœ… DO: ì‹¤í–‰ ê¶Œì¥

1. **ì´ˆê¸° ë¹ ë¥¸ ê°œì„ ì— ì§‘ì¤‘**
   - Unclip ratio, í›„ì²˜ë¦¬ ì¡°ì •ì€ íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ ìµœê³ 
   
2. **ë°ì´í„° ë‹¤ì–‘ì„± í™•ë³´**
   - WildReceipt ì¶”ê°€ë¡œ ì—ëŸ¬ ì¼€ì´ìŠ¤ ì§ì ‘ ëŒ€ì‘
   
3. **Multi-Scale TTA í™œìš©**
   - HFlipë³´ë‹¤ ì•ˆì „í•˜ê³  íš¨ê³¼ì 
   
4. **ë°±ë³¸ ë‹¤ì–‘ì„± ì‹¤í—˜**
   - EfficientNet, Swin Transformer ì‹œë„
   
5. **ì—ëŸ¬ ë¶„ì„ ê¸°ë°˜ ìµœì í™”**
   - 56_ERROR_ANALYSISì˜ 4ê°€ì§€ ì¹´í…Œê³ ë¦¬ ì§ì ‘ ëŒ€ì‘

### âŒ DON'T: ì‹¤í–‰ ë¹„ì¶”ì²œ

1. **Voting/WBF ì•™ìƒë¸” ê¸ˆì§€**
   - 98% ì´ìƒ ëª¨ë¸ì€ ì•™ìƒë¸” ì—­íš¨ê³¼ (53_ensemble_failure)
   
2. **HFlip TTA êµ¬í˜„ ê¸ˆì§€**
   - ì¢Œí‘œ ë³€í™˜ ë³µì¡ì„±, 08_tta_failure ì¬ë°œ ìœ„í—˜
   
3. **1536px+ ì´ˆê³ í•´ìƒë„ ê¸ˆì§€**
   - 1280px ì´ìƒì€ íš¨ê³¼ ì—†ìŒ (99_comprehensive)
   
4. **ResNet ê³„ì—´ ì¶”ê°€ ì‹¤í—˜ ê¸ˆì§€**
   - HRNetì´ ì´ë¯¸ ì´ˆì›”
   
5. **ê³¼ë„í•œ Grid Search**
   - ì´ë¯¸ ìµœì í™”ë¨, ì¶”ê°€ íš¨ê³¼ ë¯¸ë¯¸

---

## ğŸ“ Part 12: ê²°ë¡  ë° ê¶Œì¥ ì‹¤í–‰ ê²½ë¡œ

### ìµœì¢… ê¶Œì¥ ì‹œë‚˜ë¦¬ì˜¤

**ë³´ìˆ˜ì  ê²½ë¡œ (99.0% ëª©í‘œ, 1ì£¼ì¼)**:
```
1. Unclip Ratio (10ë¶„)        â†’ 98.83%
2. í›„ì²˜ë¦¬ ë¯¸ì„¸ì¡°ì • (5ë¶„)       â†’ 98.88%
3. WildReceipt ì¬í›ˆë ¨ (3ì‹œê°„)  â†’ 99.18%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ ì†Œìš”: 3.25ì‹œê°„
ì˜ˆìƒ ê²°ê³¼: 99.0~99.2% âœ…
```

**ì ê·¹ì  ê²½ë¡œ (99.5% ëª©í‘œ, 2ì£¼ì¼)**:
```
ë³´ìˆ˜ì  ê²½ë¡œ (99.18%)
  + Multi-Scale TTA (30ë¶„)     â†’ 99.38%
  + EfficientNet-B4 (3ì‹œê°„)    â†’ 99.42%
  + í˜¼í•© ì•™ìƒë¸” (1ì‹œê°„)         â†’ 99.58%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ ì†Œìš”: 7.75ì‹œê°„
ì˜ˆìƒ ê²°ê³¼: 99.4~99.6% âœ…âœ…
```

**í˜ì‹ ì  ê²½ë¡œ (99.8%+ ëª©í‘œ, 4ì£¼ì¼)**:
```
ì ê·¹ì  ê²½ë¡œ (99.58%)
  + Swin Transformer (6ì‹œê°„)   â†’ 99.68%
  + Pseudo-Labeling (8ì‹œê°„)    â†’ 99.78%
  + Deformable Conv (5ì‹œê°„)    â†’ 99.85%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ ì†Œìš”: 26.75ì‹œê°„ (ì•½ 3.5ì¼ GPU ì‹œê°„)
ì˜ˆìƒ ê²°ê³¼: 99.7~99.9% âœ…âœ…âœ…
```

### ìµœì¢… ì˜ì‚¬ê²°ì •

**ëª©í‘œê°€ 99.0% ë‹¬ì„±ì´ë¼ë©´**:
â†’ **ë³´ìˆ˜ì  ê²½ë¡œ** ì‹¤í–‰ (1ì£¼ì¼, ì„±ê³µ í™•ë¥  95%)
   íŠ¹íˆ **Tiny Box Loss**ê°€ í•µì‹¬! ğŸ†•

**ëª©í‘œê°€ 99.5%+ ê·¹í•œ ìµœì í™”ë¼ë©´**:
â†’ **ì ê·¹ì  ê²½ë¡œ** ì‹¤í–‰ (2ì£¼ì¼, ì„±ê³µ í™•ë¥  80%)
   13K Pre-training + 2ë‹¨ê³„ í•™ìŠµ + P2 FPN ì¡°í•© ğŸ†•

**ì—°êµ¬/ì‹¤í—˜ ëª©ì ì´ë¼ë©´**:
â†’ **í˜ì‹ ì  ê²½ë¡œ** ì‹¤í–‰ (4ì£¼ì¼, ì„±ê³µ í™•ë¥  60%)

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

- `99_comprehensive_ocr_insights_report.md`: 6ë‹¨ê³„ ëª¨ë©˜í…€ ë¶„ì„
- `56_ERROR_ANALYSIS_REPORT.md`: ì—ëŸ¬ ì¼€ì´ìŠ¤ ì‹ë³„
- `53_ensemble_failure_analysis_report.md`: ì•™ìƒë¸” ì‹¤íŒ¨ êµí›ˆ
- `08_tta_failure_analysis.md`: TTA êµ¬í˜„ ì£¼ì˜ì‚¬í•­
- `16_Leaderboard score maximization`: EfficientNet ì „ëµ
- `42_SROIE_CORD_WildReceipt_GT_í™•ë³´_ê°€ì´ë“œ.md`: ì™¸ë¶€ ë°ì´í„° ê°€ì´ë“œ

---

**ì‘ì„±ì**: GitHub Copilot  
**ì‘ì„±ì¼**: 2026-02-13  
**ë²„ì „**: v2.0 (ì‹ ê·œ ì „ëµ 4ê°œ ì¶”ê°€: Tiny Box Loss, 13K Pre-training, 2ë‹¨ê³„ í•™ìŠµ, P2 FPN)  
**ë‹¤ìŒ ì—…ë°ì´íŠ¸**: Phase 1 ì‹¤í–‰ í›„ ê²°ê³¼ ë°˜ì˜

**v2.0 ì—…ë°ì´íŠ¸ ë‚´ì—­**:
- ğŸ†• Tiny Box Loss ê°€ì¤‘ì¹˜ ë¶€ì—¬ ì „ëµ ì¶”ê°€ (Tier 1)
- ğŸ†• ëŒ€ê·œëª¨ 13K ì™¸ë¶€ ë°ì´í„° Pre-training ì „ëµ ì¶”ê°€ (Tier 2)
- ğŸ†• 2ë‹¨ê³„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (Curriculum Learning) ì¶”ê°€ (Tier 2)
- ğŸ†• P2 Feature Pyramid ë ˆë²¨ ì¶”ê°€ ì „ëµ ì¶”ê°€ (Tier 2)
- ì´ ì „ëµ ìˆ˜: 21ê°œ â†’ 25ê°œë¡œ í™•ì¥
- ì˜ˆìƒ ê°œì„ í­: +0.6~1.2%p â†’ +1.5~2.5%pë¡œ ìƒí–¥

---

## ğŸš€ ì¦‰ì‹œ ì‹¤í–‰ ëª…ë ¹ì–´ ëª¨ìŒ

```bash
# === Phase 1: Quick Wins (5.25ì‹œê°„) ğŸ”¥ ===

# 1. Unclip Ratio ìµœì í™” (10ë¶„)
cd /data/ephemeral/home/baseline_code
python scripts/optimize_unclip_ratio.py \
  --checkpoint checkpoints/kfold/fold_3/fold3_best.ckpt \
  --val_json kfold_results/fold_3/val.json \
  --ratio_range 1.85 2.15 --step 0.05

# 2. ğŸ†• Tiny Box Loss ê°€ì¤‘ì¹˜ êµ¬í˜„ ë° Fine-tuning (2ì‹œê°„)
# DBLossWeighted í´ë˜ìŠ¤ êµ¬í˜„ (ocr/models/loss/db_loss_weighted.py)
python runners/train.py \
    preset=hrnet_w44_1024_external_weighted_loss \
    model.loss.name=DBLossWeighted \
    model.loss.tiny_weight=10.0 \
    model.loss.small_weight=5.0 \
    ++datasets.train_dataset.annotation_path=train_augmented_full.json \
    ++datasets.val_dataset.annotation_path=kfold_results/fold_3/val.json \
    exp_name=hrnet_w44_tiny_box_weighted \
    trainer.max_epochs=10

# 3. í›„ì²˜ë¦¬ ë¯¸ì„¸ì¡°ì • (5ë¶„)
python scripts/postprocess_grid_search.py \
  --checkpoint checkpoints/hrnet_w44_tiny_box_weighted/best.ckpt \
  --thresh_range 0.210 0.220 --thresh_step 0.002 \
  --box_thresh_range 0.410 0.420 --box_thresh_step 0.005

# 4. WildReceipt + ICDAR ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ (3ì‹œê°„)
cd /data/ephemeral/home/data/pseudo_label
git clone https://github.com/clovaai/wildreceipt.git
wget https://rrc.cvc.uab.es/downloads/icdar2019_task1.zip && unzip icdar2019_task1.zip

cd /data/ephemeral/home/baseline_code
python scripts/convert_external_datasets.py \
  --wildreceipt ../data/pseudo_label/wildreceipt \
  --icdar ../data/pseudo_label/icdar2019_task1 \
  --output ../data/datasets/wildreceipt_icdar.json

python scripts/merge_datasets.py \
  --inputs train_augmented_full.json wildreceipt_icdar.json \
  --output train_extended_wildreceipt.json

# 5. ì¬í›ˆë ¨ (overnight)
python runners/train.py \
    preset=hrnet_w44_1024_extended \
    ++datasets.train_dataset.annotation_path=train_extended_wildreceipt.json \
    exp_name=hrnet_w44_extended_final \
    trainer.max_epochs=18

# === Phase 2: ê³ íš¨ê³¼ ì‹¤í—˜ (25ì‹œê°„ ì¶”ê°€) â­ ===

# 6. ğŸ†• ëŒ€ê·œëª¨ 13K Pre-training (8ì‹œê°„)
# ëª¨ë“  ì™¸ë¶€ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° í†µí•©
python scripts/convert_all_external_datasets.py \
  --sroie ../data/pseudo_label/sroie \
  --cord ../data/pseudo_label/cord-v2 \
  --wildreceipt ../data/pseudo_label/wildreceipt \
  --icdar ../data/pseudo_label/icdar2019_task1 \
  --output ../data/datasets/external_unified_13k.json

python runners/train.py \
    preset=hrnet_w44_1024_pretrain \
    ++datasets.train_dataset.annotation_path=external_unified_13k.json \
    exp_name=hrnet_w44_pretrain_13k \
    trainer.max_epochs=15

# 7. ğŸ†• 2ë‹¨ê³„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (6ì‹œê°„)
# Stage 1: 1024px Pre-training
python runners/train.py \
    preset=hrnet_w44_1024_stage1 \
    ++datasets.train_dataset.annotation_path=train_mega_dataset_13k.json \
    datasets.image_size=1024 \
    optimizer.lr=0.001 \
    trainer.max_epochs=15 \
    exp_name=stage1_pretrain_1024px_13k

# Stage 2: 1280px Fine-tuning
python runners/train.py \
    preset=hrnet_w44_1280_stage2 \
    ++resume_from=outputs/stage1_pretrain_1024px_13k/checkpoints/last.ckpt \
    ++datasets.train_dataset.annotation_path=train.json \
    datasets.image_size=1280 \
    optimizer.lr=0.0001 \
    trainer.max_epochs=8 \
    exp_name=stage2_finetune_1280px_competition

# 8. ğŸ†• P2 Feature Pyramid ì¶”ê°€ (5ì‹œê°„)
# FPNDecoderWithP2 êµ¬í˜„ í›„
python runners/train.py \
    preset=hrnet_w44_1024_fpn_p2 \
    model.decoder.name=FPNDecoderWithP2 \
    ++datasets.train_dataset.annotation_path=train_augmented_full.json \
    dataloaders.train_dataloader.batch_size=2 \
    trainer.max_epochs=12 \
    exp_name=hrnet_w44_fpn_p2_small_objects

# 9. Multi-Scale TTA (30ë¶„)
python scripts/predict_multiscale_tta.py \
  --checkpoint checkpoints/stage2_finetune_1280px_competition/best.ckpt \
  --scales 960 1024 1088 \
  --weights 0.25 0.50 0.25

# 10. EfficientNet-B4 í•™ìŠµ (3ì‹œê°„)
python runners/train.py \
    preset=efficientnet_b4_1024 \
    ++datasets.train_dataset.annotation_path=train_extended_wildreceipt.json \
    exp_name=efficientnet_b4_extended

# 11. í˜¼í•© ì•™ìƒë¸” (1ì‹œê°„)
python scripts/mixed_backbone_ensemble.py \
  --model1 checkpoints/stage2_finetune_1280px_competition/best.ckpt \
  --model2 checkpoints/efficientnet_b4_extended/best.ckpt \
  --weights 0.55 0.45 --iou_thr 0.7
```

**ì˜ˆìƒ ìµœì¢… ì„±ëŠ¥: 99.7~100%+ H-Mean** ğŸ¯ğŸ¯ğŸ¯

**ğŸ†• ì‹ ê·œ ì „ëµ ìš”ì•½**:
1. **Tiny Box Loss** - ì‘ì€ ë°•ìŠ¤ ê²€ì¶œ ê°•í™”, +0.4~0.7%p
2. **13K Pre-training** - ëŒ€ê·œëª¨ ë°ì´í„° ì¼ë°˜í™”, +0.8~1.2%p
3. **2ë‹¨ê³„ í•™ìŠµ** - Curriculum Learning, +0.3~0.6%p
4. **P2 FPN** - ê³ í•´ìƒë„ ë¯¸ì„¸ í…ìŠ¤íŠ¸, +0.2~0.5%p
