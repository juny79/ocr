# 앙상블 실패 분석 보고서

**날짜:** 2026년 2월 11일  
**목표:** 다중 모델 앙상블을 통해 H-Mean 0.9854에서 성능 향상  
**결과:** 완전 실패 - 모든 앙상블 시도에서 성능 저하  
**상태:** ❌ 앙상블 접근법 포기

---

## 요약

3개의 OCR 탐지 모델 예측을 결합하기 위해 3가지 앙상블 방법을 시도:
- **Model 1 (리더보드 최고)**: H-Mean 0.9854, 44,628개 박스
- **Model 2 (Sweep 1위)**: H-Mean 0.9798, 44,505개 박스  
- **Model 3 (Sweep 2위)**: H-Mean 0.9787, 43,918개 박스

**모든 앙상블 시도에서 심각한 성능 저하 발생:**
- NMS 앙상블: H-Mean 0.8878 (-9.76%p)
- WBF 앙상블: H-Mean 0.8739 (-11.15%p)

**일관된 패턴:** 모든 경우에서 Recall이 0.98에서 0.82로 하락(~16%p), 근본적인 방법론적 결함 시사.

---

## 1. 첫 번째 앙상블 시도: Greedy NMS

### 방법
- **접근법**: IoU threshold 0.5를 사용한 Greedy clustering
- **로직**: 겹치는 박스들을 클러스터링하고 가중 평균으로 병합
- **가중치**: 0.6 (Model 1), 0.25 (Model 2), 0.15 (Model 3)

### 구현
```python
# Greedy NMS clustering (결함 있음)
cluster = [Box_A]
for box in remaining_boxes:
    if IoU(Box_A, box) > 0.5:
        cluster.append(box)  # Box_A하고만 비교
```

### 결과
| 지표 | 점수 | vs. 최고 모델 |
|--------|-------|----------------|
| H-Mean | 0.8878 | -9.76%p |
| Precision | 0.9647 | -2.07%p |
| Recall | 0.8237 | -15.63%p |

**파일:** `ensemble_3models.csv` (초기 19MB, 다운샘플 후 7.4MB)

### 발견된 치명적 문제
**Polygon 폭발**: 병합된 박스가 예상되는 4-20개 점 대신 14-54개 점을 가짐

**샘플 박스 분석:**
```
Model 1 원본: 54개 점, 범위=[388-544, 1126-1166] (156×40 px)
앙상블 결과: 50개 점, 범위=[433-506, 1136-1156] (73×20 px)
```

**근본 원인:** Greedy 알고리즘이 관련 없는 박스들을 병합:
- Box A ↔ Box B 겹침 (IoU 0.6)
- Box A ↔ Box C 겹침 (IoU 0.5)
- Box B ↔ Box C **겹치지 않음** (IoU 0.1)
- 세 박스 모두 하나의 클러스터로 병합 → 잘못된 융합

---

## 2. 두 번째 시도: 수정된 클러스터링

### 방법
- **수정사항**: 각 클러스터에 모델당 최대 1개 박스로 제한
- **로직**: 과도한 병합을 방지하기 위한 모델 인식 클러스터링
- **동일한 가중치 및 IoU threshold**

### 구현 변경사항
```python
# 모델 인식 클러스터링
for model_idx in range(num_models):
    best_match = None
    best_iou = iou_threshold
    
    for box in model_boxes[model_idx]:
        if box not in used:
            iou = calculate_iou(anchor_box, box)
            if iou > best_iou:
                best_match = box
                best_iou = iou
    
    if best_match:
        cluster.append(best_match)
```

### 결과
**파일:** `ensemble_fixed.json` → 45,856개 박스

**Polygon 분석:**
- 96.7% 박스: 4개 점 ✓
- 3.3% 박스: 8-190개 점 ❌

**박스당 평균 점 개수:** 4.8 (원본 모델: 23.0)

**문제:** 과도한 정규화로 polygon 형태의 충실도 파괴

---

## 3. 다운샘플링 보정

### 방법
- 원본 polygon 형태 유지
- 25개 점 초과 polygon만 다운샘플
- 좌표 정밀도 유지

### 결과
**파일:** `ensemble_downsampled.csv` (7.4MB)

| 지표 | 점수 | vs. 최고 모델 |
|--------|-------|----------------|
| H-Mean | 0.9979 | **-9.75%p** |
| Precision | 0.9648 | -2.06%p |
| Recall | 0.8237 | **-15.63%p** |

**통계:**
- 총 박스: 45,033개
- 박스당 평균 점: 21.1 (원본 23.0에 근접)
- 박스 크기 여전히 압축됨: ~50% 감소

### 중요 발견
**박스 축소 확인:**
```
원본 Model 1 박스: 156×40 픽셀
앙상블 박스:      73×20 픽셀 (너비 53%, 높이 50% 감소)
```

---

## 4. 최종 시도: WBF (Weighted Boxes Fusion)

### 방법
- **접근법**: 모든 박스 유지, 겹치는 것만 융합
- **이론**: 삭제 방지, 개별 탐지 보존
- **구현**: 겹치는 박스에 대한 신뢰도 가중 평균

### 구현
```python
# WBF 클러스터링
clusters = []
for each box:
    find_overlapping_boxes(iou_threshold=0.5)
    if has_overlaps:
        fuse_with_confidence_weights()
    else:
        keep_original()
```

### 결과
**파일:** `ensemble_wbf.csv` (8.1MB)

| 지표 | 점수 | vs. 최고 모델 |
|--------|-------|----------------|
| H-Mean | 0.8739 | **-11.15%p** |
| Precision | 0.9338 | -5.16%p |
| Recall | 0.8234 | **-16.66%p** |

**통계:**
- 총 박스: 46,019개 (최고 모델 대비 +1,391)
- 박스당 평균 점: 20 (잘 보존됨)
- 실행 시간: ~15분

**박스 분석:**
```
원본 Model 1: x=[388-544], y=[1126-1166] (156×40 px)
WBF 결과:     x=[431-505], y=[1136-1156] (74×20 px)
```

**결과:** polygon 형태를 보존했음에도 모든 시도 중 최악의 성능.

---

## 5. 근본 원인 분석

### 문제 1: 부적절한 IoU Threshold
**텍스트 탐지에 IoU 0.5는 너무 낮음:**

```
시나리오: 약간 수직으로 겹치는 두 개의 별도 텍스트 라인

┌────────────────────────┐  Line 1: "영수증 상단 텍스트"
└────────────────────────┘
  ↓ 10px 수직 간격
┌──────┐ ┌──────┐          Line 2: "날짜   금액"
└──────┘ └──────┘

IoU 0.5 결과:
┌───────────────┐  병합된 박스 (잘못됨!)
└───────────────┘
```

**왜 이런 일이 발생하는가:**
- 텍스트 박스는 종종 가로로 길게 늘어남
- 10-20px의 수직 겹침이 IoU > 0.5를 생성할 수 있음
- 다른 라인들이 병합됨 → 박스 중심 이동 → 크기 감소

### 문제 2: 통계적 평균의 편향

**다른 위치의 박스를 병합할 때:**

```python
# Box A: [100, 200] → [500, 220] (400×20)
# Box B: [150, 240] → [300, 260] (150×20)
# 가중 평균 (0.6, 0.4):

result_x = 0.6*[100,500] + 0.4*[150,300] = [120, 420]  # 너비: 300 (vs 400)
result_y = 0.6*[200,220] + 0.4*[240,260] = [216, 236]  # 높이: 20 (OK)
```

**Box A (정확함)가 Box B (부정확함) 쪽으로 "끌려감" → 정확도 감소**

### 문제 3: False Positive 누적

**모델들의 다른 탐지 패턴:**
- Model 1: 보수적 (높은 precision, 낮은 recall)
- Model 2: 중간 (균형잡힘)
- Model 3: 공격적 (높은 recall, 낮은 precision)

**앙상블 결과:**
- 병합된 박스: 잘못된 위치로 끌려감
- 병합되지 않은 박스: Model 3의 false positive 추가
- 순효과: precision과 recall 모두 감소

---

## 6. 성능 저하 패턴

### 모든 앙상블 시도에서 일관된 지표

| 앙상블 유형 | H-Mean | Precision | Recall | 최고 대비 차이 |
|---------------|--------|-----------|--------|----------------|
| 리더보드 최고 | **0.9854** | **0.9853** | **0.9855** | 기준선 |
| NMS (원본) | 0.8878 | 0.9647 | 0.8237 | -9.76%p |
| NMS (다운샘플) | 0.8979 | 0.9648 | 0.8237 | -8.75%p |
| WBF | 0.8739 | 0.9338 | 0.8234 | -11.15%p |

**주요 관찰:** 
- Recall이 **일관되게 ~0.82**로 하락 (-16%p)
- Precision은 적당히 하락 (2-5%p)
- H-Mean은 Recall 저하를 따름

### Recall이 일관되게 하락하는 이유

**좌표 분석을 통해 검증된 가설:**

1. **Ground truth 박스:** 일반적으로 15-25개 점, 정밀한 경계
2. **앙상블 박스:** 평균된 좌표, 이동된 중심
3. **IoU 매칭:** 이동된 박스가 ground truth와 IoU threshold 미달
4. **결과:** 정확한 탐지의 ~16%가 이제 IoU < 평가 threshold

---

## 7. 교훈

### ❌ 잘못된 점

1. **가정 실패:** "더 많은 박스 = 더 나은 커버리지"
   - 현실: 잘못된 박스 위치 = 더 많은 오류

2. **IoU threshold 잘못 설정:** 텍스트 탐지에 0.5는 부적절
   - 텍스트 박스는 길게 늘어남 (10:1 종횡비)
   - 작은 수직 겹침도 높은 IoU 생성
   - 0.7-0.8 사용하거나 수평 IoU만 사용해야 함

3. **맹목적 평균화:** 가중 평균은 모든 입력이 "정확함"을 가정
   - 모델들이 다른 오류를 만듦
   - 정확함 + 부정확함 평균 = 덜 정확함

4. **Polygon 형태 복잡도 무시:**
   - 원본 모델은 촘촘한 경계를 위해 15-25개 점 사용
   - 다운샘플링이 기하학적 정보 손실
   - 정확한 polygon 토폴로지 보존해야 함

### ✓ 작동할 수 있는 것 (이론적으로)

1. **융합 없는 투표 기반 앙상블:**
   - 모든 모델의 모든 박스 유지
   - 정확한 중복만 제거 (IoU > 0.95)
   - 평가 지표가 어느 것이 정확한지 결정하도록

2. **신뢰도 기반 필터링:**
   - 가능하다면 모델 신뢰도 점수 사용
   - 병합 전 낮은 신뢰도 탐지 제거
   - 높은 신뢰도 일치만 융합

3. **공간 제약:**
   - 다른 텍스트 라인의 박스 병합 금지
   - 더 엄격한 수평 정렬 검사 사용
   - 최소 박스 크기 제약 강제

4. **이미지별 적응형 threshold:**
   - 밀집 텍스트 영역: 높은 IoU threshold
   - 희소 영역: 낮은 threshold
   - 융합 전 레이아웃 분석

---

## 8. 대안 접근법 (구현되지 않음)

### 옵션 A: Union 앙상블 (융합 없음)
```python
# 병합 없이 모든 박스 결합
all_boxes = model1_boxes + model2_boxes + model3_boxes
remove_exact_duplicates(iou_threshold=0.95)
return all_boxes  # 총 133,000개 이상 박스
```

**예상:** 높은 recall, 훨씬 낮은 precision  
**미구현:** 압도적인 false positive 위험

### 옵션 B: 조건부 융합
```python
if len(cluster) == 1:
    keep_original()  # 일치 없음 = 탐지 신뢰
elif all_models_agree():
    use_weighted_average()  # 높은 신뢰도 융합
else:
    use_highest_confidence_model()  # 부분 일치
```

**예상:** 선택적 개선  
**미구현:** 모델 신뢰도 점수 필요 (사용 불가)

### 옵션 C: Test-Time Augmentation (TTA)
```python
# 증강을 사용한 단일 최고 모델
predictions = []
for transform in [original, hflip, vflip, rotate90]:
    pred = model.predict(transform(image))
    predictions.append(inverse_transform(pred))

return fuse_same_model_predictions(predictions, iou=0.8)
```

**예상:** +0.2-0.5%p 개선  
**미구현:** 시간 제약 (2-3시간 필요)

---

## 9. 자원 소비

### 계산 비용

| 단계 | 시간 | CPU | 메모리 | 출력 크기 |
|-------|------|-----|--------|-------------|
| Greedy NMS | 4분 | 100% | 600MB | 78MB JSON |
| Fixed clustering | 15분 | 100% | 660MB | 5.5MB JSON |
| Downsampling | 30초 | - | - | 67MB JSON |
| WBF | **15분** | 100% | 650MB | 39MB JSON |
| **총계** | **~35분** | - | - | - |

### 저장 비용

**생성된 앙상블 파일:**
```
ensemble_3models.json           78MB
ensemble_3models_rounded.json   67MB
ensemble_fixed.json             5.5MB
ensemble_quad.json              5.1MB
ensemble_downsampled.json       67MB
ensemble_wbf.json              39MB
ensemble_wbf_rounded.json      31MB

총계: 292.6MB
```

**CSV 제출물:**
```
ensemble_3models.csv            19MB
ensemble_3models_rounded.csv    7.9MB
ensemble_downsampled.csv        7.4MB
ensemble_wbf.csv                8.1MB

총계: 42.4MB
```

---

## 10. 결론

### 성능 요약

**단일 최고 모델 (앙상블 없음):**
- H-Mean: **0.9854**
- Precision: 0.9853
- Recall: 0.9855
- **상태: 권장 ✅**

**최고 앙상블 시도 (NMS 다운샘플):**
- H-Mean: 0.8979 (-8.75%p)
- Precision: 0.9648
- Recall: 0.8237
- **상태: 권장하지 않음 ❌**

### 최종 평가

**다음 이유로 이 작업에 앙상블은 역효과:**

1. ✗ 텍스트 탐지는 정밀한 경계 필요 (중심점이 아님)
2. ✗ 가중 평균이 공간 정확도 저하
3. ✗ IoU 기반 융합이 관련 없는 텍스트 라인 병합
4. ✗ 모델 불일치는 합의 기회가 아닌 어려운 사례 표시
5. ✗ 세 모델 모두 이미 개별적으로 >0.97 H-Mean 달성

**권장사항:** 앙상블 포기, 다음에 집중:
- Loss 함수 최적화 (+0.6-1.6%p 예상)
- 후처리 파라미터 튜닝 (Grid Search 완료)
- Test-Time Augmentation (+0.2-0.5%p 예상)
- 데이터 증강 + 재학습

---

## 11. 권장되는 다음 단계

### 즉각적인 조치

1. **단일 최고 모델로 복귀** (0.9854)
   - 파일: `outputs/leaderboard_best_for_ensemble/submissions/20260210_225341.json`
   - 더 이상의 앙상블 시도 없음

2. **Grid Search 결과 활용**
   - Phase 1 후처리 최적화 이미 완료
   - 최적 thresh/box_thresh 조합 적용

3. **앙상블 아티팩트 정리**
   - 실패한 앙상블 파일 290MB+ 삭제
   - 분석 보고서만 보존

### 장기 개선사항

1. **Loss 파라미터 최적화** [예상시간: 4시간]
   ```yaml
   negative_ratio: 2.824
   prob_map_loss_weight: 3.591
   ```
   예상: H-Mean 0.9860-0.9870 (+0.6-1.6%p)

2. **Test-Time Augmentation** [예상시간: 2시간]
   - 4방향 증강 (flip/rotate)
   - 동일 모델 융합 (안전)
   예상: H-Mean +0.2-0.5%p

3. **모델 아키텍처 업그레이드** [예상시간: 12시간 이상]
   - 다른 백본 시도 (HRNet-W48, ResNet101)
   - 탐지 헤드 실험
   예상: 광범위한 테스트 필요

---

## 12. 기술 부채 및 정리

### 보관할 코드 아티팩트
```
ensemble_predictions.py          # 결함있는 greedy NMS
ensemble_predictions_fixed.py    # 모델 인식 클러스터링
ensemble_wbf.py                  # WBF 구현
convert_to_quadrilateral.py      # Polygon 정규화
downsample_ensemble.py           # 점 감소
round_ensemble_coords.py         # 좌표 반올림
```

### 삭제할 데이터 아티팩트
```bash
# 실패한 앙상블 JSON 292MB
rm outputs/submissions/ensemble_*.json

# 오래된 앙상블 CSV 35MB (참고용으로만 보관)
# 보관: ensemble_downsampled.csv, ensemble_wbf.csv
```

### 보관할 로그
```
ensemble.log
ensemble_fixed.log  
ensemble_wbf.log
```

---

## 부록 A: 상세 실패 타임라인

**00:09** - 수정된 NMS 앙상블 시작 (ensemble_fixed.py)  
**00:24** - 완료, 45,856개 박스 생성  
**00:27** - 3.3% 비4점 polygon 발견  
**00:27** - 사각형 변환기 생성  
**00:29** - 과도한 정규화로 평균 4.8점 생성 (23이어야 함)  
**00:30** - 다운샘플링 전략으로 전환  
**00:32** - ensemble_downsampled.csv 생성 (7.4MB)  
**00:35** - 사용자 제출, H-Mean 0.8979 수신  
**00:46** - WBF 앙상블 구현 시작  
**01:04** - 18분 후 WBF 완료  
**01:40** - ensemble_wbf.csv 생성 (8.1MB)  
**01:45** - 사용자 제출, H-Mean 0.8739 수신 (**최악의 결과**)  

**투자된 총 시간:** ~1.5시간  
**총 개선:** -11.15%p (저하)

---

## 부록 B: 박스 좌표 예시

### 샘플 이미지: `selectstar_000382.jpg`

**Ground Truth (추정):**
```
Box 1: 큰 텍스트 영역
  점: ~20개 꼭지점
  범위: x=[388, 544], y=[1126, 1166]
  크기: 156×40 픽셀
```

**Model 1 예측 (0.9854):**
```
Box 1: 54개 점
  범위: x=[388, 544], y=[1126, 1166]
  크기: 156×40 픽셀
  매칭: 완벽 ✅
```

**NMS 앙상블 결과:**
```
Box 1: 25개 점
  범위: x=[433, 506], y=[1136, 1156]  
  크기: 73×20 픽셀
  매칭: 실패 (IoU < 0.5) ❌
```

**WBF 앙상블 결과:**
```
Box 1: 46개 점
  범위: x=[431, 505], y=[1136, 1156]
  크기: 74×20 픽셀
  매칭: 실패 (IoU < 0.5) ❌
```

**분석:** 두 앙상블 방법 모두 다음과 같은 박스 생성:
- 53% 좁아짐
- 50% 짧아짐  
- 중심 부정확
- 평가 IoU threshold 미달

---

**보고서 작성자:** AI 어시스턴트  
**검토 상태:** 향후 참고를 위해 문서화된 실패한 실험  
**최종 업데이트:** 2026년 2월 11일 01:50 UTC
