#!/usr/bin/env python3
"""
ì™¸ë¶€ ë°ì´í„°ì…‹ë“¤ì„ ê¸°ì¡´ train.jsonê³¼ ë³‘í•©
"""
import json
from pathlib import Path


def merge_all_datasets():
    """SROIE + CORD + ê¸°ì¡´ ë°ì´í„° í†µí•©"""
    
    print("ğŸ”„ ì „ì²´ ë°ì´í„°ì…‹ ë³‘í•© ì‹œì‘\n")
    
    # íŒŒì¼ ê²½ë¡œ
    base_json = Path("/data/ephemeral/home/data/datasets/jsons/train.json")
    sroie_json = Path("/data/ephemeral/home/data/datasets/jsons/train_augmented.json")  # SROIE í¬í•¨
    cord_json = Path("/data/ephemeral/home/data/datasets/jsons/cord_ufo.json")
    output_json = Path("/data/ephemeral/home/data/datasets/jsons/train_augmented_full.json")
    
    # 1. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ (ì´ë¯¸ SROIE í¬í•¨ë˜ì–´ ìˆìŒ)
    with open(sroie_json, 'r', encoding='utf-8') as f:
        merged_data = json.load(f)
    
    print(f"ğŸ“Š ê¸°ì¡´ + SROIE ë°ì´í„°: {len(merged_data['images'])}ê°œ ì´ë¯¸ì§€")
    
    # 2. CORD ë°ì´í„° ì¶”ê°€
    with open(cord_json, 'r', encoding='utf-8') as f:
        cord_data = json.load(f)
    
    print(f"ğŸ“Š CORD-v2 ë°ì´í„°: {len(cord_data['images'])}ê°œ ì´ë¯¸ì§€")
    
    added = 0
    for img_name, img_info in cord_data["images"].items():
        if img_name not in merged_data["images"]:
            merged_data["images"][img_name] = img_info
            added += 1
    
    print(f"âœ… CORD-v2 {added}ê°œ ì´ë¯¸ì§€ ì¶”ê°€")
    print(f"ğŸ“Š ìµœì¢… ë°ì´í„°ì…‹: {len(merged_data['images'])}ê°œ ì´ë¯¸ì§€")
    
    # ë°ì´í„° ì¶œì²˜ í†µê³„
    sroie_count = sum(1 for img in merged_data['images'].values() if 'SROIE' in img.get('tags', []))
    cord_count = sum(1 for img in merged_data['images'].values() if 'CORD' in img.get('tags', []))
    original_count = len(merged_data['images']) - sroie_count - cord_count
    
    print(f"\nğŸ“ˆ ë°ì´í„° êµ¬ì„±:")
    print(f"  - ì›ë³¸ ë°ì´í„°: {original_count}ê°œ")
    print(f"  - SROIE: {sroie_count}ê°œ")
    print(f"  - CORD-v2: {cord_count}ê°œ")
    print(f"  - ì´í•©: {len(merged_data['images'])}ê°œ")
    
    # 3. ì €ì¥
    with open(output_json, 'w', encoding='utf-8') as f:
        json.dump(merged_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ í†µí•© JSON ì €ì¥: {output_json}")
    
    # íŒŒì¼ í¬ê¸° ë¹„êµ
    import os
    base_size = os.path.getsize(base_json) / (1024 * 1024)
    output_size = os.path.getsize(output_json) / (1024 * 1024)
    print(f"\nğŸ“ íŒŒì¼ í¬ê¸°:")
    print(f"  - ì›ë³¸: {base_size:.1f} MB")
    print(f"  - í†µí•©: {output_size:.1f} MB (x{output_size/base_size:.2f})")


if __name__ == "__main__":
    merge_all_datasets()
