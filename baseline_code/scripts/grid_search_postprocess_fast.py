"""
ë¹ ë¥¸ í›„ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜
ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œí•˜ê³  í›„ì²˜ë¦¬ íŒŒë¼ë¯¸í„°ë§Œ ë³€ê²½í•˜ì—¬ ë¹ ë¥´ê²Œ íƒìƒ‰
"""
import os
import sys
import json
import torch
import numpy as np
from pathlib import Path
from datetime import datetime
from tqdm import tqdm
import lightning.pytorch as pl
from omegaconf import OmegaConf

sys.path.append(os.getcwd())
from ocr.lightning_modules import get_pl_modules_by_cfg
from ocr.metrics.cleval_metric import CLEvalMetric

# í˜„ì¬ ìµœê³  ì ìˆ˜ì˜ íŒŒë¼ë¯¸í„°
BASELINE_THRESH = 0.231
BASELINE_BOX_THRESH = 0.432

# ê·¸ë¦¬ë“œ ì„œì¹˜ ë²”ìœ„ ì„¤ì • (ë” ì„¸ë°€í•˜ê²Œ)
THRESH_RANGE = np.arange(0.21, 0.26, 0.005)  # 0.21 ~ 0.255, step 0.005
BOX_THRESH_RANGE = np.arange(0.40, 0.46, 0.005)  # 0.40 ~ 0.455, step 0.005

# ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
CHECKPOINT_PATH = "outputs/hrnet_w44_1024_augmented_optimized/checkpoints/epoch=12-step=10634.ckpt"

# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
RESULTS_DIR = Path("grid_search_results")
RESULTS_DIR.mkdir(exist_ok=True)

# ê²°ê³¼ ì €ì¥ íŒŒì¼
RESULTS_FILE = RESULTS_DIR / f"grid_search_fast_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"


def load_model_and_data():
    """ëª¨ë¸ê³¼ ë°ì´í„° ë¡œë” ì¤€ë¹„"""
    print("ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    # ì„¤ì • ë¡œë“œ
    config_path = Path("configs/preset/hrnet_w44_1024.yaml")
    config = OmegaConf.load(config_path)
    
    # Base config ë³‘í•©
    base_config = OmegaConf.load("configs/preset/base.yaml")
    config = OmegaConf.merge(base_config, config)
    
    # í•„ìš”í•œ ì„¤ì • ì¶”ê°€
    config.seed = 42
    config.checkpoint_path = CHECKPOINT_PATH
    
    pl.seed_everything(42, workers=True)
    
    # ëª¨ë¸ê³¼ ë°ì´í„° ë¡œë” ìƒì„±
    model_module, data_module = get_pl_modules_by_cfg(config)
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')
    model_module.load_state_dict(checkpoint['state_dict'])
    model_module.eval()
    model_module.cuda()
    
    # ë°ì´í„° ë¡œë” ì¤€ë¹„
    data_module.setup('test')
    test_dataloader = data_module.test_dataloader()
    
    return model_module, test_dataloader, config


def evaluate_with_params(model, dataloader, thresh, box_thresh):
    """
    íŠ¹ì • í›„ì²˜ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ í‰ê°€
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        dataloader: í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë”
        thresh: threshold ê°’
        box_thresh: box threshold ê°’
        
    Returns:
        dict: í‰ê°€ ê²°ê³¼
    """
    # í›„ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
    model.model.head.postprocessor.thresh = thresh
    model.model.head.postprocessor.box_thresh = box_thresh
    
    # ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
    metric = CLEvalMetric()
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    model.eval()
    with torch.no_grad():
        for batch in dataloader:
            # GPUë¡œ ì´ë™
            images = batch['images'].cuda()
            
            # ì˜ˆì¸¡
            outputs = model(images)
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            metric.update(
                outputs,
                batch['gt_polygons'],
                batch['gt_ignore_masks']
            )
    
    # ìµœì¢… ë©”íŠ¸ë¦­ ê³„ì‚°
    results = metric.compute()
    
    return {
        'hmean': float(results['hmean']),
        'precision': float(results['precision']),
        'recall': float(results['recall']),
        'success': True
    }


def main():
    """ê·¸ë¦¬ë“œ ì„œì¹˜ ë©”ì¸ í•¨ìˆ˜"""
    print("="*80)
    print("ë¹ ë¥¸ í›„ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹œì‘")
    print("="*80)
    print(f"Checkpoint: {CHECKPOINT_PATH}")
    print(f"Thresh range: {THRESH_RANGE[0]:.3f} ~ {THRESH_RANGE[-1]:.3f} (step: 0.005)")
    print(f"Box Thresh range: {BOX_THRESH_RANGE[0]:.3f} ~ {BOX_THRESH_RANGE[-1]:.3f} (step: 0.005)")
    print(f"Total combinations: {len(THRESH_RANGE)} Ã— {len(BOX_THRESH_RANGE)} = {len(THRESH_RANGE) * len(BOX_THRESH_RANGE)}")
    print(f"Baseline params: thresh={BASELINE_THRESH:.3f}, box_thresh={BASELINE_BOX_THRESH:.3f}")
    print()
    
    # ëª¨ë¸ê³¼ ë°ì´í„° ë¡œë“œ
    try:
        model, dataloader, config = load_model_and_data()
        print("âœ“ ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n")
    except Exception as e:
        print(f"âœ— ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    results = {
        'baseline': {
            'thresh': BASELINE_THRESH,
            'box_thresh': BASELINE_BOX_THRESH,
            'submission_score': {
                'hmean': 0.9851,
                'precision': 0.9854,
                'recall': 0.9857
            }
        },
        'search_space': {
            'thresh_range': [float(THRESH_RANGE[0]), float(THRESH_RANGE[-1])],
            'box_thresh_range': [float(BOX_THRESH_RANGE[0]), float(BOX_THRESH_RANGE[-1])],
        },
        'experiments': []
    }
    
    best_hmean = 0.0
    best_params = None
    
    total_experiments = len(THRESH_RANGE) * len(BOX_THRESH_RANGE)
    
    # ê·¸ë¦¬ë“œ ì„œì¹˜ ìˆ˜í–‰
    with tqdm(total=total_experiments, desc="Grid Search") as pbar:
        for thresh in THRESH_RANGE:
            for box_thresh in BOX_THRESH_RANGE:
                try:
                    # í‰ê°€ ì‹¤í–‰
                    metrics = evaluate_with_params(model, dataloader, thresh, box_thresh)
                    
                    # ê²°ê³¼ ì €ì¥
                    experiment_result = {
                        'thresh': float(thresh),
                        'box_thresh': float(box_thresh),
                        'metrics': metrics,
                        'timestamp': datetime.now().isoformat()
                    }
                    results['experiments'].append(experiment_result)
                    
                    # ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
                    if metrics['success'] and metrics['hmean'] > best_hmean:
                        best_hmean = metrics['hmean']
                        best_params = {
                            'thresh': float(thresh),
                            'box_thresh': float(box_thresh),
                            'hmean': metrics['hmean'],
                            'precision': metrics['precision'],
                            'recall': metrics['recall']
                        }
                        pbar.set_postfix({
                            'best_hmean': f"{best_hmean:.6f}",
                            'thresh': f"{thresh:.3f}",
                            'box_thresh': f"{box_thresh:.3f}"
                        })
                
                except Exception as e:
                    print(f"\nâœ— Error at thresh={thresh:.3f}, box_thresh={box_thresh:.3f}: {e}")
                    experiment_result = {
                        'thresh': float(thresh),
                        'box_thresh': float(box_thresh),
                        'metrics': {
                            'hmean': 0.0,
                            'precision': 0.0,
                            'recall': 0.0,
                            'success': False,
                            'error': str(e)
                        },
                        'timestamp': datetime.now().isoformat()
                    }
                    results['experiments'].append(experiment_result)
                
                pbar.update(1)
                
                # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (50ê°œë§ˆë‹¤)
                if len(results['experiments']) % 50 == 0:
                    results['best_so_far'] = best_params
                    with open(RESULTS_FILE, 'w') as f:
                        json.dump(results, f, indent=2)
    
    # ìµœì¢… ê²°ê³¼ ì €ì¥
    results['best'] = best_params
    results['total_experiments'] = total_experiments
    results['completed_at'] = datetime.now().isoformat()
    
    with open(RESULTS_FILE, 'w') as f:
        json.dump(results, f, indent=2)
    
    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print("\n" + "="*80)
    print("ê·¸ë¦¬ë“œ ì„œì¹˜ ì™„ë£Œ!")
    print("="*80)
    print(f"\nì´ ì‹¤í—˜ íšŸìˆ˜: {total_experiments}")
    print(f"ê²°ê³¼ íŒŒì¼: {RESULTS_FILE}")
    
    if best_params:
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ íŒŒë¼ë¯¸í„°:")
        print(f"  thresh: {best_params['thresh']:.4f}")
        print(f"  box_thresh: {best_params['box_thresh']:.4f}")
        print(f"  H-Mean: {best_params['hmean']:.6f}")
        print(f"  Precision: {best_params['precision']:.6f}")
        print(f"  Recall: {best_params['recall']:.6f}")
        
        # Baselineê³¼ ë¹„êµ
        baseline_val_hmean = best_params['hmean']  # validation
        baseline_sub_hmean = 0.9851  # submission
        improvement = best_params['hmean'] - baseline_val_hmean
        print(f"\nğŸ“Š Baseline submission ëŒ€ë¹„ (ì°¸ê³ ìš©):")
        print(f"  Submission H-Mean: {baseline_sub_hmean:.4f}")
        print(f"  Validation H-Mean (ì´ë²ˆ ìµœê³ ): {best_params['hmean']:.6f}")
    
    # ìƒìœ„ 10ê°œ ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“ˆ ìƒìœ„ 10ê°œ ê²°ê³¼:")
    sorted_results = sorted(
        [r for r in results['experiments'] if r['metrics']['success']],
        key=lambda x: x['metrics']['hmean'],
        reverse=True
    )[:10]
    
    for i, result in enumerate(sorted_results, 1):
        print(f"  {i}. thresh={result['thresh']:.4f}, box_thresh={result['box_thresh']:.4f} "
              f"â†’ H-Mean: {result['metrics']['hmean']:.6f}")
    
    print("\n" + "="*80)
    
    # íˆíŠ¸ë§µ ë°ì´í„° ìƒì„± (ì‹œê°í™”ìš©)
    print("\nìƒì„±ëœ íˆíŠ¸ë§µ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    heatmap_data = np.zeros((len(THRESH_RANGE), len(BOX_THRESH_RANGE)))
    for i, thresh in enumerate(THRESH_RANGE):
        for j, box_thresh in enumerate(BOX_THRESH_RANGE):
            for exp in results['experiments']:
                if (abs(exp['thresh'] - thresh) < 0.001 and 
                    abs(exp['box_thresh'] - box_thresh) < 0.001 and
                    exp['metrics']['success']):
                    heatmap_data[i, j] = exp['metrics']['hmean']
                    break
    
    # íˆíŠ¸ë§µ ì €ì¥
    heatmap_file = RESULTS_DIR / f"heatmap_{datetime.now().strftime('%Y%m%d_%H%M%S')}.npy"
    np.save(heatmap_file, heatmap_data)
    print(f"íˆíŠ¸ë§µ ë°ì´í„° ì €ì¥: {heatmap_file}")


if __name__ == "__main__":
    main()
