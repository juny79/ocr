# WandB Sweepμ„ μ΄μ©ν• HRNet-W44 1280x1280 μµμ  νλΌλ―Έν„° νƒμƒ‰

## π“ ν„μ¬ μ„±κ³Ό
- **μ μ¶ κ²°κ³Ό**: H-Mean 97.14%, Precision 97.35%, Recall 97.08%
- **ν„μ¬ νλΌλ―Έν„°**:
  - lr: 0.00045
  - weight_decay: 0.00006
  - T_max: 20
  - eta_min: 0.000008

---

## π― Sweep λ©ν‘

λ” λ‚μ€ νλΌλ―Έν„° μ΅°ν•©μ„ μλ™μΌλ΅ μ°ΎκΈ° μ„ν•΄ **Bayesian Optimization**κ³Ό **Hyperband** μ΅°κΈ° μΆ…λ£λ¥Ό μ‚¬μ©ν•©λ‹λ‹¤.

### νƒμƒ‰ λ²”μ„

| νλΌλ―Έν„° | νƒμƒ‰ λ²”μ„ | ν„μ¬κ°’ | λΉ„κ³  |
|---------|---------|--------|------|
| **Learning Rate** | 0.00001 ~ 0.0002 | 0.00045 | log scale (μ£Όλ³€ Β±2λ°°) |
| **Weight Decay** | 0.0000061 ~ 0.000123 | 0.00006 | log scale (Β±2λ°°) |
| **T_max** | [15, 18, 20, 25] | 20 | μ •μκ°’ μ„ νƒ |
| **eta_min** | 0.0000022 ~ 0.000045 | 0.000008 | log scale (Β±5λ°°) |

### μµμ ν™” μ „λµ
- **λ°©μ‹**: Bayesian Optimization (μ¤λ§νΈ νƒμƒ‰)
- **λ©”νΈλ¦­**: val/hmean μµλ€ν™”
- **μ΅°κΈ° μΆ…λ£**: Hyperband (5 epoch ν›„ μ„±λ¥ λ‚®μ€ μ΅°ν•© μλ™ μ¤‘λ‹¨)
- **μμƒ μ‹κ°„**: 8 parallel runs Γ— ~6μ‹κ°„/run = λ³‘λ ¬ μ‹¤ν–‰ μ‹ ~6μ‹κ°„

---

## π€ μ‹¤ν–‰ λ°©λ²•

### λ°©λ²• 1: μλ™ μ‹¤ν–‰ (κ¶μ¥)
```bash
cd /data/ephemeral/home/baseline_code
chmod +x run_sweep.sh
./run_sweep.sh
```

μ΄ λ…λ Ήμ–΄λ”:
1. β… Sweep μ„¤μ • μ΄κΈ°ν™”
2. β… Sweep ID μƒμ„±
3. β… 8κ° λ³‘λ ¬ μ—μ΄μ „νΈ μ‹μ‘

### λ°©λ²• 2: μλ™ μ‹¤ν–‰ (λ‹¨κ³„λ³„)

**Step 1: Sweep μ΄κΈ°ν™”**
```bash
cd /data/ephemeral/home/baseline_code
wandb sweep sweep_hrnet_w44_1280.yaml \
  --project hrnet-w44-1280-sweep \
  --entity juny79
```

μ¶λ ¥ μμ‹:
```
Create sweep with ID: abc123xyz
Run sweep agent with: wandb agent juny79/hrnet-w44-1280-sweep/abc123xyz
```

**Step 2: Sweep μ—μ΄μ „νΈ μ‹¤ν–‰** (ν„°λ―Έλ„ 1μ—μ„)
```bash
cd /data/ephemeral/home/baseline_code
wandb agent juny79/hrnet-w44-1280-sweep/abc123xyz --count 8
```

λλ” **λ³‘λ ¬ μ‹¤ν–‰** (μ—¬λ¬ ν„°λ―Έλ„μ—μ„ λ™μ‹ μ‹¤ν–‰):
```bash
# ν„°λ―Έλ„ 1, 2, 3... μ—μ„ κ°κ° μ‹¤ν–‰
wandb agent juny79/hrnet-w44-1280-sweep/abc123xyz
```

---

## π“ μ‹¤μ‹κ°„ λ¨λ‹ν„°λ§

### WandB Dashboard ν™•μΈ
```
https://wandb.ai/juny79/hrnet-w44-1280-sweep
```

Dashboardμ—μ„ ν™•μΈ κ°€λ¥ν• μ •λ³΄:
- κ° μ‹¤ν–‰μ ν•™μµ κ³΅μ„  (loss, val_hmean λ“±)
- νλΌλ―Έν„° vs μ„±λ¥ κ΄€κ³„
- μµκ³  μ„±λ¥ μ΅°ν•©
- λ³‘λ ¬ μ‹¤ν–‰ μ§„ν–‰λ„

### λ΅μ»¬μ—μ„ μ‹¤μ‹κ°„ ν™•μΈ
```bash
# Sweep μƒνƒ ν™•μΈ
wandb sweep status juny79/hrnet-w44-1280-sweep/abc123xyz

# μµμ‹  κ²°κ³Ό ν™•μΈ
wandb sweeps best juny79/hrnet-w44-1280-sweep
```

---

## π’΅ Bayesian Optimization μ΄ν•΄ν•κΈ°

```
μ΄κΈ° μ‹¤ν–‰ (3-4κ°):
  β†’ νλΌλ―Έν„° κ³µκ°„ νƒν—

μ¤‘κΈ° μ‹¤ν–‰ (5-6κ°):
  β†’ μΆ‹μ€ μμ—­μΌλ΅ μ§‘μ¤‘
  β†’ μ΅°κΈ° μΆ…λ£ ν™μ©

ν›„κΈ° μ‹¤ν–‰ (7-8κ°):
  β†’ μµκ³  μ„±λ¥ μ΅°ν•© κ·Όμ² νƒμƒ‰
  β†’ μλ ΄ ν™•μΈ
```

---

## β΅ μ΅°κΈ° μΆ…λ£ (Hyperband) λ©”μ»¤λ‹μ¦

```
κ° μ‹¤ν–‰μ 5 epochλ§λ‹¤ κ²€μ‚¬:

Epoch 5:  λ‚®μ€ μ„±λ¥ β†’ μ¤‘λ‹¨ (24μ‹κ°„ μ μ•½)
Epoch 10: μ¤‘κ°„ μ„±λ¥ β†’ κ³„μ† μ§„ν–‰
Epoch 15: λ†’μ€ μ„±λ¥ β†’ κ³„μ† μ§„ν–‰
Epoch 20: μµμΆ… μ„±λ¥ κΈ°λ΅
```

**ν¨κ³Ό**: λ‚μ νλΌλ―Έν„° μ΅°ν•©μ€ μ΅°κΈ°μ— μ¤‘λ‹¨λμ–΄ λ¦¬μ†μ¤ μ μ•½

---

## π“ μμƒ κ²°κ³Ό

Sweep μ™„λ£ ν›„ WandBμ—μ„ μλ™ μƒμ„±λλ” λ³΄κ³ μ„:

```
μµκ³  μ„±λ¥ μ„¤μ •:
  lr: 0.0003 (λλ” λ‹¤λ¥Έ κ°’)
  weight_decay: 0.00005
  T_max: 20
  eta_min: 0.000012
  
μμƒ H-Mean: 97.20% ~ 97.35%
```

---

## π“ Sweep μ„¤μ • μƒμ„Έ (sweep_hrnet_w44_1280.yaml)

### νλΌλ―Έν„° μ„¤μ • μ΄μ 

**Learning Rate - log_uniform**
- ν„μ¬ 0.00045κ°€ μΆ‹μ€ κ°’μ΄λ―€λ΅ μ£Όλ³€μ—μ„ νƒμƒ‰
- Log scale: 0.00001 ~ 0.0002 (ν„μ¬κ°’μ Β±2λ°° λ²”μ„)
- Bayesian Optimizationμ΄ μλ™μΌλ΅ μ λ§ν• μμ—­ νƒμƒ‰

**Weight Decay - log_uniform**
- λ°°μΉ ν¬κΈ° 2μ— λ§μ¶”μ–΄ μ΅°μ •
- ν„μ¬ 0.00006 μ£Όλ³€μ—μ„ Β±2λ°° λ²”μ„ νƒμƒ‰

**T_max - discrete**
- μ½”μ‚¬μΈ μ–΄λ‹λ§ μ‚¬μ΄ν΄
- 15, 18, 20, 25 μ¤‘ μµμ κ°’ μ„ νƒ
- λ²”μ£Όν• κ²€μƒ‰ (λ” λΉ λ¥Έ μλ ΄)

**eta_min - log_uniform**
- μµμ† ν•™μµμ¨
- Β±5λ°° λ²”μ„λ΅ λ” λ„“κ² νƒμƒ‰

---

## π”§ νΈλ¬λΈ”μν…

### λ¬Έμ  1: λ©”λ¨λ¦¬ λ¶€μ΅±
```bash
# Parallel runs κ°μ†
wandb agent ... --count 4  # 8μ—μ„ 4λ΅ κ°μ†
```

### λ¬Έμ  2: Sweep μ¤‘λ‹¨λμ—μ„ λ•
```bash
# λ™μΌν• sweep IDλ΅ λ‹¤μ‹ μ‹μ‘
wandb agent juny79/hrnet-w44-1280-sweep/abc123xyz --count 4
```

### λ¬Έμ  3: μµμ κ°’ μ°ΎκΈ°
```bash
# WandBμ—μ„ μλ™ μ μ‹ (Dashboardμ "Best" ν‘μ‹)
# λλ” ν”„λ΅κ·Έλλ°μΌλ΅:
wandb sweeps best juny79/hrnet-w44-1280-sweep
```

---

## π“ Sweep μ™„λ£ ν›„ λ‹¤μ λ‹¨κ³„

1. **μµκ³  νλΌλ―Έν„° ν™•μΈ**
   - WandB Dashboardμ—μ„ μµκ³  H-Mean μ°ΎκΈ°
   - λ¨λ“  foldμ— μ μ©ν•  νλΌλ―Έν„° κ²°μ •

2. **λ‹¤λ¥Έ foldμ— μ μ©**
   ```bash
   # Fold 1-4λ„ λ™μΌν• νλΌλ―Έν„°λ΅ ν•™μµ
   python runners/train.py preset=hrnet_w44_1280 \
     models.optimizer.lr=<best_lr> \
     models.optimizer.weight_decay=<best_wd> \
     models.scheduler.T_max=<best_tmax> \
     models.scheduler.eta_min=<best_etamin> \
     trainer.max_epochs=20
   ```

3. **5-fold μ•™μƒλΈ”**
   ```bash
   python scripts/ensemble_kfold.py
   ```

---

## π“ μμƒ μΌμ •

```
μ‹μ‘: μ§€κΈ
Step 1 (Sweep μ΄κΈ°ν™”): 5λ¶„
Step 2 (λ³‘λ ¬ μ‹¤ν–‰): ~6μ‹κ°„ (8κ° run λ™μ‹)
Step 3 (μµκ³ κ°’ λ¶„μ„): 10λ¶„
Step 4 (Fold 1-4 ν•™μµ): ~30μ‹κ°„ (λ³‘λ ¬ μ‹¤ν–‰ μ‹ ~10μ‹κ°„)
Step 5 (5-fold μ•™μƒλΈ”): 1μ‹κ°„

μ΄ μμƒ μ‹κ°„: 48μ‹κ°„ μ΄λ‚΄ (λ¨λ“  fold ν¬ν•¨)
```

---

## π― μ„±κ³µ μ§€ν‘

β… Sweep μ™„λ£ μ‹ λ‹¤μ ν™•μΈ:
- [ ] μµκ³  H-Mean > 97.14% (ν„μ¬κ°’)
- [ ] λ¨λ“  runμ΄ μ•μ •μ μΌλ΅ μ™„λ£λ¨
- [ ] νλΌλ―Έν„° μν–¥λ„ μ‹κ°ν™” (WandB μ κ³µ)
- [ ] μµμ κ°’ μ΅°ν•© λ„μ¶

**μμƒ μµμΆ… μ„±κ³Ό**: H-Mean **97.20% ~ 97.40%** π€
