# @package _global_

defaults:
  - /preset/models/decoder/unet_resnet50
  - /preset/models/encoder/timm_backbone_resnet50
  - /preset/models/head/db_head
  - /preset/models/loss/db_loss
  - _self_

models:
  optimizer:
    _target_: torch.optim.Adam
    lr: 0.0005  # ResNet50은 더 크므로 학습률 약간 낮춤
    weight_decay: 0.0001
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: 24
    eta_min: 0.00001
