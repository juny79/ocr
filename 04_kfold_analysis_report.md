# K-Fold 앙상블 개선 결과 보고서 (v2)

**작성일**: 2026. 01. 31  
**작성자**: GitHub Copilot  
**기반 문서**: [3_kfold_analysis_report.md](3_kfold_analysis_report.md)

---

## 1. 실험 개요 및 결과 요약

본 보고서는 K-Fold 앙상블 과정에서 **"과도하게 관대한 결합(Union)"**으로 인해 발생했던 정확도(Precision) 하락 문제를 해결하기 위해, **"다수결 투표(Majority Voting, Votes ≥ 2)"** 방식을 적용한 후의 성과를 분석합니다.

### 1.1 성능 비교 (Leaderboard)

| 지표 (Metric) | 개선 전 (Union) | **개선 후 (Votes ≥ 2)** | 증감 (Delta) |
| :--- | :---: | :---: | :---: |
| **H-Mean** | 0.8756 | **0.9176** | **+0.0420 (▲)** |
| **Precision** | 0.8489 | **0.9174** | **+0.0685 (▲)** |
| **Recall** | 0.9098 | **0.9212** | **+0.0114 (▲)** |

---

## 2. 결과 정밀 분석

### 2.1 정밀도(Precision)의 대폭 향상 (+6.8%)
*   **원인**: 이전 방식은 5개 Fold 모델 중 단 1개만 예측해도 정답으로 인정했기 때문에, 모델들이 뱉어낸 모든 노이즈(배경 오인식 등)가 결과에 포함되었습니다.
*   **개선**: **"최소 2개 이상의 모델이 동의해야 한다"**는 조건(`votes >= 2`)을 추가하여, 우연히 발생한 노이즈를 효과적으로 필터링했습니다.
*   **의의**: 앙상블의 진정한 목적(모델 간 상호 보완 및 검증)이 달성되었습니다.

### 2.2 재현율(Recall)의 동반 상승 (+1.1%)
*   **현상**: 일반적으로 투표 기준을 강화하면(필터링을 많이 하면) 놓치는 정답이 생겨 Recall이 떨어지기 마련인데, 이번에는 오히려 상승했습니다.
*   **해석**:
    1.  **Metric의 특성**: 이전 결과물에 너무 많은 박스가 난립(Overlapping)하여, 정답 매칭 과정에서 페널티를 받거나 혼선을 주었을 가능성이 큽니다. 불필요한 박스가 제거되면서 매칭이 더 깔끔해졌습니다.
    2.  **안정적 검출**: 2개 이상의 모델이 공통적으로 잡은 박스들은 그 위치와 형태가 더 정교(Refined)해져서, Ground Truth와의 IOU(교집합 비율)가 높아졌을 수 있습니다.

### 2.3 일반화 성능 입증
*   단일 모델(Baseline) 대비 H-Mean 점수가 **0.9176**으로 안정적인 고득점권에 진입했습니다.
*   K-Fold 학습 과정에서 보였던 일부 불안정 요소(로그 폭주 등)와 상관없이, **최종 결과물(Model Weights)** 자체는 매우 훌륭하게 학습되었음을 증명합니다.

---

## 3. 향후 제언 (Next Step)

현재 점수(0.9176)는 매우 경쟁력 있는 수치입니다. 여기서 점수를 더 쥐어짜기(Squeeze) 위한 전략을 제안합니다.

### 3.1 투표 기준 상향 실험 (Optional)
*   **제안**: 현재 기준인 `Votes ≥ 2`를 **`Votes ≥ 3` (과반수)**으로 높여봅니다.
*   **예상**: Precision은 약 0.93~0.94까지 오를 수 있으나, Recall이 떨어질 위험이 있습니다. 리더보드 제출 횟수가 남았다면 시도해볼 가치가 있습니다.

### 3.2 TTA (Test Time Augmentation) 적용
*   **제안**: 추론(Inference) 단계에서 이미지를 `[원본, 1.5배 확대, 좌우 반전]` 등으로 변환하여 예측한 뒤 합칩니다.
*   **이유**: 작은 글씨나 희미한 글씨를 찾아내어 **Recall을 0.93~0.94**대로 끌어올릴 수 있는 가장 강력한 방법입니다.

### 3.3 후처리 파라미터 미세 조정
*   **제안**: `scripts/ensemble_kfold.py`가 아닌 `runners/predict.py` 단계에서 `box_thresh`(현재 0.5)와 `unclip_ratio`(현재 1.5 or 2.0)를 조정해봅니다.
*   **방향**: Precision이 충분히 확보되었으므로, `box_thresh`를 0.45 정도로 살짝 낮춰 Recall을 더 챙기는 전략이 유효할 수 있습니다.

---

## 4. 종합 결론

> **"K-Fold 전략은 성공적이었으며, 단순한 후처리 로직 수정만으로 잠재력을 폭발시켰습니다."**

초기의 불안정해 보이던 학습 과정은 단순한 로그 출력 문제였으며, 결과적으로 5개의 모델은 각자의 역할을 충실히 해냈습니다. 올바른 앙상블 기법(Voting)이 적용되자 즉각적인 성능 향상으로 이어졌습니다. 이제 이 모델은 **매우 강력한 베이스라인**이 되었습니다.
