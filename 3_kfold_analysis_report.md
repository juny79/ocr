# K-Fold 분석 및 개선 방향 보고서

**작성일**: 2026. 01. 31  
**작성자**: GitHub Copilot  
**대상**: OCR Receipt Detection Project

---

## 1. 리더보드 결과 분석

### 1.1 점수 현황
*   **H-Mean**: 0.8756
*   **Precision (정밀도)**: 0.8489 (▼ 심각한 하락)
*   **Recall (재현율)**: 0.9098 (▲ 상승)

### 1.2 현상 해석
*   **"Generalization은 올랐으나, 틀린 예측이 너무 많다."**
    *   **Recall 0.9098**: 5개의 모델이 각자 다른 시각으로 텍스트를 찾아내면서, 단일 모델이 놓쳤던 텍스트를 잡아내는 데는 성공했습니다. (일반화 성능 향상)
    *   **Precision 0.8489**: 그러나 5개 모델이 쏟아낸 예측값들을 "엄격하게 심사"하지 않고 모두 정답으로 제출했습니다. 노이즈나 배경을 텍스트로 인식한 False Positive가 대거 포함되었습니다.

### 1.3 원인 진단: 앙상블 로직의 결함
현재 `ensemble_kfold.py`의 `nms_boxes` 함수 로직은 다음과 같습니다.
1.  비슷한 박스끼리 그룹화하여 투표(Voting) 수를 셉니다. (1~5표)
2.  투표 수가 높은 순서대로 정렬합니다.
3.  **투표 수가 적은(1~2표) 박스도 버리지 않고 모두 결과에 포함시켰습니다.**

이로 인해 5개 모델 중 **단 1개 모델이라도 실수를 하면 최종 결과도 틀리게 되는 구조**가 되었습니다. 안정성을 위해서는 **Majority Vote(최소 3개 이상의 모델이 동의한 경우에만 인정)** 방식이 필수적입니다.

---

## 2. K-Fold 프로세스 안정성 검토

사용자께서 지적하신 "불안정한 상황"에 대한 기술적 분석입니다.

### 2.1 학습 중 로그 불안정 (tqdm 이슈)
*   **현상**: `nohup` 백그라운드 실행 시 진행률 표시바(ProgressBar)가 깨져서 로그 파일이 비대해지고 에러처럼 보이는 현상.
*   **진단**: 이는 단순한 출력(I/O) 문제이며, 실제 모델의 가중치(Weight) 학습에는 영향을 주지 않았습니다.
*   **조치**: 향후 스크립트에서는 `trainer.fit(..., enable_progress_bar=False)` 처럼 설정하거나, 단순 텍스트 로그 모드로 변경해야 관리 효율성이 높아집니다.

### 2.2 ConvexHull Failed 경고
*   **현상**: `[WARN] ConvexHull failed...` 메시지 다수 발생.
*   **진단**: DBNet은 픽셀 단위 마스크를 박스로 변환합니다. 학습 초기나 불안정한 예측 시, 점들이 꼬이거나 면적이 없는(직선 형태) 폴리곤이 생성될 때 발생하는 기하학적 연산 에러입니다.
*   **영향**: 해당 샘플은 Loss 계산에서 제외되거나 무시되므로, 전체 학습 흐름을 끊지는 않습니다. 다만, 이 경고가 너무 많으면 수렴이 덜 되었다는 신호일 수 있습니다.

---

## 3. 향후 개선 방향 (Action Plan)

안정성을 확보하고 점수를 대폭 향상시키기 위한 단계별 전략입니다.

### [1단계: 즉시 적용] 앙상블 로직 수정 (점수 급상승 예상)
현재 훈련된 5개의 체크포인트는 유효합니다. 다시 학습할 필요 없이 **예측(Inference) 로직만 수정**하면 됩니다.
*   **Soft Voting 도입**: 단순히 박스 좌표만 겹치는 것이 아니라, 모델이 내뱉은 `score(확신도)`의 평균을 사용합니다.
*   **Thresholding**: 5개 중 **최소 3개 이상의 Fold**에서 검출된 영역만 남기고, 나머지는 과감히 버립니다. (Easy Ensemble)
*   **예상 효과**: Precision이 Baseline 수준(0.92+)으로 복구되면서 H-Mean 0.90 돌파 가능.

### [2단계: 후처리(Post-processing) 튜닝]
DBNet 결과는 다음 두 가지 파라미터에 민감합니다.
*   `box_thresh`: 이 값 이상인 영역만 박스로 인정. (현재 0.5 -> 0.6으로 상향 고려)
*   `unclip_ratio`: 박스를 얼마나 팽창시킬지 결정. (글자가 잘린다면 키우고, 겹친다면 줄여야 함)
*   Fold 별 검증 데이터셋(Validation Set)을 이용해 최적의 `thresh` 값을 찾은 뒤 Test 셋에 적용해야 합니다.

### [3단계: 추가 기법]
*   **TTA (Test Time Augmentation)**: 예측 시 이미지를 [원본, 좌우반전, 확대] 등으로 변형해 예측하고 합칩니다. K-Fold와 결합하면 더욱 강력해집니다.

---

## 4. 결론

K-Fold 자체는 성공적으로 수행되었으나, **"결과를 합치는 방법(Union)"**이 너무 관대했습니다. 
현재 가장 시급하고 효과적인 조치는 **앙상블 스크립트에 `min_vote` 조건을 추가하여 다시 제출 파일을 생성하는 것**입니다.

이 수정만으로도 H-Mean 점수는 즉시 상승할 것입니다.
