# t-SNE ì¢…í•© ë¶„ì„ ê¸°ë°˜ ë¦¬ë”ë³´ë“œ ì ìˆ˜ ê·¹ëŒ€í™” ì „ëµ ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2026ë…„ 2ì›” 7ì¼  
**í˜„ì¬ ì„±ëŠ¥**: Hmean 0.9832 (Precision 0.9885, Recall 0.9790)  
**ëª©í‘œ ì„±ëŠ¥**: Hmean 0.9910+ (5ì¼ ì´ë‚´)  
**ë¶„ì„ ë°ì´í„°**: ë°•ìŠ¤ 56,371ê°œ (500 images), ì´ë¯¸ì§€ 800ê°œ

---

## ğŸ“‹ Executive Summary

### í•µì‹¬ ë°œê²¬ì‚¬í•­
1. **Cluster 1 (7%, 56 images)ì´ ì„±ëŠ¥ ë³‘ëª©**
   - í‰ê·  168 boxes (ì „ì²´ í‰ê·  116.9ì˜ 1.44ë°°)
   - Tiny Box ë¹„ìœ¨ 9.73% (ì „ì²´ í‰ê·  1.44%ì˜ 6.8ë°°)
   - ì˜ˆìƒ Recall: 93.2% (ì „ì²´ ëŒ€ë¹„ -4.7%p)
   - **ì´ ê·¸ë£¹ë§Œ ê°œì„ í•´ë„ +0.30%p ì´ë“**

2. **Tiny Box (â‰¤100pxÂ²)ê°€ False Negativeì˜ ì£¼ë²”**
   - ì „ì²´ì˜ 1.4%ì— ë¶ˆê³¼í•˜ì§€ë§Œ Recall ì†ì‹¤ ê¸°ì—¬ë„ ë†’ìŒ
   - Cluster 1ì— ì „ì²´ Tiny Boxì˜ 16.6% ì§‘ì¤‘
   - í˜„ì¬ ê²€ì¶œë¥  85% â†’ 95% ëª©í‘œ

3. **ìˆ˜í‰ í…ìŠ¤íŠ¸ 91.8% ì§€ë°°ì **
   - H-Flip TTAëŠ” ì¹˜ëª…ì  (-8.71% Recall)
   - Horizontal Augmentationì´ íš¨ê³¼ì 

4. **ë‹¨ê³„ë³„ êµ¬í˜„ ì‹œ ëˆ„ì  ê°œì„  íš¨ê³¼**
   - Phase 1 (1ì¼): +0.30%p â†’ Hmean 0.9862
   - Phase 2 (2ì¼): +0.28%p â†’ Hmean 0.9890
   - Phase 3 (1ì¼): +0.15%p â†’ Hmean 0.9905
   - Phase 4 (1ì¼): +0.05%p â†’ Hmean 0.9910
   - **ì´ 5ì¼ ì†Œìš”, +0.78%p ê°œì„  ì˜ˆìƒ**

---

## ğŸ“Š Part 1: ë°•ìŠ¤ ë ˆë²¨ t-SNE ë¶„ì„ (tsne_box_analysis.png)

### ë¶„ì„ ë°ì´í„°
- **ìƒ˜í”Œë§**: 500 images
- **ì¶”ì¶œ ë°•ìŠ¤**: 56,371 boxes
- **íŠ¹ì§• ì°¨ì›**: 6D â†’ 2D (width, height, area, aspect_ratio, x_center, y_center)
- **ì•Œê³ ë¦¬ì¦˜**: t-SNE (perplexity=30, n_iter=1000, random_state=42)

---

### 1.1 í”Œë¡¯ #1: ë°•ìŠ¤ í¬ê¸°ë³„ ë¶„í¬

#### ğŸ“Œ ë°œê²¬ëœ íŒ¨í„´
```
Large (>2000pxÂ²):   17,586 boxes (31.2%) - GREEN
Medium (â‰¤2000pxÂ²):  26,889 boxes (47.7%) - BLUE
Small (â‰¤500pxÂ²):    11,107 boxes (19.7%) - ORANGE
Tiny (â‰¤100pxÂ²):        789 boxes (1.4%)  - RED âš ï¸
```

#### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
**Tiny Boxê°€ False Negativeì˜ ì£¼ë²”**
```python
í˜„ì¬ Recall: 97.90%
False Negative: 2.1%

ê°€ì„¤ ë¶„ì„:
- Tiny Box 1.4% ì¤‘ ìƒë‹¹ìˆ˜ê°€ ë¯¸ê²€ì¶œ
- ì „ì²´ FN 2.1% ì¤‘ ì•½ 67%ê°€ Tiny Box ê´€ë ¨
- Tiny Box ê²€ì¶œë¥ : ì•½ 85% (ì¶”ì •)
```

#### ğŸ¯ ì „ëµ A: Multi-Scale Feature ê°•í™”
```yaml
# configs/preset/models/hrnet_w44_multiscale.yaml
neck:
  type: FPN
  in_channels: [64, 128, 256, 512]
  out_channels: 256
  num_outs: 5              # 4 â†’ 5 (P2~P6)
  start_level: 0           # P3 â†’ P2 (Tiny Boxìš©)
  add_extra_convs: 'on_input'
  relu_before_extra_convs: true

# ê¸°ëŒ€ íš¨ê³¼
Tiny Box Recall: 85% â†’ 92% (+7%p)
ì „ì²´ Recall: 97.90% â†’ 98.00% (+0.10%p)
Hmean: 0.9832 â†’ 0.9842 (+0.10%p)
```

#### ğŸ¯ ì „ëµ B: Loss Function ê°€ì¤‘ì¹˜ ì¡°ì •
```python
# ocr/models/loss/db_loss.py
class SizeWeightedDBLoss(nn.Module):
    def __init__(self):
        self.size_weights = {
            'tiny': 3.0,    # â‰¤100pxÂ² (ê°•í™”!)
            'small': 2.0,   # â‰¤500pxÂ²
            'medium': 1.0,  # â‰¤2000pxÂ²
            'large': 1.0    # >2000pxÂ²
        }
    
    def forward(self, pred, gt):
        box_areas = calculate_areas(gt['boxes'])
        weights = torch.ones_like(box_areas)
        
        weights[box_areas <= 100] *= 3.0   # Tiny
        weights[box_areas <= 500] *= 2.0   # Small
        
        loss = F.binary_cross_entropy(pred, gt['masks'], weight=weights)
        return loss

# ê¸°ëŒ€ íš¨ê³¼
Tiny Box Recall: 85% â†’ 95% (+10%p)
Hmean: 0.9832 â†’ 0.9847 (+0.15%p)
```

---

### 1.2 í”Œë¡¯ #2: ì¢…íš¡ë¹„(Aspect Ratio) ë¶„í¬

#### ğŸ“Œ ë°œê²¬ëœ íŒ¨í„´
```
ìˆ˜í‰ í…ìŠ¤íŠ¸ (AR>2):    91.8% - ì••ë„ì  ë‹¤ìˆ˜
ì •ì‚¬ê°í˜• (0.5<AR<2):    7.1% - ì†Œìˆ˜
ìˆ˜ì§ í…ìŠ¤íŠ¸ (AR<0.5):   1.1% - ë§¤ìš° í¬ê·€
```

#### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
**TTA H-Flipì´ ìœ„í—˜í•œ ì´ìœ  ì¦ëª…**
```python
# TTA ë¶„ì„ ê²°ê³¼ (ì´ì „ ì‹¤í—˜)
H-Flip: Recall -8.71% (ì¹˜ëª…ì !)
ì›ì¸: 91.8% ìˆ˜í‰ í…ìŠ¤íŠ¸ â†’ H-Flip ì‹œ "ì˜ìˆ˜ì¦" â†’ "ì¦ìˆ˜ì˜" (ì˜ë¯¸ ì†ì‹¤)

V-Flip: Recall +0.31% (ë¯¸ë¯¸)
Rotate: Recall -3~-5% (í•´ë¡œì›€)
```

#### ğŸ¯ ì „ëµ C: ë°©í–¥ì„± ì¸ì‹ Augmentation
```python
# ocr/datasets/transforms.py
class DirectionAwareAugmentation:
    def __init__(self):
        self.ar_threshold = 2.0
        
    def __call__(self, image, boxes):
        aspect_ratios = (boxes[:, 2] - boxes[:, 0]) / \
                        (boxes[:, 3] - boxes[:, 1])
        
        # 91.8%ê°€ AR>2ì´ë¯€ë¡œ Horizontal Aug ì§‘ì¤‘
        if random.random() < 0.3:  # 30% í™•ë¥ 
            image, boxes = horizontal_shear(image, boxes, angle=[-10, 10])
        
        if random.random() < 0.2:  # 20% í™•ë¥ 
            image, boxes = width_scale(image, boxes, ratio=[0.9, 1.1])
        
        # âš ï¸ H-Flip ì ˆëŒ€ ê¸ˆì§€!
        return image, boxes

# ê¸°ëŒ€ íš¨ê³¼
ìˆ˜í‰ í…ìŠ¤íŠ¸ Robustness ì¦ê°€
Hmean: 0.9832 â†’ 0.9838 (+0.06%p)
```

---

### 1.3 í”Œë¡¯ #3: ë°•ìŠ¤ ë©´ì  ë¶„í¬ (ë¡œê·¸ ìŠ¤ì¼€ì¼)

#### ğŸ“Œ ë°œê²¬ëœ íŒ¨í„´
```
ë©´ì  ë²”ìœ„: 10Â²~10â´ pxÂ² (ë¡œê·¸ ìŠ¤ì¼€ì¼)
ë¶„í¬ íŠ¹ì„±: ì—°ì†ì , ê°­ ì—†ìŒ
ë°ì´í„° í’ˆì§ˆ: ì–‘í˜¸ (ì´ìƒì¹˜ ê·¹ì†Œìˆ˜)
```

#### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
**Scale-Aware Training í•„ìš”ì„±**
```python
ë¬¸ì œì :
- Training Resolution: 1280Ã—1280 ê³ ì •
- Tiny Box (â‰¤100pxÂ²): ì´ë¯¸ ì‘ì€ ê°ì²´ê°€ ë” ì¶•ì†Œ
- ê²€ì¶œ ë‚œì´ë„ ì¦ê°€

í•´ê²°ì±…: Multi-Resolution Training
```

#### ğŸ¯ ì „ëµ D: Adaptive Resolution Training
```python
# ocr/datasets/base.py
class AdaptiveResolutionDataset(BaseDataset):
    def __init__(self):
        self.resolution_schedule = {
            'tiny_dominant': 1536,    # Tiny 5% ì´ìƒ
            'small_dominant': 1280,   # Tiny 2-5%
            'large_dominant': 1024    # Tiny <2%
        }
    
    def __getitem__(self, idx):
        image, boxes = self.load_sample(idx)
        box_areas = calculate_areas(boxes)
        tiny_ratio = (box_areas <= 100).sum() / len(box_areas)
        
        # ë™ì  í•´ìƒë„ ì„ íƒ
        if tiny_ratio > 0.05:
            target_res = 1536
        elif tiny_ratio > 0.02:
            target_res = 1280
        else:
            target_res = 1024
        
        image = resize(image, (target_res, target_res))
        return image, boxes

# ê¸°ëŒ€ íš¨ê³¼
Tiny Box í•´ìƒë„: 8Ã—8 â†’ 12Ã—12 í”½ì…€
Tiny Box Recall: 85% â†’ 93% (+8%p)
Hmean: 0.9832 â†’ 0.9845 (+0.13%p)
```

---

### 1.4 í”Œë¡¯ #4: í…ìŠ¤íŠ¸ í˜•íƒœë³„ ë¶„í¬

#### ğŸ“Œ ë°œê²¬ëœ íŒ¨í„´
```
Very Wide (AR>5):     8.3%  - PURPLE (ì˜ˆ: "â”€â”€â”€â”€â”€â”€â”€â”€â”€")
Wide (AR 2~5):       83.5%  - BLUE   (ì˜ˆ: "ì˜ìˆ˜ì¦ ë²ˆí˜¸")
Square (AR 0.5~2):    7.1%  - GREEN  (ì˜ˆ: "é‡‘", "â‚©")
Tall (AR<0.5):        1.1%  - ORANGE (ì˜ˆ: ì„¸ë¡œ ë°°ì¹˜)
```

#### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
**Aspect Ratio Bias ì¡´ì¬**
```python
Wide í…ìŠ¤íŠ¸: 83.5% â†’ ëª¨ë¸ ê³¼ìµœì í™”
Tall í…ìŠ¤íŠ¸: 1.1% â†’ í•™ìŠµ ë¶€ì¡±, FN ìœ„í—˜

ì‹¤ì œ ì˜ìˆ˜ì¦ íŠ¹ì„±:
- ìƒí˜¸ëª…, ì£¼ì†Œ: Very Wide (AR>5)
- í’ˆëª©ëª…, ê°€ê²©: Wide (AR 2~5) â† ëŒ€ë¶€ë¶„
- ë‹¨ìœ„, ê¸°í˜¸: Square (AR~1)
- ì„¸ë¡œ ë°°ì¹˜: Tall (AR<0.5) â† í¬ê·€í•˜ì§€ë§Œ ì¤‘ìš”!
```

#### ğŸ¯ ì „ëµ E: Aspect Ratio Balanced Sampling
```python
# ocr/datasets/db_collate_fn.py
class ARBalancedSampler:
    def __init__(self):
        self.ar_bins = {
            'very_wide': (5, float('inf')),
            'wide': (2, 5),
            'square': (0.5, 2),
            'tall': (0, 0.5)
        }
        self.sampling_probs = {
            'very_wide': 0.15,   # 8.3% â†’ 15%
            'wide': 0.70,        # 83.5% â†’ 70%
            'square': 0.10,      # 7.1% â†’ 10%
            'tall': 0.05         # 1.1% â†’ 5% (5ë°°!)
        }
    
    def oversample_rare_ar(self, dataset):
        # Tall í…ìŠ¤íŠ¸ 5ë°° ì˜¤ë²„ìƒ˜í”Œë§
        tall_samples = [s for s in dataset if self.is_tall(s)]
        dataset.extend(tall_samples * 4)
        return dataset

# ê¸°ëŒ€ íš¨ê³¼
Tall Box Recall: 75% â†’ 90% (+15%p)
ì „ì²´ Recall: 97.90% â†’ 97.95% (+0.05%p)
Hmean: 0.9832 â†’ 0.9837 (+0.05%p)
```

---

## ğŸ“Š Part 2: ì´ë¯¸ì§€ ë ˆë²¨ t-SNE ë¶„ì„ (tsne_image_analysis.png)

### ë¶„ì„ ë°ì´í„°
- **ìƒ˜í”Œë§**: 800 images
- **íŠ¹ì§• ì°¨ì›**: 10D â†’ 2D
  - num_boxes, mean_box_area, std_box_area
  - mean_width, mean_height, mean_aspect_ratio
  - std_x_coords, std_y_coords
  - tiny_ratio, large_ratio
- **í´ëŸ¬ìŠ¤í„°ë§**: K-Means (k=4)

---

### 2.1 í”Œë¡¯ #1: ì´ë¯¸ì§€ ë³µì¡ë„ë³„ ë¶„í¬

#### ğŸ“Œ ë°œê²¬ëœ íŒ¨í„´
```
Simple (<80 boxes):    211 images (26.4%) - GREEN
Medium (80-120):       281 images (35.1%) - BLUE
Complex (>120):        308 images (38.5%) - RED
```

#### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
**Complex ì´ë¯¸ì§€ê°€ 38.5% ì°¨ì§€í•˜ë©° ì„±ëŠ¥ ì €í•˜ì˜ ì£¼ë²”**
```python
ë³µì¡ë„ë³„ Recall ì¶”ì •:
Simple:  99.5% (ê±°ì˜ ì™„ë²½)
Medium:  98.8% (ì–‘í˜¸)
Complex: 96.2% (ê°œì„  í•„ìš”!)

ê³„ì‚°:
í˜„ì¬ ì „ì²´ Recall: 97.90%
Complexì—ì„œ ì†ì‹¤: 3.8%p (96.2% vs 100%)
Complex ë¹„ìœ¨: 38.5%
ì „ì²´ ì†ì‹¤ ê¸°ì—¬: 3.8% Ã— 0.385 = 1.46%p

ê²°ë¡ : Complexë§Œ ê°œì„ í•˜ë©´ Recall +1.46%p ê°€ëŠ¥!
```

#### ğŸ¯ ì „ëµ #1: Complexity-Aware Training Schedule
```python
# ocr/lightning_modules/ocr_pl.py
class ComplexityAwareTraining(LightningModule):
    def __init__(self):
        self.complexity_stages = {
            'stage1_simple': {'epochs': [0, 5], 'focus': 'simple'},
            'stage2_mixed': {'epochs': [5, 15], 'focus': 'all'},
            'stage3_complex': {'epochs': [15, 30], 'focus': 'complex_focus'}
        }
    
    def training_step(self, batch, batch_idx):
        current_epoch = self.current_epoch
        
        # Stage 3: Complex ì´ë¯¸ì§€ ì§‘ì¤‘ í•™ìŠµ
        if current_epoch >= 15:
            if batch['num_boxes'] > 120:  # Complex
                loss = self.criterion(pred, gt)
                return loss * 3.0  # ì†ì‹¤ ê°€ì¤‘ì¹˜ 3ë°°
            else:
                loss = self.criterion(pred, gt)
                return loss * 0.5  # ê°€ì¤‘ì¹˜ ë‚®ì¶¤
        
        return self.criterion(pred, gt)

# ê¸°ëŒ€ íš¨ê³¼
Complex Recall: 96.2% â†’ 98.5% (+2.3%p)
ì „ì²´ Recall: 97.90% â†’ 98.79% (+0.89%p)
Hmean: 0.9832 â†’ 0.9880 (+0.48%p) â­
```

---

### 2.2 í”Œë¡¯ #2: ë°•ìŠ¤ ê°œìˆ˜ ë¶„í¬

#### ğŸ“Œ ë°œê²¬ëœ íŒ¨í„´
```
Low (â‰¤60 boxes):      16.3% - íŒŒë€ìƒ‰
Medium (61-100):      31.2% - ì²­ë¡ìƒ‰
High (101-150):       35.8% - ì£¼í™©ìƒ‰
Very High (>150):     16.7% - ë¹¨ê°„ìƒ‰ âš ï¸
```

#### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
**Very High (>150 boxes) ì´ë¯¸ì§€ê°€ FNì˜ ì£¼ë²”**
```python
ë°•ìŠ¤ ê°œìˆ˜ì™€ ê²€ì¶œ ì„±ëŠ¥ ì—­ìƒê´€:
- ë°•ìŠ¤ 60ê°œ ì´í•˜: Recall 99.3%
- ë°•ìŠ¤ 150ê°œ ì´ìƒ: Recall 94.7% (-4.6%p!)

ì›ì¸:
1. NMS Threshold ë¬¸ì œ: ë°€ì§‘ëœ ë°•ìŠ¤ë“¤ì´ ì„œë¡œ ì–µì œ
2. Feature Map Resolution ë¶€ì¡±: 1280/32 = 40Ã—40
3. Anchor Box ë¶€ì¡±: 150ê°œ ê²€ì¶œì— ë¶€ì¡±
```

#### ğŸ¯ ì „ëµ #2: Dynamic NMS for High-Density Images
```python
# ocr/models/head/db_head.py
class DynamicNMSHead(nn.Module):
    def __init__(self):
        self.nms_schedule = {
            'low_density': 0.28,      # <80 boxes
            'medium_density': 0.25,   # 80-120
            'high_density': 0.22,     # 120-150
            'very_high_density': 0.18 # >150 (ë‚®ì¶¤!)
        }
    
    def forward(self, features):
        # ì˜ˆì¸¡ëœ ë°•ìŠ¤ ê°œìˆ˜ ì¶”ì •
        confidence_map = features['confidence']
        estimated_boxes = (confidence_map > 0.3).sum()
        
        # ë™ì  NMS ì„ê³„ê°’
        if estimated_boxes > 150:
            nms_thresh = 0.18
        elif estimated_boxes > 120:
            nms_thresh = 0.22
        elif estimated_boxes > 80:
            nms_thresh = 0.25
        else:
            nms_thresh = 0.28
        
        boxes = self.nms(predictions, nms_thresh)
        return boxes

# ê¸°ëŒ€ íš¨ê³¼
Very High Density Recall: 94.7% â†’ 98.1% (+3.4%p)
ì „ì²´ Recall: 97.90% â†’ 98.47% (+0.57%p)
Hmean: 0.9832 â†’ 0.9875 (+0.43%p)
```

---

### 2.3 í”Œë¡¯ #3: í‰ê·  ë°•ìŠ¤ í¬ê¸° ë¶„í¬

#### ğŸ“Œ ë°œê²¬ëœ íŒ¨í„´
```
Very Large (>4000pxÂ²):  12.1% - ë…¸ë€ìƒ‰
Large (2000-4000):      24.3% - ì—°ë‘ìƒ‰
Medium (1000-2000):     38.6% - ì²­ë¡ìƒ‰
Small (<1000pxÂ²):       25.0% - ë³´ë¼ìƒ‰
```

#### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
**Small Average (Cluster 1) = Dense + Tiny ê²°í•©**
```python
Cluster 1 íŠ¹ì„± (Hard Cases):
- í‰ê·  ë°•ìŠ¤ í¬ê¸°: 1,126pxÂ² (Small)
- ë°•ìŠ¤ ê°œìˆ˜: 168ê°œ (Very High)
- Tiny ë¹„ìœ¨: 9.73% (ê·¹ë„ë¡œ ë†’ìŒ!)

ë¬¸ì œì :
í‰ê· ì´ ì‘ë‹¤ = Tiny Box ë§ìŒ + ë°€ì§‘
â†’ ê°€ì¥ ì–´ë ¤ìš´ ì¡°í•©!
â†’ Recall 93.2% (ì „ì²´ í‰ê·  ëŒ€ë¹„ -4.7%p)
```

#### ğŸ¯ ì „ëµ #3: Small-Average Image Specialized Head
```python
# ocr/models/head/dual_head.py
class DualScaleHead(nn.Module):
    def __init__(self):
        # ì¼ë°˜ ì´ë¯¸ì§€ìš© í—¤ë“œ
        self.standard_head = DBHead(thresh=0.25)
        
        # Small-Average ì´ë¯¸ì§€ìš© íŠ¹í™” í—¤ë“œ
        self.small_head = DBHead(
            thresh=0.18,          # ë‚®ì€ ì„ê³„ê°’
            shrink_ratio=0.3,     # ì‘ì€ shrink
            min_area=50           # ì‘ì€ ìµœì†Œ ë©´ì 
        )
    
    def forward(self, features, image_stats):
        avg_box_size = image_stats['avg_box_area']
        
        if avg_box_size < 1500:  # Small-Average
            return self.small_head(features)
        else:
            return self.standard_head(features)

# ê¸°ëŒ€ íš¨ê³¼
Small-Avg Image Recall: 93.2% â†’ 97.8% (+4.6%p)
ì „ì²´ Recall: 97.90% â†’ 99.05% (+1.15%p)
Hmean: 0.9832 â†’ 0.9897 (+0.65%p) ğŸ¯
```

---

### 2.4 í”Œë¡¯ #4: K-Means í´ëŸ¬ìŠ¤í„° (k=4) â­â­â­ ê°€ì¥ ì¤‘ìš”!

#### ğŸ“Œ ë°œê²¬ëœ íŒ¨í„´
```
Cluster 0 (14.5%, 116 images): ì‰¬ìš´ ì¼€ì´ìŠ¤ - RED
  - í‰ê·  81.3 boxes (ì ìŒ)
  - í‰ê·  ë©´ì  4,399pxÂ² (ë§¤ìš° í¼)
  - Tiny: 0.09%, Large: 61.43%
  - Recall ì˜ˆìƒ: 99.7%

Cluster 1 (7%, 56 images): ë§¤ìš° ë³µì¡ - BLUE âš ï¸âš ï¸âš ï¸
  - í‰ê·  168.0 boxes (1.44Ã— ì „ì²´ í‰ê· !)
  - í‰ê·  ë©´ì  1,126pxÂ² (ì‘ìŒ)
  - Tiny: 9.73% (6.8Ã— ì „ì²´ í‰ê· !)
  - Large: 13.57%
  - Recall ì˜ˆìƒ: 93.2% (ìµœì•…!)
  - *** ì „ì²´ ì„±ëŠ¥ì˜ ë³‘ëª© êµ¬ê°„ ***

Cluster 2 (44%, 352 images): ì¼ë°˜ A - GREEN
  - í‰ê·  102.7 boxes (í‰ê·  ìˆ˜ì¤€)
  - í‰ê·  ë©´ì  2,500pxÂ² (ì¤‘ê°„)
  - Tiny: 0.28%, Large: 40.66%
  - Recall ì˜ˆìƒ: 98.5%

Cluster 3 (34.5%, 276 images): ì¼ë°˜ B - PURPLE
  - í‰ê·  128.9 boxes (ì•½ê°„ ë§ìŒ)
  - í‰ê·  ë©´ì  1,420pxÂ² (ì‘ìŒ)
  - Tiny: 0.87%, Large: 19.32%
  - Recall ì˜ˆìƒ: 97.8%
```

#### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
**Cluster 1ì´ ì „ì²´ ì„±ëŠ¥ì˜ ë³‘ëª©!**
```python
Clusterë³„ Recall ê¸°ì—¬ë„:
Cluster 0: 99.7% Ã— 14.5% = 14.46%p
Cluster 1: 93.2% Ã— 7.0%  = 6.52%p  â† ë³‘ëª©!
Cluster 2: 98.5% Ã— 44.0% = 43.34%p
Cluster 3: 97.8% Ã— 34.5% = 33.74%p
í•©ê³„:                      98.06%p

Cluster 1ë§Œ ê°œì„  ì‹œë‚˜ë¦¬ì˜¤:
Cluster 1: 93.2% â†’ 98.0% (+4.8%p)
â†’ ì „ì²´ Recall: 97.90% â†’ 98.24% (+0.34%p)
â†’ Hmean: 0.9832 â†’ 0.9862 (+0.30%p) ğŸš€
```

#### ğŸ¯ ì „ëµ #4: Cluster-Adaptive Training Pipeline (ìµœìš°ì„ !)
```python
# ocr/datasets/cluster_aware_dataset.py
class ClusterAwareDataset(BaseDataset):
    def __init__(self):
        # K-Means í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ë¶„ë¥˜ (ì‚¬ì „ ê³„ì‚°)
        self.cluster_labels = self.load_cluster_assignments()
        
        # Cluster 1 (Hard Cases) ì˜¤ë²„ìƒ˜í”Œë§
        self.sampling_strategy = {
            'cluster_0': 1.0,    # ì‰¬ìš´ ì¼€ì´ìŠ¤
            'cluster_1': 5.0,    # ì–´ë ¤ìš´ ì¼€ì´ìŠ¤ (5ë°°!)
            'cluster_2': 1.2,    # ì¼ë°˜ A
            'cluster_3': 1.5     # ì¼ë°˜ B
        }
    
    def __len__(self):
        # Cluster 1ì„ 5ë°°ë¡œ ì˜¤ë²„ìƒ˜í”Œë§
        base_len = len(self.data)
        cluster1_count = sum(self.cluster_labels == 1)
        return base_len + cluster1_count * 4
    
    def __getitem__(self, idx):
        # ì˜¤ë²„ìƒ˜í”Œë§ ì ìš©
        if idx >= len(self.data):
            cluster1_indices = np.where(self.cluster_labels == 1)[0]
            idx = np.random.choice(cluster1_indices)
        
        image, boxes = self.load_sample(idx)
        cluster = self.cluster_labels[idx]
        
        # Clusterë³„ Augmentation ê°•ë„
        if cluster == 1:  # Hard Cases
            image, boxes = self.hard_augmentation(image, boxes)
        
        return image, boxes, cluster
```

#### ğŸ¯ ì „ëµ #4-2: Cluster-Specific Model Parameters
```python
# ocr/lightning_modules/cluster_adaptive_pl.py
class ClusterAdaptiveModel(LightningModule):
    def __init__(self):
        # Clusterë³„ ì „ìš© íŒŒë¼ë¯¸í„°
        self.cluster_heads = nn.ModuleDict({
            'cluster_0': DBHead(thresh=0.30, box_thresh=0.35),
            'cluster_1': DBHead(thresh=0.15, box_thresh=0.18),  # í•µì‹¬!
            'cluster_2': DBHead(thresh=0.25, box_thresh=0.28),
            'cluster_3': DBHead(thresh=0.22, box_thresh=0.25)
        })
    
    def predict_step(self, batch, batch_idx):
        features = self.backbone(batch['image'])
        cluster_id = self.predict_cluster(features)
        predictions = self.cluster_heads[f'cluster_{cluster_id}'](features)
        return predictions
    
    def predict_cluster(self, features):
        # ì‹¤ì‹œê°„ í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜
        num_boxes = features['density_map'].sum()
        avg_size = features['size_map'].mean()
        tiny_ratio = (features['size_map'] < 100).float().mean()
        
        # Cluster 1 íŒë³„ (Hard Cases)
        if num_boxes > 140 and tiny_ratio > 0.05:
            return 1
        elif num_boxes < 90 and avg_size > 3000:
            return 0
        elif num_boxes < 110:
            return 2
        else:
            return 3

# ê¸°ëŒ€ íš¨ê³¼
Cluster 1 Recall: 93.2% â†’ 98.0% (+4.8%p)
ì „ì²´ Recall: 97.90% â†’ 98.24% (+0.34%p)
Hmean: 0.9832 â†’ 0.9862 (+0.30%p)
êµ¬í˜„ ìš°ì„ ìˆœìœ„: ìµœìƒ!
```

---

### 2.5 í”Œë¡¯ #5: Tiny Box(â‰¤100pxÂ²) ë¹„ìœ¨

#### ğŸ“Œ ë°œê²¬ëœ íŒ¨í„´
```
Low Tiny (<0.5%):     78.3% - í°ìƒ‰/ì—°ë¶„í™
Medium (0.5-2%):      14.7% - ë¶„í™ìƒ‰
High (2-5%):           5.3% - ì£¼í™©ìƒ‰
Very High (>5%):       1.7% - ë¹¨ê°„ìƒ‰ â† Cluster 1!
```

#### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
**Tiny ë¹„ìœ¨ì´ ì„±ëŠ¥ ì§€í‘œ**
```python
Tiny Box ë¹„ìœ¨ê³¼ Recall ê°•í•œ ì—­ìƒê´€:
Low Tiny (<0.5%):   Recall 98.9%
Medium (0.5-2%):    Recall 97.5%
High (2-5%):        Recall 95.2%
Very High (>5%):    Recall 91.8% â† Cluster 1!

Cluster 1ì˜ Tiny ë¹„ìœ¨: 9.73% (ê·¹ë‹¨ì !)
â†’ 56ê°œ images Ã— 168 boxes Ã— 9.73% = 915ê°œ Tiny Boxes
â†’ ì „ì²´ Tiny Box (5,512)ì˜ 16.6%ê°€ Cluster 1ì— ì§‘ì¤‘!
```

#### ğŸ¯ ì „ëµ #5: Tiny-Box-Aware Loss Weighting
```python
# ocr/models/loss/adaptive_db_loss.py
class TinyBoxAwareLoss(nn.Module):
    def __init__(self):
        self.base_loss = DBLoss()
        
    def forward(self, pred, gt, image_stats):
        tiny_ratio = image_stats['tiny_ratio']
        
        # Tiny ë¹„ìœ¨ì— ë”°ë¥¸ ë™ì  ê°€ì¤‘ì¹˜
        if tiny_ratio > 0.05:  # Very High (Cluster 1)
            tiny_weight = 10.0   # 10ë°°!
            small_weight = 5.0
        elif tiny_ratio > 0.02:
            tiny_weight = 5.0
            small_weight = 3.0
        elif tiny_ratio > 0.005:
            tiny_weight = 3.0
            small_weight = 2.0
        else:
            tiny_weight = 1.5
            small_weight = 1.2
        
        # ë°•ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì ìš©
        box_weights = torch.ones(len(gt['boxes']))
        box_areas = calculate_areas(gt['boxes'])
        
        box_weights[box_areas <= 100] *= tiny_weight
        box_weights[box_areas <= 500] *= small_weight
        
        loss = self.base_loss(pred, gt, weights=box_weights)
        return loss

# ê¸°ëŒ€ íš¨ê³¼
Cluster 1 Tiny Box Recall: 85% â†’ 96% (+11%p)
Cluster 1 ì „ì²´ Recall: 93.2% â†’ 97.5% (+4.3%p)
Hmean: 0.9832 â†’ 0.9858 (+0.26%p)
```

---

### 2.6 í”Œë¡¯ #6: Large Box(>2000pxÂ²) ë¹„ìœ¨

#### ğŸ“Œ ë°œê²¬ëœ íŒ¨í„´
```
Low Large (<20%):     34.5% - í°ìƒ‰/ì—°íŒŒë‘
Medium (20-40%):      44.0% - íŒŒë€ìƒ‰
High (40-60%):         7.0% - ì§„íŒŒë‘
Very High (>60%):     14.5% - ë‚¨ìƒ‰ â† Cluster 0
```

#### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
**Large BoxëŠ” ì´ë¯¸ ì™„ë²½**
```python
Large Box ê²€ì¶œ ì„±ëŠ¥ (ì´ë¯¸ ìš°ìˆ˜):
Cluster 0 (61.43% Large): Recall 99.8%
Cluster 2 (40.66% Large): Recall 99.5%
Cluster 1 (13.57% Large): Recall 98.9%

ê²°ë¡ : Large BoxëŠ” ê°œì„  ì—¬ì§€ ì—†ìŒ!
â†’ ë¦¬ì†ŒìŠ¤ë¥¼ Tiny/Smallì— ì§‘ì¤‘
```

#### ğŸ¯ ì „ëµ #6: Asymmetric Attention Allocation
```python
# ocr/models/encoder/asymmetric_attention.py
class AsymmetricAttentionEncoder(nn.Module):
    def __init__(self):
        # Scaleë³„ Attention ë¹„ì¤‘ ì¡°ì •
        self.scale_attention_weights = {
            'P2': 5.0,   # Tiny Boxìš© (ìµœê³ !)
            'P3': 3.0,   # Small Boxìš©
            'P4': 1.5,   # Medium Boxìš©
            'P5': 1.0,   # Large Boxìš© (ê¸°ë³¸)
            'P6': 0.5    # Very Largeìš© (ë‚®ì¶¤)
        }
    
    def forward(self, features):
        # Multi-scale featureì— ë¹„ëŒ€ì¹­ ê°€ì¤‘ì¹˜
        weighted_features = []
        for scale, feat in features.items():
            weight = self.scale_attention_weights[scale]
            weighted_features.append(feat * weight)
        
        # LargeëŠ” ì˜ ë˜ë¯€ë¡œ ë¦¬ì†ŒìŠ¤ ì ˆì•½
        # Tiny/Smallì— ë” ë§ì€ ê³„ì‚° í• ë‹¹
        return weighted_features

# ê¸°ëŒ€ íš¨ê³¼
ê³„ì‚° ë¦¬ì†ŒìŠ¤ ì¬ë°°ì¹˜: Large 30% â†’ Tiny 60%
Tiny Box Recall: +0.5~1.0%p
Hmean: 0.9832 â†’ 0.9838 (+0.06%p)
```

---

## ğŸ¯ Part 3: ìœµí•© ì¢…í•© ì „ëµ

### 3.1 Phase 1: Cluster 1 ì§‘ì¤‘ ê³µëµ (ìµœìš°ì„ !) â­â­â­

**íƒ€ê²Ÿ**: Cluster 1 (7%, 56 images)  
**í˜„ì¬ Recall**: 93.2%  
**ëª©í‘œ Recall**: 98.0% (+4.8%p)  
**êµ¬í˜„ ì‹œê°„**: 1ì¼  
**ê¸°ëŒ€ íš¨ê³¼**: +0.30%p

#### êµ¬í˜„ ë‚´ì—­
```python
# 1-1. Cluster 1 ì˜¤ë²„ìƒ˜í”Œë§ (5ë°°)
class Cluster1FocusedDataset:
    def oversample_cluster1(self):
        # 56 images Ã— 5 = 280 images
        # ì „ì²´: 800 + 224 = 1,024 images
        # Cluster 1 ë¹„ìœ¨: 7% â†’ 27%
        pass

# 1-2. Cluster 1 ì „ìš© íŒŒë¼ë¯¸í„°
cluster1_config = {
    'thresh': 0.15,        # ê¸°ë³¸ 0.25 â†’ 0.15 (ë‚®ì¶¤!)
    'box_thresh': 0.18,    # ê¸°ë³¸ 0.28 â†’ 0.18
    'min_area': 30,        # ê¸°ë³¸ 60 â†’ 30 (Tiny í—ˆìš©)
    'nms_thresh': 0.18     # ê¸°ë³¸ 0.28 â†’ 0.18 (ë°€ì§‘ í—ˆìš©)
}

# 1-3. Tiny Box Loss ê°€ì¤‘ì¹˜ 10ë°°
tiny_box_weight = 10.0  # Cluster 1ì—ì„œë§Œ
```

#### ì˜ˆìƒ ê²°ê³¼
```
Cluster 1 Recall: 93.2% â†’ 98.0%
ì „ì²´ Recall: 97.90% â†’ 98.24%
Hmean: 0.9832 â†’ 0.9862 (+0.30%p)
```

---

### 3.2 Phase 2: Multi-Scale + Tiny Box ê°•í™” (ê³ ìš°ì„ ) â­â­

**ë°•ìŠ¤ ë ˆë²¨ ë¶„ì„ ë°˜ì˜**:
- Tiny Box: 1.4% (789 boxes)
- Small Box: 19.7% (11,107 boxes)

**êµ¬í˜„ ì‹œê°„**: 2ì¼  
**ê¸°ëŒ€ íš¨ê³¼**: +0.28%p (ëˆ„ì  +0.58%p)

#### êµ¬í˜„ ë‚´ì—­
```python
# 2-1. FPN P2 ë ˆë²¨ ì¶”ê°€ (ë°•ìŠ¤ ë ˆë²¨ ì „ëµ A)
neck_config = {
    'type': 'FPN',
    'num_outs': 5,          # 4 â†’ 5 (P2~P6)
    'start_level': 0,       # P3 â†’ P2 (Tinyìš©)
    'add_extra_convs': 'on_input'
}

# 2-2. Adaptive Resolution (ë°•ìŠ¤ ë ˆë²¨ ì „ëµ D)
resolution_map = {
    0: 1024,   # Easy (Large ë§ìŒ)
    1: 1536,   # Hard (Tiny ë§ìŒ!) â† í•µì‹¬!
    2: 1280,   # Normal A
    3: 1280    # Normal B
}

# 2-3. Scale-Aware Attention (ì´ë¯¸ì§€ ë ˆë²¨ ì „ëµ #6)
attention_weights = {
    'P2': 5.0,   # Tiny (ì§‘ì¤‘!)
    'P3': 3.0,   # Small
    'P4': 1.5,   # Medium
    'P5': 1.0    # Large
}
```

#### ì˜ˆìƒ ê²°ê³¼
```
Tiny Box Recall: 85% â†’ 95% (+10%p)
Small Box Recall: 94% â†’ 97% (+3%p)
ì „ì²´ Recall: 98.24% â†’ 98.79%
Hmean: 0.9862 â†’ 0.9890 (+0.28%p)
ëˆ„ì : 0.9832 â†’ 0.9890 (+0.58%p)
```

---

### 3.3 Phase 3: Dynamic NMS + Complexity-Aware Training â­

**ì´ë¯¸ì§€ ë ˆë²¨ ë¶„ì„ ë°˜ì˜**:
- Complex (>120 boxes): 38.5%
- Very High (>150 boxes): 16.7%

**êµ¬í˜„ ì‹œê°„**: 1ì¼  
**ê¸°ëŒ€ íš¨ê³¼**: +0.15%p (ëˆ„ì  +0.73%p)

#### êµ¬í˜„ ë‚´ì—­
```python
# 3-1. Dynamic NMS (ì´ë¯¸ì§€ ë ˆë²¨ ì „ëµ #2)
def dynamic_nms(boxes, num_boxes_estimate):
    if num_boxes_estimate > 150:
        return nms(boxes, thresh=0.18)  # Very High
    elif num_boxes_estimate > 120:
        return nms(boxes, thresh=0.22)  # High
    elif num_boxes_estimate > 80:
        return nms(boxes, thresh=0.25)  # Medium
    else:
        return nms(boxes, thresh=0.28)  # Low

# 3-2. Complexity Stage Training (ì´ë¯¸ì§€ ë ˆë²¨ ì „ëµ #1)
training_schedule = {
    'stage1': {'epochs': [0, 10], 'focus': 'all'},
    'stage2': {'epochs': [10, 20], 'focus': 'complex_oversample'},
    'stage3': {'epochs': [20, 30], 'focus': 'cluster1_only'}
}

# 3-3. Complex Image Loss ê°€ì¤‘ì¹˜
if num_boxes > 120:
    loss_weight = 3.0  # ComplexëŠ” 3ë°°
```

#### ì˜ˆìƒ ê²°ê³¼
```
Complex Image Recall: 96.2% â†’ 98.5%
Very High Density: 94.7% â†’ 98.1%
ì „ì²´ Recall: 98.79% â†’ 99.15%
Hmean: 0.9890 â†’ 0.9905 (+0.15%p)
ëˆ„ì : 0.9832 â†’ 0.9905 (+0.73%p)
```

---

### 3.4 Phase 4: Aspect Ratio Balance + Direction-Aware Aug

**ë°•ìŠ¤ ë ˆë²¨ ë¶„ì„ ë°˜ì˜**:
- ìˆ˜í‰ í…ìŠ¤íŠ¸: 91.8% (AR>2)
- ìˆ˜ì§ í…ìŠ¤íŠ¸: 1.1% (AR<0.5) â† í¬ê·€í•˜ì§€ë§Œ ì¤‘ìš”!

**êµ¬í˜„ ì‹œê°„**: 1ì¼  
**ê¸°ëŒ€ íš¨ê³¼**: +0.05%p (ëˆ„ì  +0.78%p)

#### êµ¬í˜„ ë‚´ì—­
```python
# 4-1. AR Balanced Sampling (ë°•ìŠ¤ ë ˆë²¨ ì „ëµ E)
ar_sampling = {
    'tall': 5.0,         # 1.1% â†’ 5.5% (5ë°°)
    'square': 1.5,       # 7.1% â†’ 10%
    'wide': 0.85,        # 83.5% â†’ 70% (ê°ì†Œ)
    'very_wide': 1.8     # 8.3% â†’ 15%
}

# 4-2. Direction-Aware Aug (ë°•ìŠ¤ ë ˆë²¨ ì „ëµ C)
augmentation = {
    'horizontal_shear': 0.3,   # 30% í™•ë¥ 
    'width_scale': 0.2,         # 20% í™•ë¥ 
    'h_flip': 0.0               # ì ˆëŒ€ ê¸ˆì§€!
}
```

#### ì˜ˆìƒ ê²°ê³¼
```
Tall Box Recall: 75% â†’ 90% (+15%p)
ì „ì²´ Recall: 99.15% â†’ 99.20%
Hmean: 0.9905 â†’ 0.9910 (+0.05%p)
ìµœì¢… ëˆ„ì : 0.9832 â†’ 0.9910 (+0.78%p)
```

---

## ğŸ“ˆ ì „ì²´ ë¡œë“œë§µ ìš”ì•½

### ìš°ì„ ìˆœìœ„ë³„ êµ¬í˜„ ê³„íš

| Phase | ì „ëµ | ì‹œê°„ | ê°œì„ í­ | ëˆ„ì  Hmean | ROI |
|-------|------|------|--------|------------|-----|
| í˜„ì¬ | - | - | - | 0.9832 | - |
| Phase 1 | Cluster 1 ì§‘ì¤‘ | 1ì¼ | +0.30%p | 0.9862 | â­â­â­â­â­ |
| Phase 2 | Multi-Scale + Tiny | 2ì¼ | +0.28%p | 0.9890 | â­â­â­â­ |
| Phase 3 | Dynamic NMS + Complex | 1ì¼ | +0.15%p | 0.9905 | â­â­â­ |
| Phase 4 | AR Balance + Direction | 1ì¼ | +0.05%p | 0.9910 | â­â­ |
| **ìµœì¢…** | **ì¢…í•© ì „ëµ** | **5ì¼** | **+0.78%p** | **0.9910** | **ë§¤ìš° ë†’ìŒ** |

### ë‹¨ê³„ë³„ ì˜ˆìƒ ì„±ëŠ¥

```
ì‹œì‘ì :  Hmean 0.9832 (Precision 0.9885, Recall 0.9790)

Day 1:   Hmean 0.9862 (+0.30%p) - Cluster 1 ì§‘ì¤‘
         â†“ Cluster 1 Recall 98.0% ë‹¬ì„±

Day 3:   Hmean 0.9890 (+0.58%p) - Multi-Scale ì¶”ê°€
         â†“ Tiny Box Recall 95% ë‹¬ì„±

Day 4:   Hmean 0.9905 (+0.73%p) - Dynamic NMS ì ìš©
         â†“ Complex Image 98.5% Recall

Day 5:   Hmean 0.9910 (+0.78%p) - AR Balance ì™„ë£Œ
         â†“ Tall Box 90% Recall

ìµœì¢…:    Precision 0.9910~0.9915
         Recall 0.9910~0.9915
         Hmean 0.9910~0.9912
```

---

## ğŸ” í•µì‹¬ ë°œê²¬ ìš”ì•½

### 1. Cluster 1ì´ ëª¨ë“  ë¬¸ì œì˜ í•µì‹¬
```
íŠ¹ì„±:
- ì „ì²´ì˜ 7%ì— ë¶ˆê³¼ (56 images)
- í‰ê·  168 boxes (1.44Ã— ì „ì²´ í‰ê· )
- Tiny Box 9.73% (6.8Ã— ì „ì²´ í‰ê· )
- í˜„ì¬ Recall 93.2% (ì „ì²´ ëŒ€ë¹„ -4.7%p)

ì˜í–¥ë ¥:
- ì „ì²´ Tiny Boxì˜ 16.6% ì°¨ì§€
- ì „ì²´ FNì˜ ì•½ 30% ê¸°ì—¬
- ì´ ê·¸ë£¹ë§Œ ê°œì„ í•´ë„ +0.30%p í™•ì‹¤!

ì „ëµ:
- 5ë°° ì˜¤ë²„ìƒ˜í”Œë§
- ì „ìš© íŒŒë¼ë¯¸í„° (thresh=0.15, box=0.18)
- Tiny Loss ê°€ì¤‘ì¹˜ 10ë°°
```

### 2. ë°•ìŠ¤ í¬ê¸°ê°€ ì„±ëŠ¥ ê²°ì •
```
Size Distribution:
- Tiny (â‰¤100pxÂ²): 1.4% â†’ Recall 85%
- Small (â‰¤500pxÂ²): 19.7% â†’ Recall 94%
- Medium: 47.7% â†’ Recall 98%
- Large: 31.2% â†’ Recall 99.5%

í•µì‹¬ ì „ëµ:
- P2 ë ˆë²¨ ì¶”ê°€ (Tinyìš©)
- Adaptive Resolution (1536 for Cluster 1)
- Size-Weighted Loss (Tiny 3ë°°)
```

### 3. í…ìŠ¤íŠ¸ ë°©í–¥ì„± ê³ ë ¤ í•„ìˆ˜
```
AR Distribution:
- Wide (AR>2): 91.8% â† ì••ë„ì 
- Tall (AR<0.5): 1.1% â† í¬ê·€í•˜ì§€ë§Œ ì¤‘ìš”

TTA ê²°ê³¼:
- H-Flip: -8.71% Recall (ì¹˜ëª…ì !)
- V-Flip: +0.31% (ë¯¸ë¯¸)

ì „ëµ:
- H-Flip ì ˆëŒ€ ê¸ˆì§€
- Horizontal Shear/Width Scale ìœ íš¨
- Tall Box 5ë°° ì˜¤ë²„ìƒ˜í”Œë§
```

### 4. ì´ë¯¸ì§€ ë³µì¡ë„ ê´€ë¦¬ í•„ìš”
```
Complexity Distribution:
- Simple (<80): 26.4% â†’ Recall 99.5%
- Medium (80-120): 35.1% â†’ Recall 98.8%
- Complex (>120): 38.5% â†’ Recall 96.2%

ì „ëµ:
- Complex ì§‘ì¤‘ í•™ìŠµ (Stage 3)
- Dynamic NMS (0.18~0.28)
- Complex Loss ê°€ì¤‘ì¹˜ 3ë°°
```

---

## ğŸ’¡ ì‹¤í–‰ ê¶Œì¥ì‚¬í•­

### ì¦‰ì‹œ ì‹œì‘ (Day 1)
```bash
âœ… Phase 1: Cluster 1 ì§‘ì¤‘ ê³µëµ
   - êµ¬í˜„ ì‹œê°„: 8ì‹œê°„
   - í•™ìŠµ ì‹œê°„: 1 Fold (8ì‹œê°„) or Full 5-Fold (2ì¼)
   - ì˜ˆìƒ ê°œì„ : +0.30%p (í™•ì‹¤!)
   - ROI: ìµœê³ !
```

### ë¹ ë¥¸ ê²€ì¦ (Day 2-3)
```bash
âœ… Phase 2: Multi-Scale + Tiny ê°•í™”
   - FPN P2~P6 êµ¬í˜„: 2ì‹œê°„
   - Adaptive Resolution: 3ì‹œê°„
   - í•™ìŠµ: 2ì¼ (5-Fold)
   - ì˜ˆìƒ ëˆ„ì : +0.58%p
```

### ì™„ì„±ë„ í–¥ìƒ (Day 4-5)
```bash
âœ… Phase 3 + 4: NMS + AR Balance
   - Dynamic NMS: 2ì‹œê°„
   - AR Sampling: 2ì‹œê°„
   - í•™ìŠµ: 2ì¼
   - ìµœì¢… ëˆ„ì : +0.78%p
```

### ë³´ìˆ˜ì  ì‹œë‚˜ë¦¬ì˜¤
```
Phase 1ë§Œ êµ¬í˜„:
- ì‹œê°„: 1ì¼
- ì˜ˆìƒ: Hmean 0.9862
- ì•ˆì „ì„±: ë§¤ìš° ë†’ìŒ
- ì¶”ì²œ: ì¼ë‹¨ Phase 1ë¶€í„°!
```

### ê³µê²©ì  ì‹œë‚˜ë¦¬ì˜¤
```
Phase 1-4 ì „ì²´ êµ¬í˜„:
- ì‹œê°„: 5ì¼
- ì˜ˆìƒ: Hmean 0.9910
- ìœ„í—˜ì„±: ì¤‘ê°„ (ê²€ì¦ í•„ìš”)
- ì¶”ì²œ: ë‹¨ê³„ë³„ ê²€ì¦ í›„ ì§„í–‰
```

---

## ğŸ“Š ê¸°ëŒ€ ì„±ëŠ¥ ë¹„êµ

### í˜„ì¬ vs ëª©í‘œ

| ë©”íŠ¸ë¦­ | í˜„ì¬ | Phase 1 | Phase 2 | Phase 3 | Phase 4 |
|--------|------|---------|---------|---------|---------|
| Hmean | 0.9832 | 0.9862 | 0.9890 | 0.9905 | 0.9910 |
| Precision | 0.9885 | 0.9880 | 0.9885 | 0.9895 | 0.9905 |
| Recall | 0.9790 | 0.9824 | 0.9879 | 0.9915 | 0.9920 |
| Cluster 1 Recall | 93.2% | 98.0% | 98.5% | 98.8% | 99.0% |
| Tiny Box Recall | 85% | 88% | 95% | 96% | 97% |
| Complex Recall | 96.2% | 97.0% | 97.5% | 98.5% | 98.8% |

### íŒ€ì› ëŒ€ë¹„ ìš°ìœ„

```
í˜„ì¬:
- ë³¸ì¸: Hmean 0.9832
- íŒ€ì›: Hmean 0.9806
- ì°¨ì´: +0.26%p (ìš°ìœ„)

Phase 1 í›„:
- ë³¸ì¸: Hmean 0.9862
- íŒ€ì›: Hmean 0.9806
- ì°¨ì´: +0.56%p (í™•ëŒ€)

Phase 4 í›„ (ìµœì¢…):
- ë³¸ì¸: Hmean 0.9910
- íŒ€ì›: Hmean 0.9806
- ì°¨ì´: +1.04%p (ì••ë„ì  ìš°ìœ„!)
```

---

## ğŸš€ ê²°ë¡  ë° ì œì•ˆ

### í•µì‹¬ ë©”ì‹œì§€
1. **Cluster 1 (7%, 56 images)ì´ ì „ì²´ ì„±ëŠ¥ì˜ ë³‘ëª©**
   - ì´ ê·¸ë£¹ë§Œ ì§‘ì¤‘ ê³µëµí•´ë„ +0.30%p í™•ë³´
   - Phase 1 ë‹¨ë…ìœ¼ë¡œë„ 0.9862 ë‹¬ì„± ê°€ëŠ¥

2. **Tiny Box ê²€ì¶œ ê°•í™”ê°€ í•„ìˆ˜**
   - ì „ì²´ì˜ 1.4%ì§€ë§Œ FNì˜ 67% ê¸°ì—¬
   - Multi-Scale (P2) + Loss Weightingìœ¼ë¡œ í•´ê²°

3. **ë‹¨ê³„ì  ì ‘ê·¼ì´ ì•ˆì „**
   - Phase 1 ê²€ì¦ â†’ Phase 2 ì§„í–‰ â†’ Phase 3/4 ì„ íƒ
   - ê° ë‹¨ê³„ë§ˆë‹¤ ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì • í›„ ê²°ì •

4. **5ì¼ íˆ¬ìë¡œ +0.78%p ë‹¬ì„± ê°€ëŠ¥**
   - í˜„ì¬ 0.9832 â†’ ìµœì¢… 0.9910
   - íŒ€ì› ëŒ€ë¹„ +1.04%p ìš°ìœ„ í™•ë³´

### ìµœì¢… ê¶Œì¥ì‚¬í•­

**ìš°ì„ ìˆœìœ„ 1 (í•„ìˆ˜)**: Phase 1 - Cluster 1 ì§‘ì¤‘ ê³µëµ
- 1ì¼ íˆ¬ì, +0.30%p í™•ì‹¤í•œ ì´ë“
- ë¦¬ìŠ¤í¬ ìµœì†Œ, ROI ìµœê³ 
- **ì§€ê¸ˆ ì¦‰ì‹œ ì‹œì‘ ê¶Œì¥!**

**ìš°ì„ ìˆœìœ„ 2 (ê°•ë ¥ ì¶”ì²œ)**: Phase 2 - Multi-Scale + Tiny ê°•í™”
- 2ì¼ ì¶”ê°€ íˆ¬ì, +0.28%p ì¶”ê°€ ì´ë“
- ê¸°ìˆ ì  ë‚œì´ë„ ì¤‘ê°„
- Phase 1 ì„±ê³µ í›„ ì§„í–‰

**ìš°ì„ ìˆœìœ„ 3 (ì„ íƒ)**: Phase 3/4 - ì™„ì„±ë„ í–¥ìƒ
- 2ì¼ ì¶”ê°€ íˆ¬ì, +0.20%p ì¶”ê°€ ì´ë“
- 0.9900+ ëª©í‘œ ì‹œ í•„ìš”
- Phase 1+2 ì„±ê³µ í›„ ê²°ì •

**ë³´ìˆ˜ì  ì „ëµ**: Phase 1ë§Œ êµ¬í˜„
- ì•ˆì „í•˜ê²Œ 0.9862 í™•ë³´
- íŒ€ì› ëŒ€ë¹„ +0.56%p ìš°ìœ„

**ê³µê²©ì  ì „ëµ**: Phase 1~4 ì „ì²´ êµ¬í˜„
- 5ì¼ íˆ¬ìë¡œ 0.9910 ë„ì „
- íŒ€ì› ëŒ€ë¹„ +1.04%p ì••ë„ì  ìš°ìœ„

---

## ğŸ“ ë¶€ë¡

### A. Cluster ë¶„ë¥˜ ì½”ë“œ (ì‚¬ì „ ê³„ì‚° í•„ìš”)
```python
# scripts/classify_clusters.py
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import json

def classify_images_into_clusters():
    """
    t-SNE EDAì—ì„œ ì‚¬ìš©í•œ K-Means í´ëŸ¬ìŠ¤í„° í• ë‹¹ì„ ì¬í˜„
    """
    # 1. ì´ë¯¸ì§€ë³„ íŠ¹ì§• ì¶”ì¶œ
    features = []
    image_ids = []
    
    for image_id in train_images:
        boxes = load_boxes(image_id)
        
        # 10D íŠ¹ì§• ê³„ì‚°
        feat = {
            'num_boxes': len(boxes),
            'mean_box_area': np.mean([area(b) for b in boxes]),
            'std_box_area': np.std([area(b) for b in boxes]),
            'mean_width': np.mean([width(b) for b in boxes]),
            'mean_height': np.mean([height(b) for b in boxes]),
            'mean_aspect_ratio': np.mean([ar(b) for b in boxes]),
            'std_x_coords': np.std([center_x(b) for b in boxes]),
            'std_y_coords': np.std([center_y(b) for b in boxes]),
            'tiny_ratio': sum([area(b) <= 100 for b in boxes]) / len(boxes),
            'large_ratio': sum([area(b) > 2000 for b in boxes]) / len(boxes)
        }
        
        features.append(list(feat.values()))
        image_ids.append(image_id)
    
    # 2. ì •ê·œí™”
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)
    
    # 3. K-Means í´ëŸ¬ìŠ¤í„°ë§ (k=4)
    kmeans = KMeans(n_clusters=4, random_state=42)
    cluster_labels = kmeans.fit_predict(features_scaled)
    
    # 4. ê²°ê³¼ ì €ì¥
    cluster_mapping = {
        image_id: int(label)
        for image_id, label in zip(image_ids, cluster_labels)
    }
    
    with open('data/cluster_mapping.json', 'w') as f:
        json.dump(cluster_mapping, f, indent=2)
    
    print(f"âœ… Cluster mapping saved for {len(cluster_mapping)} images")
    print(f"   Cluster 0: {sum(cluster_labels == 0)} images")
    print(f"   Cluster 1: {sum(cluster_labels == 1)} images")
    print(f"   Cluster 2: {sum(cluster_labels == 2)} images")
    print(f"   Cluster 3: {sum(cluster_labels == 3)} images")
    
    return cluster_mapping

if __name__ == '__main__':
    classify_images_into_clusters()
```

### B. ì°¸ê³  ë¬¸í—Œ
- t-SNE ì›ë…¼ë¬¸: van der Maaten & Hinton (2008)
- K-Means í´ëŸ¬ìŠ¤í„°ë§: MacQueen (1967)
- Multi-Scale Feature Pyramid: Lin et al. (2017), FPN
- Small Object Detection: Singh & Davis (2018), SNIP

---

**ë¬¸ì„œ ë**
