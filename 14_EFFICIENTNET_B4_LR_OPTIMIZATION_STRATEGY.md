# EfficientNet-B4 Learning Rate ìµœì í™” ì „ëµ
## í˜„ì¬ â†’ ëª©í‘œ: 96.37% â†’ 96.50%+

---

## ğŸ“Š í˜„ì¬ ìƒí™©

### Postprocessing ìµœì í™” ê²°ê³¼ (ì™„ë£Œ âœ…)

**ì œì¶œ ê²°ê³¼ (4ê°œ)**:
| Rank | Config | H-Mean | Precision | Recall | P-R Gap |
|------|--------|--------|-----------|--------|---------|
| ğŸ¥‡ 1 | t0.28_b0.25 | **96.37%** | 96.74% | 96.23% | 0.51%p |
| ğŸ¥ˆ 2 | t0.27_b0.26 | 96.29% | 96.70% | 96.14% | 0.56%p |
| ğŸ¥‰ 3 | t0.26_b0.28 | 96.14% | 96.78% | 95.80% | 0.98%p |
| 4 | t0.25_b0.27 | 96.06% | 96.56% | 95.85% | 0.71%p |

**ì›ë³¸ (Base)**:
- H-Mean: 96.00%
- Precision: 96.27%
- Recall: 95.98%
- Config: thresh=0.22, box_thresh=0.25

### ì„±ëŠ¥ ê°œì„ 

âœ… **H-Mean**: 96.00% â†’ **96.37%** (+0.37%p)  
âœ… **Precision**: 96.27% â†’ **96.74%** (+0.47%p)  
âœ… **Recall**: 95.98% â†’ **96.23%** (+0.25%p)

### ResNet50 ë¹„êµ

| Metric | ResNet50 5-Fold | EfficientNet-B4 Optimized | ì°¨ì´ |
|--------|-----------------|---------------------------|------|
| H-Mean | 96.28% | **96.37%** | **+0.09%p** âœ… |
| Precision | 97.31% | 96.74% | -0.57%p |
| Recall | 95.58% | 96.23% | **+0.65%p** âœ… |

---

## ğŸ¯ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

### 1. ResNet50 ëŠ¥ê°€ ë‹¬ì„±! ğŸ‰
- EfficientNet-B4ê°€ **ë‹¨ì¼ ëª¨ë¸**ë¡œ ResNet50 5-Fold ì•™ìƒë¸”ì„ ë„˜ì–´ì„¬
- Postprocessing ìµœì í™”ë§Œìœ¼ë¡œ ë‹¬ì„±

### 2. Recallì´ í•µì‹¬ ê°œì„  í¬ì¸íŠ¸
- Recall: +0.65%p ëŒ€í­ ê°œì„ 
- EfficientNet-B4ê°€ ë” ë§ì€ ë°•ìŠ¤ë¥¼ ì •í™•í•˜ê²Œ ê²€ì¶œ

### 3. ìµœì  Postprocessing íŒŒë¼ë¯¸í„°
- **thresh = 0.28** (ì˜ˆìƒ 0.25-0.26ë³´ë‹¤ ë†’ìŒ)
- **box_thresh = 0.25** (ë‚®ì€ ê°’ ìœ ì§€)
- ì´ìœ : ê¸°ì¡´ ëª¨ë¸ì´ False Positiveê°€ ë§ì•˜ìŒ (thresh ì¦ê°€ë¡œ í•´ê²°)

### 4. Trade-off ë¶„ì„
```
thresh íš¨ê³¼ (0.22 â†’ 0.28):
  - Precision: +0.47%p âœ…
  - Recall: +0.25%p âœ… (ì˜ˆìƒê³¼ ë°˜ëŒ€!)
  â†’ False Positiveê°€ ë§ì•„ì„œ thresh ì¦ê°€ê°€ ì–‘ìª½ ê°œì„ 

box_thresh íš¨ê³¼:
  - 0.25 vs 0.26: í° ì°¨ì´ ì—†ìŒ
  - 0.28ë¡œ ì¦ê°€: Recall -0.33%p (ê³¼ë„)
  â†’ ë‚®ê²Œ ìœ ì§€í•˜ëŠ” ê²ƒì´ ìœ ë¦¬
```

### 5. P-R Balance
- **t0.28_b0.25**: 0.51%p (ìµœì  ê· í˜•) âœ…
- t0.27_b0.26: 0.56%p
- t0.26_b0.28: 0.98%p (ë¶ˆê· í˜•)

---

## ğŸš€ ë‹¤ìŒ ì „ëµ: Learning Rate ìµœì í™”

### ëª©í‘œ
- í˜„ì¬: 96.37% (thresh=0.28, LR=0.0003)
- ëª©í‘œ: **96.50%+** (LR ìµœì í™”)
- ìµœì¢…: **96.70-96.80%** (5-Fold Ensemble)

### ê°€ì„¤
í˜„ì¬ Learning Rate (0.0003)ê°€ EfficientNet-B4ì— ìµœì ì´ ì•„ë‹ ìˆ˜ ìˆìŒ:
- ResNet50: LR=0.0005 ìµœì 
- EfficientNet-B4: LR=0.0003 (60% ê°ì†Œ)
- í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” 0.0004-0.0005ê°€ ë” ë‚˜ì„ ìˆ˜ë„?

### WandB Sweep ì „ëµ

**ë°©ë²•**: Bayesian Optimization  
**ì‹¤í–‰ íšŸìˆ˜**: 12íšŒ (LRì— ì§‘ì¤‘)  
**ì†Œìš” ì‹œê°„**: ì•½ 4ì‹œê°„

**íƒìƒ‰ íŒŒë¼ë¯¸í„°**:
```yaml
Critical (High Impact):
  - Learning Rate: 0.00025 - 0.0006
  - Weight Decay: 0.00005 - 0.0005

Secondary (Medium Impact):
  - T_Max: 20, 22, 24
  - eta_min: 0.000005 - 0.00005

Fixed (ìµœì ê°’):
  - thresh: 0.28
  - box_thresh: 0.25
  - max_candidates: 600
```

**ì˜ˆìƒ ê²°ê³¼**:
- Conservative (70%): 96.42-96.48%
- Neutral (50%): 96.48-96.55%
- Optimistic (30%): 96.55-96.65%

---

## ğŸ“‹ ì‹¤í–‰ ê³„íš

### Option 1: WandB Sweep (ê¶Œì¥)

**ì¥ì **:
- âœ… ìë™ ìµœì í™”
- âœ… Bayesianìœ¼ë¡œ íš¨ìœ¨ì  íƒìƒ‰
- âœ… 96.50%+ ë‹¬ì„± ê°€ëŠ¥ì„± ë†’ìŒ

**ì‹¤í–‰**:
```bash
cd /data/ephemeral/home/baseline_code

# WandB ë¡œê·¸ì¸
wandb login

# Sweep ì‹¤í–‰ (12íšŒ, 4ì‹œê°„)
bash scripts/run_sweep_lr_optimized.sh 12

# ë˜ëŠ” Background ì‹¤í–‰
bash scripts/run_sweep_lr_optimized.sh 12 bg
```

**ë‹¤ìŒ ë‹¨ê³„**:
1. WandB ëŒ€ì‹œë³´ë“œì—ì„œ ìµœê³  ì„±ëŠ¥ í™•ì¸
2. ìµœì  LRë¡œ ë‹¨ì¼ ëª¨ë¸ ì¬í•™ìŠµ
3. 96.50%+ ë‹¬ì„± ì‹œ 5-Fold ì§„í–‰

---

### Option 2: ìˆ˜ë™ LR í…ŒìŠ¤íŠ¸ (ë¹ ë¦„)

**ì¥ì **:
- âœ… WandB ë¶ˆí•„ìš”
- âœ… 2-3ì‹œê°„ ì†Œìš”
- âœ… ë‹¨ìˆœ ëª…í™•

**ì‹¤í–‰**:
```bash
# LR=0.0004 í…ŒìŠ¤íŠ¸ (í˜„ì¬ 0.0003ì˜ 133%)
python runners/train.py \
  preset=efficientnet_b4_lr_optimized \
  exp_name=efficientnet_b4_lr_0.0004 \
  models.optimizer.lr=0.0004 \
  trainer.max_epochs=22

# ê²°ê³¼ í™•ì¸ í›„ ì˜ˆì¸¡
python runners/predict.py \
  preset=efficientnet_b4_lr_optimized \
  exp_name=efficientnet_b4_lr_0.0004_predict \
  checkpoint_path=outputs/efficientnet_b4_lr_0.0004/checkpoints/best.ckpt
```

**LR í›„ë³´**:
1. **0.0004** (í˜„ì¬ 0.0003ì˜ 133%) - ì¶”ì²œ â­
2. 0.00035 (í˜„ì¬ 0.0003ì˜ 117%)
3. 0.00045 (í˜„ì¬ 0.0003ì˜ 150%)

---

### Option 3: ë°”ë¡œ 5-Fold (ë³´ìˆ˜ì )

**ì¥ì **:
- âœ… ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥
- âœ… 96.45-96.55% ê¸°ëŒ€
- âœ… ì•ˆì •ì 

**ì‹¤í–‰**:
```bash
# í˜„ì¬ ìµœì  ì„¤ì •(thresh=0.28, LR=0.0003)ìœ¼ë¡œ 5-Fold
bash scripts/train_efficientnet_b4_5fold_optimized.sh
```

**ì˜ˆìƒ ê²°ê³¼**:
- Conservative: 96.42-96.48%
- Neutral: 96.48-96.55%
- Optimistic: 96.55-96.62%

---

## ğŸ¯ ê¶Œì¥ ì‹¤í–‰ ìˆœì„œ

### Phase 1: ìˆ˜ë™ LR í…ŒìŠ¤íŠ¸ (2-3ì‹œê°„)
```bash
# LR=0.0004 í…ŒìŠ¤íŠ¸
python runners/train.py \
  preset=efficientnet_b4_lr_optimized \
  exp_name=efficientnet_b4_lr_0.0004 \
  models.optimizer.lr=0.0004 \
  trainer.max_epochs=22
```

### Phase 2: ê²°ê³¼ í‰ê°€ (30ë¶„)
- 96.45%+ ë‹¬ì„± â†’ Phase 3 (5-Fold)
- 96.40-96.45% â†’ WandB Sweep
- <96.40% â†’ LR=0.00035 ì¬ì‹œë„

### Phase 3: 5-Fold í•™ìŠµ (12ì‹œê°„)
```bash
# ìµœì  LRë¡œ 5-Fold
bash scripts/train_efficientnet_b4_5fold_optimized.sh
```

### Phase 4: Voting Ensemble
- Votingâ‰¥3 ì¶”ì²œ
- ì˜ˆìƒ: 96.55-96.65%

---

## ğŸ“Š ì˜ˆìƒ ìµœì¢… ì„±ëŠ¥

### ë‹¨ì¼ ëª¨ë¸ (LR ìµœì í™”)
- Conservative: 96.45-96.48%
- Neutral: 96.48-96.55%
- Optimistic: 96.55-96.60%

### 5-Fold Ensemble (Votingâ‰¥3)
- Conservative: 96.50-96.58%
- Neutral: 96.58-96.65%
- Optimistic: 96.65-96.75%

### vs ResNet50
| Model | H-Mean | ì°¨ì´ |
|-------|--------|------|
| ResNet50 5-Fold | 96.28% | - |
| EfficientNet-B4 Single (Optimized) | 96.50% | +0.22%p |
| EfficientNet-B4 5-Fold (Votingâ‰¥3) | 96.65% | +0.37%p |

---

## ğŸ”§ ìƒì„±ëœ íŒŒì¼

### Config Files
1. **configs/sweep_efficientnet_b4_lr_optimized.yaml**
   - WandB Sweep ì„¤ì •
   - Postprocessing ê³ ì • (thresh=0.28, box_thresh=0.25)
   - LR, Weight Decay íƒìƒ‰

2. **configs/preset/efficientnet_b4_lr_optimized.yaml**
   - ìµœì í™”ëœ preset

3. **configs/preset/models/model_efficientnet_b4_lr_optimized.yaml**
   - LR=0.0004 (ê¸°ë³¸ê°’, Sweepìœ¼ë¡œ ìµœì í™”)

4. **configs/preset/models/head/db_head_lr_optimized.yaml**
   - thresh=0.28, box_thresh=0.25 ê³ ì •

### Scripts
5. **scripts/run_sweep_lr_optimized.sh**
   - WandB Sweep ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
   - Background ëª¨ë“œ ì§€ì›

---

## ğŸ’¡ í•µì‹¬ ìš”ì•½

### ë‹¬ì„±í•œ ê²ƒ
âœ… Postprocessing ìµœì í™”ë¡œ 96.37% ë‹¬ì„±  
âœ… ResNet50 5-Fold (96.28%) ëŠ¥ê°€  
âœ… ìµœì  íŒŒë¼ë¯¸í„° ë°œê²¬: thresh=0.28, box_thresh=0.25

### ë‹¤ìŒ ëª©í‘œ
ğŸ¯ Learning Rate ìµœì í™”ë¡œ 96.50%+ ë‹¬ì„±  
ğŸ¯ 5-Fold Ensembleë¡œ 96.65%+ ë‹¬ì„±  
ğŸ¯ ìµœì¢… ëª©í‘œ: 96.70-96.80%

### ì¶”ì²œ ì „ëµ
1ï¸âƒ£ **ì¦‰ì‹œ**: LR=0.0004 ë‹¨ì¼ í…ŒìŠ¤íŠ¸ (2ì‹œê°„)  
2ï¸âƒ£ **96.45%+ ë‹¬ì„± ì‹œ**: 5-Fold ì§„í–‰ (12ì‹œê°„)  
3ï¸âƒ£ **<96.45% ì‹œ**: WandB Sweep (4ì‹œê°„)

---

## ğŸš€ ë°”ë¡œ ì‹œì‘í•˜ê¸°

**ê°€ì¥ ë¹ ë¥¸ ë°©ë²•** (2ì‹œê°„):
```bash
cd /data/ephemeral/home/baseline_code
python runners/train.py \
  preset=efficientnet_b4_lr_optimized \
  exp_name=efficientnet_b4_lr_0.0004 \
  models.optimizer.lr=0.0004 \
  trainer.max_epochs=22
```

**ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•** (4ì‹œê°„):
```bash
wandb login
bash scripts/run_sweep_lr_optimized.sh 12 bg
```

**ê°€ì¥ ì•ˆì „í•œ ë°©ë²•** (12ì‹œê°„):
```bash
bash scripts/train_efficientnet_b4_5fold_optimized.sh
```

---

**ìƒì„± ì¼ì‹œ**: 2026-02-02  
**í˜„ì¬ Best**: 96.37% (EfficientNet-B4, thresh=0.28)  
**ëª©í‘œ**: 96.65%+ (5-Fold Ensemble)  
**ì „ëµ**: LR ìµœì í™” â†’ 5-Fold â†’ 96.7% ëŒíŒŒ!
